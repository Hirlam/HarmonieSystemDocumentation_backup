var documenterSearchIndex = {"docs":
[{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/BoundaryFilePreparation?action=edit\"","category":"page"},{"location":"BoundaryFilePreparation/#Preparation-of-initial-and-boundary-files-1","page":"Boundaries","title":"Preparation of initial and boundary files","text":"","category":"section"},{"location":"BoundaryFilePreparation/#Introduction-1","page":"Boundaries","title":"Introduction","text":"","category":"section"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"HARMONIE can be coupled with external models as IFS, ARPEGE, HIRLAM. Internally it is possible to nest the different ALADIN/ALARO/AROME with some restrictions. In the following we describe the host initial and boundary files are generated depending on different configurations. Boundary file preparation basically includes two parts: forecast file fetching and boundary file generation.","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"The ECFLOW tasks for initial and boundary preparation","category":"page"},{"location":"BoundaryFilePreparation/#Boundary-strategies-1","page":"Boundaries","title":"Boundary strategies","text":"","category":"section"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"There are a number of ways to chose which forecast lengths you use as boundaries. The strategy is determined by BDSTRATEGY in ecf/config_exp.h  and there are a number of strategies implemented.","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"available            : Search for available files in BDDIR adn try to keep forecast consistency. This is ment to be used operationally since it will at least keep your run going, but with old boundaries, if no new boundaries are available.\nsimulate_operational : Mimic the behaviour of the operational runs using ECMWF 6h old boundaries.\nsame_forecast        : Use all boundaries from the same forecast, start from analysis\nanalysis_only        : Use only analyses as boundaries. Note that BDINT cannot be shorter than the frequency of the analyses.\nlatest               : Use the latest possible boundary with the shortest forecast length\nRCR_operational      : Mimic the behaviour of the RCR runs, ie\n12h old boundaries at 00 and 12 and\n06h old boundaries at 06 and 18\njbensemble          : Same as sameforecast but used for JB-statistics generation. With this you should export JBENSMEMBER=some_number\neps_ec               : ECMWF EPS members (on reduced Gaussian grid). It is only meaningful with ENSMSEL non-empty, i.e., ENSSIZE > 0","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"All the strategies are defined in Boundary_strategy.pl. The script generates a file bdstrategy in your working directory that could look like:","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":" Boundary strategy\r\n\r\n       DTG: 2011090618\r\n        LL: 36\r\n     BDINT: 3\r\n   BDCYCLE: 6\r\n  STRATEGY: simulate_operational\r\n     BDDIR: /cca/tmp/ms/se/snh/hm_home/alaro_37h1_trunk/ECMWF/archive/@YYYY@/@MM@/@DD@/@HH@\r\nHOST_MODEL: ifs\r\nINT_BDFILE: /cca/tmp/ms/se/snh/hm_home/alaro_37h1_trunk/20110906_18/ELSCFHARMALBC@NNN@\r\n\r\n# The output bdstrategy file has the format of \r\n# NNN|YYYYMMDDHH INT_BDFILE BDFILE BDFILE_REQUEST_METHOD \r\n# where \r\n# NNN        is the input hour\r\n# YYYYMMDDHH is the valid hour for this boundary\r\n# INT_BDFILE is the final boundary file\r\n# BDFILE                is the input boundary file\r\n# BDFILE_REQUEST_METHOD is the method to the request BDFILE from e.g. MARS, ECFS or via scp\r\n\r\nSURFEX_INI| /cca/tmp/ms/se/snh/hm_home/alaro_37h1_trunk/20110906_18/SURFXINI.lfi \r\n000|2011090618 /cca/tmp/ms/se/snh/hm_home/alaro_37h1_trunk/20110906_18/ELSCFHARMALBC000 /cca/tmp/ms/se/snh/hm_home/alaro_37h1_trunk/ECMWF/archive/2011/09/06/12/fc20110906_12+006 MARS_umbrella -d 20110906 -h 12 -l 6 -t\r\n003|2011090621 /cca/tmp/ms/se/snh/hm_home/alaro_37h1_trunk/20110906_18/ELSCFHARMALBC001 /cca/tmp/ms/se/snh/hm_home/alaro_37h1_trunk/ECMWF/archive/2011/09/06/12/fc20110906_12+009 MARS_umbrella -d 20110906 -h 12 -l 9 -t\r\n...","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"Meaning that the if the boundary file is not found under BDDIR the command MARS_umbrella -d YYYYMMDD -h HH -l LLL -t BDDIR will be executed. A local interpretation could be to search for external data if your file is not on BDDIR. Like the example from SMHI:","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":" Boundary strategy\r\n\r\n       DTG: 2011090112\r\n        LL: 24\r\n     BDINT: 3\r\n   BDCYCLE: 06\r\n  STRATEGY: latest\r\n     BDDIR: /nobackup/smhid9/sm_esbol/hm_home/ice_36h1_4/g05a/archive/@YYYY@/@MM@/@DD@/@HH@\r\nHOST_MODEL: hir\r\nINT_BDFILE: /nobackup/smhid9/sm_esbol/hm_home/ice_36h1_4/20110901_12/ELSCFHARMALBC@NNN@\r\n EXT_BDDIR: smhi_file:/data/arkiv/field/f_archive/hirlam/G05_60lev/@YYYY@@MM@/G05_@YYYY@@MM@@DD@@HH@00+@LLL@H00M\r\nEXT_ACCESS: scp\r\n\r\n# The output bdstrategy file has the format of \r\n# NNN|YYYYMMDDHH INT_BDFILE BDFILE BDFILE_REQUEST_METHOD \r\n# where \r\n# NNN        is the input hour\r\n# YYYYMMDDHH is the valid hour for this boundary\r\n# INT_BDFILE is the final boundary file\r\n# BDFILE                is the input boundary file\r\n# BDFILE_REQUEST_METHOD is the method to the request BDFILE from e.g. MARS, ECFS or via scp\r\n\r\n# hh_offset is 0 ; DTG is  \r\nSURFEX_INI| /nobackup/smhid9/sm_esbol/hm_home/ice_36h1_4/20110901_12/SURFXINI.lfi \r\n000|2011090112 /nobackup/smhid9/sm_esbol/hm_home/ice_36h1_4/20110901_12/ELSCFHARMALBC000 /nobackup/smhid9/sm_esbol/hm_home/ice_36h1_4/g05a/archive/2011/09/01/12/fc20110901_12+000 scp smhi:/data/arkiv/field/f_archive/hirlam/G05_60lev/201109/G05_201109011200+000H00M \r\n003|2011090115 /nobackup/smhid9/sm_esbol/hm_home/ice_36h1_4/20110901_12/ELSCFHARMALBC001 /nobackup/smhid9/sm_esbol/hm_home/ice_36h1_4/g05a/archive/2011/09/01/12/fc20110901_12+003 scp smhi:/data/arkiv/field/f_archive/hirlam/G05_60lev/201109/G05_201109011200+003H00M ","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"In this example an scp from smhi will be executed if the expected file is not in BDDIR. There are a few environment variables that one can play with in sms/confi_exp.h that deals with the initial and boundary files","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"HOST_MODEL : Tells the origin of your boundary data      * ifs : ecmwf data      * hir : hirlam data      * ald : Output from aladin physics, this also covers arpege data after fullpos processing.      * ala : Output from alaro physics      * aro : Output from arome physics\nBDINT : Interval of boundaries in hours\nBDLIB : Name of the forcing experiment. Set\nECMWF to use MARS data\nRCRa  to use RCRa data from ECFS\nOther HARMONIE/HIRLAM experiment\nBDDIR : The path to the boundary file. In the default location BDDIR=$HM_DATA/${BDLIB}/archive/@YYYY@/@MM@/@DD@/@HH@ the file retrieved from e.g. MARS will be stored in a separate directory. On could also consider to configure this so that all the retrieved files are located in your working directory $WRK. Locally this points to the directory where you have all your common boundary HIRLAM or ECMWF files.\nINT_BDFILE : is the full path of the interpolated boundary files. The default setting is to let the boundary file be removed by directing it to $WRK.\nINTSINIFILE : The full path of the initial surfex file. ","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"There are a few optional environment variables that could be used that are not visible in config_exp.h ","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"EXTBDDIR : External location of boundary data. If not set rules are depending on HOSTMODEL\nEXTACCESS : Method for accessing external data. If not set rules are depending on HOSTMODEL\nBDCYCLE : Assimilation cycle interval of forcing data, default is 6h.","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"More about this can be bounds in the Boundary_strategy.pl script.","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"The bdstrategy file is parsed by the script ExtractBD. ","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"ExtractBD Checks if data are on BDDIR otherwise copy from EXTBDDIR.  The operation performed can be different depending on HOST and HOSTMODEL. IFS data at ECMWF are extracted from MARS, RCR data are copied from ECFS.\nInput parameters: Forecast hour\nExecutables: none.","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"In case data should be retrieved from MARS there is also a stage step. When calling MARS with the stage command we ask MARS to make sure data are on disk. In HARMONIE we ask for all data for one day of r forecasts ( normally four cycles ) at the time.  ","category":"page"},{"location":"BoundaryFilePreparation/#Initial-and-Boundary-file-generation-1","page":"Boundaries","title":"Initial and Boundary file generation","text":"","category":"section"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"To be able to start the model we need the variables defining the model state.","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"T,U,V,PS in spectral space\nQ in gridpoint or spectral space","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"Optional:","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"Q,,l,,, Q,,i,,, Q,,r,,, Q,,g,,,  Q,,s,,, Q,,h,,\nTKE","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"For the surface we need the different state variables for the different tiles. The scheme selected determines the variables.","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"Boundary files (coupling files) for HARMONIE are prepared in two different ways depending on the  nesting procedure defined by HOST_MODEL.","category":"page"},{"location":"BoundaryFilePreparation/#Using-gl-1","page":"Boundaries","title":"Using gl","text":"","category":"section"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"If you use data from HIRLAM or ECMWF glgribapi will be called to generate boundaries. The generation can be summarized in the following steps:","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"Setup geometry and what kind of fields to read depending on HOST_MODEL\nRead the necessary climate data from a climate file\nTranslate and interpolate the surface variables horizontally if the file is to be used as an initial file. All interpolation respects land sea mask properties. The soil water is not interpolated directly but interpolated using the Soil Wetness Index to preserve the properties of the soil between different models. The treatment of the surface fields is only done for the initial file.\nHorizontal interpolation of upper air fields as well as restaggering of winds.\nVertical interpolation using the same method (etaeta) as in HIRLAM\nConserve boundary layer structure\nConserve integrated quantities\nOutput to an FA file ( partly in spectral space )","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"glgribapi is called by the script gl_bd where we make different choices depending on PHYSICS and HOST_MODEL","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"When starting a forecast there are options to whether e.g. cloud properties and TKE should be read from the initial/boundary file through NREQIN and NCOUPLING. At the moment these fields are read from the initial file but not coupled to. gl reads them if they are available in the input files and sets them to zero otherwise. For a Non-Hydrostatic run the non-hydrostatic pressure departure and the vertical divergence are demanded as an initial field. The pressure departure is by definition zero if you start from a non-hydrostatic mode and since the error done when disregarding the vertical divergence is small it is also set to zero in gl. There are also a choice in the forecast model to run with Q in gridpoint or in spectral space.","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"It's possible to use an input file without e.g. the uppermost levels. By setting LDEMAND_ALL_LEVELS=.FALSE. the missing levels will be ignored. This is used at some institutes to reduce the amount of data transferred for the operational runs. ","category":"page"},{"location":"BoundaryFilePreparation/#Using-fullpos-1","page":"Boundaries","title":"Using fullpos","text":"","category":"section"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"If you use data generated by HARMONIE you will use fullpos to generate boundaries and initial conditions. Here we will describe how it's implemented in HARMONIE but there are also good documentation on the gmapdoc site.","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"fullpos","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"In HARMONIE it is done by the script E927. It contains the following steps:","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"Fetcht climate files. Fullpos needs a climate file and the geometry definition for both the input and output domains. \nSet different moist variables in the namelists depending if your run AROME or ALADIN/ALARO.\nCheck if input data has Q in gridpoint or spectral space.\nDemand NH variables if we run NH.\nDetermine the number of levels in the input file and extract the correct levels from the definition in [source:Harmonie/scr/Vertical_level.pl]","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"Run fullpos","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"E927 is also called from 4DVAR when the resolution is changed between the inner and outer loops.","category":"page"},{"location":"BoundaryFilePreparation/#Generation-of-initial-data-for-SURFEX-1","page":"Boundaries","title":"Generation of initial data for SURFEX","text":"","category":"section"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"For SURFEX we have to fill the different tiles with correct information from the input data. This is called the PREP step in the SURFEX context. Prepinisurfex creates an initial SURFEX file from an FA file if you run with SURFACE=surfex. ","category":"page"},{"location":"BoundaryFilePreparation/#","page":"Boundaries","title":"Boundaries","text":"Read more about SURFEX","category":"page"},{"location":"BoundaryFilePreparation/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Boundaries","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Build_with_makeup?action=edit\"","category":"page"},{"location":"Build_with_makeup/#Building-with-MAKEUP-1","page":"Makeup","title":"Building with MAKEUP","text":"","category":"section"},{"location":"Build_with_makeup/#Background-1","page":"Makeup","title":"Background","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Makeup is an alternative mechanism to build the HARMONIE system Instead of using GMKPACK to build the libraries and binaries, standard GNU make (gmake) procedures are used, making build of executables an easier task. Also parallel make comes for free, thus enhanced turn-around time for build process. Furthermore, rebuilds and change of compiler flags – either per project and/or per source files basis – are now trivial to do.","category":"page"},{"location":"Build_with_makeup/#MAKEUP-very-quickly-1","page":"Makeup","title":"MAKEUP very quickly","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The process of using the MAKEUP system in stand-alone fashion is described next.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Lets define two helper variables for the presentation purposes:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The variable HARMONIE_SRC refers to the directory, where the AROME source code is situated. Another variable HARMONIE_MAKEUP refers to the directory, where build configuration files and MAKEUP's scripts are located. ","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\n# In ksh/bash\r\nexport HARMONIE_SRC=/some/path/harmonie/src\r\nexport HARMONIE_MAKEUP=/some/path/harmonie/util/makeup\r\n# In csh/tcsh\r\nsetenv HARMONIE_SRC /some/path/harmonie/src\r\nsetenv HARMONIE_MAKEUP /some/path/harmonie/util/makeup","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Usually HARMONIE_MAKEUP is HARMONIE_SRC/../util/makeup , but it doesn't have to be (e.g. in FMI's production system the HARMONIE_MAKEUP is situated on a separate disk than the source code HARMONIE_SRC) – and MAKEUP can handle this now.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The process of building HARMONIE executable contains just a few steps:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Goto directory HARMONIE_MAKEUP and create/edit your configuration file (config.*). Beware of preferred naming convention:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"config.<MET-INSTITUTE>.<MACHINE-PLATFORM>.<COMPILER-NAME>.<FUNDAMENTAL-OPTIONS>.<OPTIONAL-OPTIONS>","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Run MAKEUP's configure script under HARMONIE_SRC (for example):","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\n$HARMONIE_MAKEUP/configure $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"If applicable, adjust environment settings before launching of make. e.g., on some platforms, one needs to remember loading adequate modules, such as for DMI Cray XT5,","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"  module swap PrgEnv-pgi PrgEnv-pathscale  # if pathscale is to be used\r\n  module swap xt-mpt xt-mpt/3.5.0\r\n  module swap xt-asyncpe/3.8 xt-asyncpe/3.4","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Goto HARMONIE_SRC directory and type make (or gmake, if make is non-GNU make). Redirect output to a file & terminal:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\ngmake 2>&1 |  tee logfile  # ksh/bash\r\ngmake      |& tee logfile  # csh/tcsh","category":"page"},{"location":"Build_with_makeup/#Using-MAKEUP-to-build-auxlibs-(bufr,-gribex,-rgb)-1","page":"Makeup","title":"Using MAKEUP to build auxlibs (bufr, gribex, rgb)","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"You can now build EMOS- and related libraries by using the MAKEUP. All you need to know is what is your sources.<arch> that you would use to build this stuff anyway. Pass that generic name to the MAKEUP's configure through -E option and you're in business. An example for FMI's Cray:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\n$HARMONIE_MAKEUP/configure -E sources.crayxt $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\ngmake","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"This will create extra libs (so called ´´MY_SYSLIBS´´) libbufr.a, libgribex.a and librgb.a and they will end up being linked into your executables, like MASTERODB.","category":"page"},{"location":"Build_with_makeup/#Using-MAKEUP-to-build-also-util/gl-tools-1","page":"Makeup","title":"Using MAKEUP to build also util/gl -tools","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"HARMONIE utility package GL as located in util/gl directory can also be built as part of MAKEUP process, if option -G is also given to the configure:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\n$HARMONIE_MAKEUP/configure -G $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\ngmake","category":"page"},{"location":"Build_with_makeup/#Using-MAKEUP-to-build-also-Oulan-and/or-Monitor-tools-1","page":"Makeup","title":"Using MAKEUP to build also Oulan and/or Monitor -tools","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"HARMONIE utility package MONITOR and obs-preprocessor OULAN can also be build with MAKEUP. If you add option -B , then you will get Oulan and Monitor executables built, too. Or you can be more selective and oopt only for oulan with -b oulan, or just monitor -b monitor :","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\n# Request for building both oulan & monitor, too\r\n$HARMONIE_MAKEUP/configure -B $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\n# .. or add oulan only :\r\n$HARMONIE_MAKEUP/configure -b oulan $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\n# .. or add monitor only :\r\n$HARMONIE_MAKEUP/configure -b monitor $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\ngmake","category":"page"},{"location":"Build_with_makeup/#Building-objects-away-from-HARMONIE_SRC-directory-1","page":"Makeup","title":"Building objects away from $HARMONIE_SRC-directory","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"If you do not want to pollute your source directories with objects and thus making it hard to recognize which files are under version handling system SVN and which ain't (... although SVN command svn -q st would tell ...), then use -P option. This will redirect compilations away from source code, under $HARMONIE_SRC/../makeup.ZZZ, where ZZZ is the suffix of your config-file, e.g. FMI.cray_xt5m.pathscale.mpi+openmp.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The operation sequence is as follows:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\n$HARMONIE_MAKEUP/configure [options] -P $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\ncd $HARMONIE_SRC/../makeup.FMI.cray_xt5m.pathscale.mpi+openmp/src\r\ngmake","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The drawback with this approach is that whenever there is an update in the master source directories, you need to run lengthy configure in order to rsync the working directory up to date. We may need to introduce a separate command for this to avoid full rerun of configure.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"You can also use lowercase -p option with argument pointing to a directory-root, where to compile:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\n$HARMONIE_MAKEUP/configure [options] -p /working/path $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\ncd /working/path/src\r\ngmake","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Now, it is important to understand that this /working/path has no connection to version handling i.e. if you change something  in your master copy (say : issue a svn up-command), then your working directory remains unaltered. To synchronize it, do the following:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd /working/path/src\r\ngmake rsync","category":"page"},{"location":"Build_with_makeup/#More-details-1","page":"Makeup","title":"More details","text":"","category":"section"},{"location":"Build_with_makeup/#Re-running-configure-1","page":"Makeup","title":"Re-running configure","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Afterwards you can rerun configure as many times as you wish.  Please note that the very first time is always slowed (maybe 10 minutes) as interface blocks for arp/ and ald/ projects are generated.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Usually running configure many times is not necessary – not even when you have changed your config-file (!) – except when interface blocks needs to be updated/re-created (-c or -g options). For example, when subroutine/function call argument list has changed. Then the whole config+build sequence can be run under HARMONIE_SRC as follows:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\n# -c option: Check if *some* interface blocks need regeneration and regenerate\r\n$HARMONIE_MAKEUP/configure -c $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\n# -g option: Force to regenerate interface blocks \r\n# $HARMONIE_MAKEUP/configure -g $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\ngmake","category":"page"},{"location":"Build_with_makeup/#Changing-the-number-of-tasks-for-compilation-1","page":"Makeup","title":"Changing the number of tasks for compilation","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The number of tasks used for gmake-compilations is set by default to 8. See NPES parameter in HARMONIE_MAKEUP/defaults.mk To change the default, you can have two choices:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Add NPES to your config-file, for example set it to 2:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\nNPES=2","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Invoke gmake with NPES parameter, e.g. set it to 10:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ngmake NPES=10","category":"page"},{"location":"Build_with_makeup/#Inserting-DRHOOK-for-Meso-projects-1","page":"Makeup","title":"Inserting DRHOOK for Meso-projects","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"To insert DrHook profiling automatically for mpa/ and mse/ projects, reconfigure with -H option:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\n$HARMONIE_MAKEUP/configure -H $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"You can also pick and choose either mpa/ or mse/ projects with -h option (can be supplied several times):","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\n$HARMONIE_MAKEUP/configure -h mpa $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\n$HARMONIE_MAKEUP/configure -h mse $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\n# The following are the same as if the option -H was used\r\n$HARMONIE_MAKEUP/configure -h mpa -h mse -h surfex $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp\r\n$HARMONIE_MAKEUP/configure -h mpa:mse:surfex $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"In the future it may not be necessary to insert DrHook automagically, if the insertion has been  done in the svn (version handling) level.","category":"page"},{"location":"Build_with_makeup/#Speeding-up-compilations-by-use-of-RAM-disk-1","page":"Makeup","title":"Speeding up compilations by use of RAM-disk","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"To further speedup compilation and if you have several GBytes of Linux RAM-disk (/dev/shm) available, do the following:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Create your personal RAM-disk subdirectory and check available disk space","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\nmkdir /dev/shm/$USER\r\ndf -kh /dev/shm/$USER","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Reconfigure with RAM-disk either by defining LIBDISK in your config-file or running","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"cd $HARMONIE_SRC\r\n$HARMONIE_MAKEUP/configure -L /dev/shm/$USER $HARMONIE_MAKEUP/config.FMI.cray_xt5m.pathscale.mpi+openmp","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Also define TMPDIR to point to /dev/shm/USER to allow compiler specific temporary files on RAM-disk","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\n# In ksh/bash-shells:\r\nexport TMPDIR=/dev/shm/$USER\r\ngmake 2>&1 |  tee logfile\r\n# In csh/tcsh-shells:\r\nsetenv TMPDIR /dev/shm/$USER\r\ngmake      |& tee logfile","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Please note that the step-2 creates all libraries AND executablus under the directory pointed by the -L argument. Object files and modules still, however, are placed under corresponding source directories.","category":"page"},{"location":"Build_with_makeup/#What-if-you-run-out-of-RAM-disk-space-?-1","page":"Makeup","title":"What if you run out of RAM-disk space ?","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Sometimes you may find that the disk space becomes limited in /dev/shm/USER. Then you have an option to supply LIBDISK parameter directly to gmake-command without need to reconfigure:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ngmake LIBDISK=`pwd`","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"This usually increases the throughput time as creation of the AROME executable to disk rather than RAM-disk may be 5-10 times slower. But at least you won't run out of disk space.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"","category":"page"},{"location":"Build_with_makeup/#How-is-ODB-related-stuff-handled-?-1","page":"Makeup","title":"How is ODB related stuff handled ?","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The Observational DataBase (ODB) is a complicated beast for good reasons. Unlike any other project, which produce just one library per project, correct use of ODB in variational data assimilation requires several libraries.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The trick to manage this with MAKEUP is to create a bunch of symbolic links pointing to HARMONIE_SRC/odb/ -project directory. There will be one (additional) library for each link. And then we choose carefully the correct subdirectories and source codes therein to be compiled for each library.","category":"page"},{"location":"Build_with_makeup/#Specific-ODB-libraries,-their-meaning-and-the-source-files-included-1","page":"Makeup","title":"Specific ODB-libraries, their meaning & the source files included","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Library Description Source files\nlibodb ODB core library lib/ & aux/ : [a-z].F90 [a-z].c\n  module/ & pandor/module : *.F90\nlibodbport Interface between IFS (ARPEGE/ALADIN/AROME) & ODB cma2odb/ & bufr2odb/ : *.F90\n – also contains BUFR2ODB routines pandor/extrtovs & pandor/fcq & pandor/mandalay : *.F90\nlibodbdummy ODB-related dummies lib/   : [A-Z].F90 [A-Z].c\nlibodbmain ODB tools, main programs (C & Fortran) tools/ : [A-Z]*.F90 *.c *.F\nlibPREODB ERA40 database (not needed, but good for debugging) ddl.PREODB/.sql  , ddl.PREODB/.ddl\nlibCCMA Compressed Central Memory Array database (minimization) ddl.CCMA/.sql    , ddl.CCMA/.ddl\nlibECMA Extended Central Memory Array database (obs. screening) ddl.ECMA/.sql    , ddl.ECMA/.ddl\nlibECMASCR Carbon copy of ECMA for obs. load balancing between PEs ddl.ECMASCR/.sql , ddl.ECMASCR/.ddl","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"From the file HARMONIE_MAKEUP/configure you can also find how different files are nearly hand-picked for particular libraries. Search for block","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\n if [[ \"$d\" = @(odb|odbport|odbdummy|odbmain)]] ; then\r\n     case \"$d\" in\r\n              odb) case \"$i\" in\r\n                   lib|aux)              files=$(\\ls -C1 [a-z]*.F90 [a-z]*.c 2>/dev/null) ;;\r\n                   module|pandor/module) files=$(\\ls -C1 *.F90 2>/dev/null) ;;\r\n                   esac ;;\r\n          odbport) case \"$i\" in\r\n                   cma2odb|bufr2odb)                           files=$(\\ls -C1 *.F90 2>/dev/null) ;;\r\n                   pandor/extrtovs|pandor/fcq|pandor/mandalay) files=$(\\ls -C1 *.F90 2>/dev/null) ;;\r\n                   esac ;;\r\n         odbdummy) [[ \"$i\" != \"lib\"]] || files=$(\\ls -C1 [A-Z]*.F90 [A-Z]*.c 2>/dev/null) ;;\r\n          odbmain) [[ \"$i\" != \"tools\"]] || files=$(\\ls -C1 [A-Z]*.F90 *.c *.F 2>/dev/null) ;;\r\n     esac\r\n elif [[ \"$d\" = @($case_odbs)]] ; then\r\n   [[ \"$i\" != \"ddl.$d\"]] || {\r\n       files=$(\\ls -C1 *.ddl *.sql 2>/dev/null)\r\n       mkdepend=$CMDROOT/sfmakedepend_ODB\r\n   }\r\n else\r\n  ... ","category":"page"},{"location":"Build_with_makeup/#Handling-SQL-query-and-data-layout-files-1","page":"Makeup","title":"Handling SQL-query and data layout files","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"For SQL-query compilations (ODB/SQL queries are translated into C-code for greater performance), odb98.x SQL-compiler executable is also built as a first thing in the MAKEUP process.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Queries and data definition layouts (DDL-files) are always under <database>/ddl.<database>/ directory.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"","category":"page"},{"location":"Build_with_makeup/#Miscellaneous-stuff-1","page":"Makeup","title":"Miscellaneous stuff","text":"","category":"section"},{"location":"Build_with_makeup/#Selective-compilation-1","page":"Makeup","title":"Selective compilation","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"It is very easy to deviate from the generic compilation options for certain source files or even projects. If you want to change compiler option (say) from -O3 to -O2 for routine src/arp/pp_obs/pppmer.F90, you can add the following lines at the end of your config-file:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"pppmer.o: FCFLAGS := $(subst -O3,-O2,$(FCFLAGS))","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"If you want to apply this to all pppmer*.F90-routines, then you need to enter the following \"wildcard\"-sequence:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"pppme%.o: FCFLAGS := $(subst -O3,-O2,$(FCFLAGS))","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Note by the way that for some reason we need to use pppme%.o as the more natural (from Unix) pppmer%.o would choose only routines pppmertl.F90 and pppmerad.F90, not the routine pppmer.F90 at all!","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Applying different compiler flags for project (say) arp only, then one can put the following at the end of config-file:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"ifeq ($(PROJ),arp)\r\n%.o:  FCFLAGS := $(subst -O3,-O2,$(FCFLAGS))\r\nendif","category":"page"},{"location":"Build_with_makeup/#(Re-)building-just-one-project-1","page":"Makeup","title":"(Re-)building just one project","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Sometime you could opt for rebuilding only (say) the xrd-project i.e. libxrd.a. This can be done as follows:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ngmake PROJ=xrd","category":"page"},{"location":"Build_with_makeup/#Cleaning-up-files-1","page":"Makeup","title":"Cleaning up files","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"You can clean up by","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ngmake clean","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"... or selectively just the project arp:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ngmake PROJ=arp clean","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"This clean does not wipe out makefiles i.e. you don't have to rerun configure after this.","category":"page"},{"location":"Build_with_makeup/#Restoring-and-cleaning-up-the-state-of-HARMONIE_SRC-1","page":"Makeup","title":"Restoring and cleaning up the state of $HARMONIE_SRC","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The following command you can run only once before issuing another configure command. It will remove all related object and executable files as well as generated makefiles, logfiles etc. stuff which was generated by MAKEUP's configure :","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ncd $HARMONIE_SRC\r\ngmake veryclean\r\n\r\n# .. or alternatively :\r\n$HARMONIE_MAKEUP/unconfigure","category":"page"},{"location":"Build_with_makeup/#Ignoring-errors-1","page":"Makeup","title":"Ignoring errors","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"Sometimes it is useful to enforce compilations even if one or more routines fail to compile. In such cases recommended syntax is:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ngmake -i\r\n\r\n# or not to mess up the output, use just one process for compilations\r\n\r\ngmake NPES=1 -i","category":"page"},{"location":"Build_with_makeup/#Creating-precompiled-installation-1","page":"Makeup","title":"Creating precompiled installation","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"If you want to provide precompiled libraries, objects, source code to other users so that they do not have to start compilation from scratch, then make a distribution or precompiled installation as follows:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ngmake PRECOMPILED=/a/precompiled/rootdir precompiled","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"After this the stuff you just compiled ends up in directory /a/precompiled/rootdir with two subdirectories : src/ and util/. All executables are currently removed.","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"You can repeat this call, and it will just rsync the modified bits.","category":"page"},{"location":"Build_with_makeup/#Update/check-your-interface-blocks-outside-configure-1","page":"Makeup","title":"Update/check your interface blocks outside configure","text":"","category":"section"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"The configure has options -c or -g to check up or enforce for (re-)creation of interface blocks of projects arp and ald. To avoid full and lengthy configure-run, you can just do the following:","category":"page"},{"location":"Build_with_makeup/#","page":"Makeup","title":"Makeup","text":"#!sh\r\ngmake intfb","category":"page"},{"location":"Build_with_makeup/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Makeup","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PostPP/Fullpos?action=edit\"","category":"page"},{"location":"PostPP/Fullpos/#Postprocessing-with-FULL-POS-1","page":"Fullpos","title":"Postprocessing with FULL-POS","text":"","category":"section"},{"location":"PostPP/Fullpos/#Introduction-1","page":"Fullpos","title":"Introduction","text":"","category":"section"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"FULL-POS is a powerful postprocessing package, which is part of the  common ARPEGE/IFS cycle. FULL-POS is documented by ","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"Yessad (2011): This documentation describes the software FULL-POS doing post-processing on different kind of vertical levels. In particular, post-processable variables and organigramme are given. Some aspects of horizontal and vertical interpolators (which may be used in some other applications) are also described.\nykfpos38.pdf: FULL-POS in cycle 38\nEl Khatib (2002): Older documentation with a link to an old FULL-POS website.","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"FULL-POS is a special configuration (9xx) of the full model for setup and initialization. In other words it is a 0 hour forecast, with extra namelist settings for variables to (post)process and to write out. When generating initial or boundary files we are calling a special configuration of FULL-POS, e927.","category":"page"},{"location":"PostPP/Fullpos/#ecf/config_exp.h-1","page":"Fullpos","title":"ecf/config_exp.h","text":"","category":"section"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"The use of FULL-POS is controlled by the POSTP variable in the [source:Harmonie/ecf/config_exp.h] file:","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"POSTP=\"inline\"                          # Postprocessing by Fullpos (inline|offline|none).\r\n                                        # See Setup_postp.pl for selection of fields.\r\n                                        # inline: this is run inside of the forecast\r\n                                        # offline: this is run in parallel to the forecast in a separate task","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"\"inline\" is the default which means FULL-POS postprocessing is called from the forecast model as it runs. If you select \"offline\" the model is called independently of the running forecast model using the forecast model output files as inputs to be postprocessed. By selecting \"none\" no FULL-POS postprocessing will be carried out.","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"Output frequency by FULL-POS is controlled by PWRITUPTIMES, FPOUTINT and FREQ_RESET:","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"# Postprocessing times (space separated list)\r\nPWRITUPTIMES=\"03 06 09 12 15 18 21 24 30 36 42 48 54 60\"\r\nFPOUTINT=\"-1\"                           # Regular  interval if > 0. Not used if <= 0.\r\n\r\nFREQ_RESET=3                            # Reset frequency of max/min values in hours, controls NRAZTS","category":"page"},{"location":"PostPP/Fullpos/#FULL-POS-1","page":"Fullpos","title":"FULL-POS","text":"","category":"section"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"The use of FULL-POS is controlled by the following namelists: NAMFPPHY, NAMFPDY2, NAMFPDYP, NAMFPDYH, NAMFPDYI, NAMFPDYV, NAMFPDYT and NAMFPDYS. These namelists can be used to make an accurate list of post- processed fields. It is possible to call FULL-POS when running the model. In such a configuration we can configure HARMONIE to write some parameters with a different frequency than the standard historical files produced. ","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"However, with \"inline\" postprocessing, it is possible to get, at each post-processing time step, exactly the fields you wish. In this case, you have to make other namelists file which will contain the selection of the fields you wish to get. First, you have to set in NAMCT0 the variable CNPPATH as the directory where the selection files will be. Under this directory, the name of a selection file must be xxtDDDDHHMM, where DDDDHHMM specifies the date/time of the post-processing time step.","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"The Postpp script executes the \"offline\" FULL-POS postprocessing in HARMONIE system. ","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"The management of FULL-POS and the creation of selection files is made easier for the user by the  Select_postp.pl perl script. ","category":"page"},{"location":"PostPP/Fullpos/#Parameter-selection-1","page":"Fullpos","title":"Parameter selection","text":"","category":"section"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"Some of the more relevant entries in this script:","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"CFP2DF: names of the 2D dynamics fields to be post-processed. Names have at maximum 16 characters. By default CFP2DF contains blanks (no 2D dynamical field to post-process).\nCFP3DF: names of the 3D dynamics fields to be post-processed. Names have at maximum 12 characters. By default CFP3DF contains blanks (no 3D dynamical field to post-process).\nCFPPHY: names of the physical fields to be post-processed. Names have at maximum 16 characters. By default CFPPHY contains blanks (no physical field to post-process). \nCFPXFU:  names of the instantaneous fluxes fields to be post-processed. Names have at maximum 16 characters. By default CFPXFU contains blanks (no instantaneous fluxes field to post-process).\nCFPCFU: names of the cumulated fluxes fields to be post-processed. Names have at maximum 16 characters. By default CFPCFU contains blanks (no cumulated fluxes field to post-process).","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"You can define the levels you wish to output using the following variable:","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"NRFP3S: model levels to postprocess\nRFP3H: height above ground levels to postprocess\nRFP3P: pressure levels to postprocess\nRFP3PV: PV levels to postprocess\nRFP3I: temperature levels to postprocess","category":"page"},{"location":"PostPP/Fullpos/#Add-new-output-1","page":"Fullpos","title":"Add new output","text":"","category":"section"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"This section provides a simple example on how to add a new parameter/vertical level for postprocessing in Select_postp.pl.","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"To add new \"height above ground\" output at 150m to the FULL-POS output, two changes are required:","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"Add the new height, 150., to the RFP3H array\nAdd level array number to the @namfpdyh_lev level selection","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"cd $HOME/hm_home/levexp\r\n$PATH_TO_HARMONIE/config-sh/Harmonie co scr/Select_postp.pl\r\ncp scr/Select_postp.pl scr/Select_postp.pl.ori\r\n### edit scr/Select_postp.pl\r\ndiff scr/Select_postp.pl scr/Select_postp.pl.ori\r\n83c83\r\n<  RFP3H => ['20.','50.','100.','150.','250.','500.','750.','1000.','1250.','1500.','2000.','2500.','3000.'],\r\n---\r\n>  RFP3H => ['20.','50.','100.','250.','500.','750.','1000.','1250.','1500.','2000.','2500.','3000.'],\r\n132c132\r\n<  @namfpdyh_lev = (1,2,3,4,5,6,7,8,9,10,11,12,13) ;\r\n---\r\n>  @namfpdyh_lev = (1,2,3,4,5,6,7,8,9,10,11,12) ;","category":"page"},{"location":"PostPP/Fullpos/#Expert-users-1","page":"Fullpos","title":"Expert users","text":"","category":"section"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"In the FULL-POS namelist NAMFPC (variables explained in yomfpc.F90), the variables are placed into different categories:","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"LFPCAPEX: if true XFU fields used for CAPE and CIN computation (with NFPCAPE).\nLFPMOIS: month allowed for climatology usage:\n.F. => month of the model (forecast).\n.T. => month of the file.\nNFPCLI:  usage level for climatology:\n0: no climatology\n1: orography and land-sea mask of output only\n2: all available climatological fields of the current month\n3: shifting mean from the climatological fields of the current month to the ones of the closest month\nNFPCAPE: kind of computation for CAPE and CIN:\n1 => from bottom model layer\n2 => from the most unstable layer\n3 => from mto standard height (2 meters) as recomputed values\n4 => from mto standard height (2 meters) out of fluxes (for analysis)\nCFPFMT:  format of the output files, can take the following values:\n’MODEL’ for output in spherical harmonics.\n’GAUSS’ for output in grid-point space on Gaussian grid (covering the global sphere).\n’LELAM’ for output on a grid of kind ’ALADIN’ (spectral or grid-point coefficients).\n’LALON’ for a grid of kind \"latitudes * longitudes\".","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"Default is ’GAUSS’ in ARPEGE/IFS, ’LELAM’ in ALADIN.","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"CFPDOM: names of the subdomains. Names have at maximum 7 characters.\nIf CFPFMT=’GAUSS’ or ’LELAM’ only one output domain is allowed.\nIf CFPFMT=’LALON’ the maximum of output subdomains allowed is 10.\nBy default, one output domain is requested, CFPDOM(1)=’000’ and CFPDOM(i)=’’ for i>1.\nLREADMODEL_DATE:  if: .TRUE. read date from the model","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"The default FA-names for parameters in different categories can be found from suafn1.F90.","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"It's worth mentioning some of the variables postprocessed by FULL-POS","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"True vertical velocity w VW.\nPotential vorticity P V [PV].\nPressure coordinate vertical velocity ω [VV].\nEta coordinate vertical velocity η [ETAD].\nAbsolute vorticity ζ + f [ABS].\nRelative vorticity ζ [VOR].\nDivergence D [DIV].\nSatellite equivalents\nMSAT7 MVIRI channels 1 and 2 ([MSAT7C1] and [MSAT7C2]).\nMSAT8 MVIRI channels 1 to 8 ([MSAT8C1] to [MSAT8C8]).\nMSAT9 MVIRI channels 1 to 8 ([MSAT9C1] to [MSAT9C8]).\nGOES11 IMAGER channels 1 to 4 ([GOES11C1] to [GOES11C4]).\nGOES12 IMAGER channels 1 to 4 ([GOES12C1] to [GOES12C4]).\nMTSAT1 IMAGER channels 1 to 4 ([MTSAT1C1] to [MTSAT1C4]).","category":"page"},{"location":"PostPP/Fullpos/#Problems-1","page":"Fullpos","title":"Problems","text":"","category":"section"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"Problems may be encountered with FULL-POS when running on large domains. Here are some things to look out for:","category":"page"},{"location":"PostPP/Fullpos/#","page":"Fullpos","title":"Fullpos","text":"Increase the MBX_SIZE if you run out of MPI buffer space. \nIncrease number of cores if you run out of memory.\nMake sure NFPROMA and NFPROMA_DEP are small and equal to NPROMA.\nSet NSTRIN=NSTROUT=NPROC in nampar0 if one of the above mentioned doesn't help.","category":"page"},{"location":"PostPP/Fullpos/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../../HarmonieSystemDocumentation.md)-1","page":"Fullpos","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"ObservationPreprocessing/ObservationData/#","page":"Observation data","title":"Observation data","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ObservationPreprocessing/ObservationData?action=edit\"","category":"page"},{"location":"ObservationPreprocessing/ObservationData/#Observation-data-1","page":"Observation data","title":"Observation data","text":"","category":"section"},{"location":"ObservationPreprocessing/ObservationData/#","page":"Observation data","title":"Observation data","text":"In off-line experiments the Prepare_ob script extracts observations from a data archive, e.g from MARS archive at ECMWF platform, or from existing observation files available locally.","category":"page"},{"location":"ObservationPreprocessing/ObservationData/#ECMWF-1","page":"Observation data","title":"ECMWF","text":"","category":"section"},{"location":"ObservationPreprocessing/ObservationData/#","page":"Observation data","title":"Observation data","text":"At ECMWF, the HARMONIE script [prepares the retrieval (retrin) file for MARS request. source:Harmonie/scr/WriteMARSreq is executed by [source:Harmonie/scr/Prepare_ob].","category":"page"},{"location":"ObservationPreprocessing/ObservationData/#","page":"Observation data","title":"Observation data","text":"    WriteMARSreq -d $DATE -t $TIME -r $RANGE -o $OBSLIST -m ./retrin -z $BUFRFILE -g $GEOL","category":"page"},{"location":"ObservationPreprocessing/ObservationData/#","page":"Observation data","title":"Observation data","text":"The variables above denote","category":"page"},{"location":"ObservationPreprocessing/ObservationData/#","page":"Observation data","title":"Observation data","text":"DATE - analysis date\nTIME - analysis time\nRANGE - extraction time interval\nOBSLIST - list of the observations to be extracted according to MARS definition; \nBUFRFILE - name of the extracted BUFR file\nGEOL - Extraction of the model domain properties from the climate file as follows","category":"page"},{"location":"ObservationPreprocessing/ObservationData/#","page":"Observation data","title":"Observation data","text":"  $BINDIR/domain_prop $CLIMDIR/m$MM -f -MAX_EXT > foo\r\n     EASTEC=$( tail -1 foo | head -1 | sed 's/ //g' )\r\n     NORTHEC=$( tail -2 foo | head -1 | sed 's/ //g' )\r\n     WESTEC=$( tail -3 foo | head -1 | sed 's/ //g' )\r\n     SOUTHEC=$( tail -4 foo | head -1 | sed 's/ //g' )","category":"page"},{"location":"ObservationPreprocessing/ObservationData/#LOCAL-1","page":"Observation data","title":"LOCAL","text":"","category":"section"},{"location":"ObservationPreprocessing/ObservationData/#","page":"Observation data","title":"Observation data","text":"Otherwise, this step consists of fetching (or waiting for) the observations stored in OBDIR defined in ecfconfig_exph  In that case one can use the command cat to merge different observations into one BUFR file ob{DTG}. In general, HIRLAM services are adopting SAPP, ECMWF's scalable acquisition and pre-processing system, to process (conventional) GTS reports and other observational data for use in operational NWP. SAPP produces BUFR encoded in the same way as observational BUFR data available in the MARS archive.","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PostPP/Extract4verification?action=edit\"","category":"page"},{"location":"PostPP/Extract4verification/#Verification-preparation-1","page":"-","title":"Verification preparation","text":"","category":"section"},{"location":"PostPP/Extract4verification/#Introduction-1","page":"-","title":"Introduction","text":"","category":"section"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"Before we can run the verification we need to extract data for each geographical point and produce files in a format that the verification program can use. In HARMONIE there are two programs, one fore extracting model data (fldextrgribapi) and one for observations ( obsextr ). Both are part of the glgribapi package. ","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"fldextr is capable of extracting data from several sources (HARMONIE/HIRLAM/IFS and produces so called vfld-files in ASCII format. The main tasks of the program is to:","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"Recalculates rh,td to be over water\nInterpolates to geographical points according to a synop.list and temp.list\nDoes MSLP,RH2M,TD2M calculations if the are not available in the input file\nOptional fraction of land check.\nInterpolates to pressure levels for TEMP data.","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"obsextr extracts conventional observations from BUFR data and creates a vobs file similar to the vfld file. It:","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"Reads SYNOP and TEMP\nLUSE_LIST controls the usage of a station list","category":"page"},{"location":"PostPP/Extract4verification/#Station-lists-used-by-verification-1","page":"-","title":"Station lists used by verification","text":"","category":"section"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"Fldextr links  synop.list to HM_LIB/util/glgribapi/scr/allsynop.list  and temp.list to HM_LIB/util/glgribapi/scr/alltemp.list. These station lists are based on information in WMO's ''Publication No. 9, Volume A, Observing Stations  and WMO Catalogue of Radiosondes. This is regularly updated by the WMO. allsynop.list and alltemp.list are updated less frequently. There is also scope to include local stations in these lists that are not included in WMO'sPublication No. 9''. The following 7-digit station identifiers are available to HIRLAM countries:","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"Norway !1000000 - !1099999\nSweden !2000000 - !2099999\nEstonia !2600000 - !2649999\nLithuania !2650000 - !2699999\nFinland !2700000 - !2799999\nIreland !3900000 - !3900000\nIceland !4000000 - !4099999\nGreenland !4200000 - !4299999\nDenmark !6000000 - !6999999\nNetherlands !6200000 - !6299999\nSpain !8000000 - !8099999","category":"page"},{"location":"PostPP/Extract4verification/#Field-extraction-1","page":"-","title":"Field extraction","text":"","category":"section"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"Fldextr. This script goes through all forecast files and  collects all the variables (T2m, V10m, mean sea level pressure, RH2m, Q2m, total cloudiness, precipitation + profiles)  needed in basic verification.","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"Input parameters: none.\nData: Forecast files.\nNamelists: Station lists for surface data (ewglam.list) and radiosounding data (temp.list).\nExecutables: fldextr.\nOutput: Field extraction files (vfldEXP{DTG}), which are placed in EXTRARCH.","category":"page"},{"location":"PostPP/Extract4verification/#Extract-observations-1","page":"-","title":"Extract observations","text":"","category":"section"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"FetchOBS scripts takes care of the observation  extraction for verification. First, the observation BUFR-file is fetched from the MARS (ExtractVEROBSfromMARS),  then all the needed data is extracted from the BUFR-files.","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"Input parameters: none.  \nData:  Station lists for surface data (ewglam.list) and radiosounding data (temp.list). These shoud be found from SCRDIR  \nExecutables: mars, obsextr.  \nOutput: Field extraction files (vobs), which are placed in *EXTRARCH.","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"For the continuous monitoring on hirlam.org the most recent data are kept online at ECMWF under ecgb:/scratch/ms/dk/nhz/OBS.","category":"page"},{"location":"PostPP/Extract4verification/#A-general-input-format-1","page":"-","title":"A general input format","text":"","category":"section"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"The file format for verification is a simple ascii file with a header that allows an arbitrary number of different types of point data to be included in the model vfld- or observation vobs- files.","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"The generalized input format is defined as ","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"nstation_synop nstation_temp version_flag  # written in fortran format '(1x,3I6)' )\r\n# where version_flag == 4\r\n# If ( nstation_synop > 0 ) we read the variables in the file, their descriptors and\r\n# their accumulation time\r\n#\r\nnvar_synop\r\nDESC_1 ACC_TIME_1\r\n...\r\nDESC_nvar_synop ACC_TIME_nvar_synop\r\n# Station information and data N=nstation_synop times\r\nstid_1 lat lon hgt val(1:nvar_synop)\r\n...\r\nstid_N lat lon hgt val(1:nvar_synop)\r\n\r\n# If ( nstation_temp > 0 )\r\nnlev_temp\r\nnvar_temp\r\nDESC_1 ACC_TIME_1\r\n..\r\nDESC_nvar_temp ACC_TIME_nvar_temp\r\n# Station information and data nstation_temp times\r\n# and station data nlev_temp times for each station\r\nstid_1 lat lon hgt\r\npressure(1) val(1:nvar_temp)\r\n...\r\npressure(nlev_temp) val(1:nvar_temp)\r\nstid_2 lat lon hgt\r\n...","category":"page"},{"location":"PostPP/Extract4verification/#","page":"-","title":"-","text":"The accumulation time allows us to e.g. easily include different precipitation accumulation intervals.","category":"page"},{"location":"PostPP/Extract4verification/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../../HarmonieSystemDocumentation.md)-1","page":"-","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PostPP/Obsmon?action=edit\"","category":"page"},{"location":"PostPP/Obsmon/#OBSMON-1","page":"Obsmon","title":"OBSMON","text":"","category":"section"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"In 2014 a new version of the observational monitoring system entered trunk. The first official release containing obsmon was cy38h1.2","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"The obsmon package consists of two components. The first is a fortran-based code that is run, for all the active observations types (defined in scr/include.ass), at the post-processing stage of an experiment. It generates statistics from the ODB and store data in three SQLite tables (ECMA/CCMA/ECMA_SFC(CANARI)). In addition the SQLite tables are concatenated in tables in the /ts directory at the end of the run.","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"The second component is written in R using the Shiny web application framework. It allows the interactive visualization of the data contained in the SQLite tables produced by the first component of the package. This can be done either offline or via a server daemon (e.g. shiny.hirlam.org).","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"For disambiguation, we will hereinafter use the terms \"backend\" and \"frontend\" to refer to the first and second components of obsmon, respectively.","category":"page"},{"location":"PostPP/Obsmon/#How-to-turn-on-backend-obsmon?-1","page":"Obsmon","title":"How to turn on backend obsmon?","text":"","category":"section"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"Obsmon is enabled by default in ecf/config_exp.h  vi OBSMONITOR=obstat","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"NB1! If you don't have any log-files from the monitoring experiment, you should disable plotlog from the OBSMONITOR= string in ecf/config_exp.h  NB2! Make sure that the -DODBMONITOR pre-processor flag is active during compilation of util/monitor. This should only be an issue on untested platforms and is by default enabled on ECMWF.","category":"page"},{"location":"PostPP/Obsmon/#How-to-create-statistics-and-SQLite-tables-offline/stand-alone:-1","page":"Obsmon","title":"How to create statistics and SQLite tables offline/stand-alone:","text":"","category":"section"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"If you are running a normal harmonie experiment with the OBSMONITOR=obstat active, the following step is not relevant.","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"Two new actions are implemented in the Harmonie script. Instead of start you can write obsmon and instead of prod you can write obsmonprod. This will use the correct definition file and only do post-processing. If you have your ODB files in another experiment you can add the variable OBSMONEXPARCHIVEROOT to point to the archive directory in the experiment you are monitoring. This approach is used in the operational MetCoOp runs. If you set OBSMONEXP=label the runs will be stored in EXTRARCH/label/. This way you can use the same experiment to monitor all other experiments. The experiements do not need to belong to you as long as you have reading permissions to the experiment. ","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"1. as start:\r\n${HM_REV}/config-sh/Harmonie obsmon DTG=YYYYMMDDHH DTGEND=YYYYMMDDHH OBSMON_EXP_ARCHIVE_ROOT=PATH-TO-ARCHIVE-DIRECTORY-TO-MONITOR OBSMON_EXP=MY-LABEL","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"2. as prod:\r\n${HM_REV}/config-sh/Harmonie obsmonprod DTGEND=YYYYMMDDHH OBSMON_EXP_ARCHIVE_ROOT=PATH-TO-ARCHIVE-DIRECTORY-TO-MONITOR OBSMON_EXP=MY-LABEL","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"If you want to monitor an experiment stored on ECFS, you should specify OBSMONEXPARCHIVE_ROOT with the full address (ectmp:/USER or ecUSER/...) e.g. ","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"OBSMON_EXP_ARCHIVE_ROOT=ectmp:/$USER/harmonie/MY-EXP OBSMON_EXP=MY-LABEL","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"You can also monitor other users experiments as long as you have read-access to the data.","category":"page"},{"location":"PostPP/Obsmon/#How-to-visualize-the-SQLite-tables-using-frontend-obsmon:-1","page":"Obsmon","title":"How to visualize the SQLite tables using frontend obsmon:","text":"","category":"section"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"Download the code from its git repo at hirlam.org:","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"git clone https://git.hirlam.org/Obsmon obsmon","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"Instructions on how to install, configure and run the code can be found in the file docs/obsmon_documentation.pdf that is shipped with the code.","category":"page"},{"location":"PostPP/Obsmon/#How-to-extend-backend-obsmon-with-new-observation-types-1","page":"Obsmon","title":"How to extend backend obsmon with new observation types","text":"","category":"section"},{"location":"PostPP/Obsmon/#Step-1:-Extract-statistics-from-ODB-1","page":"Obsmon","title":"Step 1: Extract statistics from ODB","text":"","category":"section"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"In the scripts you must enable monitoring of your observation type. Each observation type is monitored if active in:","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"msms/harmonie.tdf","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"The script which calls the obsmon binary, is:","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"scr/obsmon_stat","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"This script set the correct namelist based on how you define your observation below. ","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"After the information is extracted, the different SQLite bases are gathered into one big SQLite file in the script:","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"scr/obsmon_link_stat","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"The observation types which the above script is gathering is defined in obtypes in this script:","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"util/monitor/scr/monitor.inc","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"Then let us introduce the new observation in the obsmon binary. The source code is in ","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"harmonie/util/monitor","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"There are two modules controlling the extraction from ODB:","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"mod/module_obstypes.f90\r\nmod/module_obsmon.F90","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"The first routine defines and initializes the observation type you want to monitor. The second calls the intialization defined in the first file. The important steps are to introduce namelist variables and a meaningful definition in the initialization of the observation type.","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"The real extraction from ODB is done in","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"cmastat/odb_extract.f90","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"At the moment there are two different SQL files used, one for conventional and one for satelites. E.g. radar is handled as TEMP/AIRCRAFT.","category":"page"},{"location":"PostPP/Obsmon/#Step-2:-Visualize-the-new-observation-in-shiny-(frontend-obsmon)-1","page":"Obsmon","title":"Step 2: Visualize the new observation in shiny (frontend obsmon)","text":"","category":"section"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"The logics of which observation type to display is defined in:","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"src/observation_definitions.R","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"In case of a new plot added, the plotting is defined in the files under:","category":"page"},{"location":"PostPP/Obsmon/#","page":"Obsmon","title":"Obsmon","text":"src/plots","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Fast_start_on_cca?action=edit\"","category":"page"},{"location":"Fast_start_on_cca/#Configure-for-faster-setup-on-cca-1","page":"Fast start on cca","title":"Configure for faster setup on cca","text":"","category":"section"},{"location":"Fast_start_on_cca/#Background-1","page":"Fast start on cca","title":"Background","text":"","category":"section"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"Since ECMWF switched from the IBM based c2a to the new Cray XC30 cca setting up and start a new HARMONIE experiment has been a very slow process. With the current settings it may take several hours from the moment you say Harmonie start until the code is fully compiled and the real run starts. In the following we describe how to configure your experiment to get started in about half an hour.","category":"page"},{"location":"Fast_start_on_cca/#What's-special-with-cca?-1","page":"Fast start on cca","title":"What's special with cca?","text":"","category":"section"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"The main cause for the slow synchronization and compilation time on cca is the Lustre file system. Such a file system is optimized for large files but is less efficient for large numbers of small files. As a comparison it takes ~2 minutes to copy the full harmonie system from ecgb:$HOME to $PERM whereas it takes about 1 hour or more to make the same copy to cca:$SCRATCH. It's not the transfer to cca that takes time but the IO on the $SCRATCH file system.","category":"page"},{"location":"Fast_start_on_cca/#How-to-set-it-all-up-1","page":"Fast start on cca","title":"How to set it all up","text":"","category":"section"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"The changes required can be viewed in [13814] and in below we go through what you have to do as a user. At the bottom of the page you'll find the versions adapted so far.","category":"page"},{"location":"Fast_start_on_cca/#Using-the-:PERM-disk-1","page":"Fast start on cca","title":"Using the PERM disk","text":"","category":"section"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"Normally HARMONIE is setup to use $SCRATCH as the main disk for both ecgb and cca. Two changes are required in Env_system to use the $PERM disk on cca.","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"Set HM_LIB=/hpc$PERM/build_harmonie/$EXP/lib for the ecgb part of Env_system\nSet HM_LIB=$PERM/build_harmonie/$EXP/lib for the cca part of Env_system","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"This means that ecgb:$HM_LIB == cca:$HM_LIB so the synchronization between ecgb and cca is for free. Your working directories and results will still be found under $SCRATCH/hm_home/$EXP.","category":"page"},{"location":"Fast_start_on_cca/#Compiling-with-gmkpack-1","page":"Fast start on cca","title":"Compiling with gmkpack","text":"","category":"section"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"Harmonie comes with two way of compiling the code, Makeup and Gmkpack. Both methods have their benefits but in this particular case Gmkpack gives us the fastest throughput for two reasons.","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"We only compile the source you have changed for the rest we reuse the already built libraries. This is partly true for Makeup as well but in the search for what to actually compile takes longer time.\nLess disk space and number of inodes is required compared to Makeup. We only copy the code to be compiled.","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"The above mentioned is only true if you make small changes for larger number of changes that requires recompilation of big parts of the code it may not necessary be true any longer. To compile with gmkpack set","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"MAKEUP=no in Env_system\nMake sure BUILD_ROOTPACK=no in ecf/config_exp.h. The already compiled libraries are listed below. If you have to compile the full code Makeup is faster.","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"The reproducibility between compilation with Makeup and gmkpack has not been checked yet although great care has been taken to use the same compilation options. To avoid unpleasant surprises you are not recommended to change compilation method between to experiments that you expect to compare.","category":"page"},{"location":"Fast_start_on_cca/#Things-to-keep-an-eye-on-1","page":"Fast start on cca","title":"Things to keep an eye on","text":"","category":"section"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"The disk space on cca:$PERM is limited not only for the disk space in GB but also for the number of files, the inodes. A typical experiment takes 2.5GB and uses 10000 inodes. Thus the number of experiments you can setup this ways is limited. To check your quota on cca:$PERM type","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"quota -v","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"on cca.","category":"page"},{"location":"Fast_start_on_cca/#What-about-existing-experiments?-1","page":"Fast start on cca","title":"What about existing experiments?","text":"","category":"section"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"There is not a great need to change your setup if you have a running experiment. The costly part is the initial setup and compilation. If you still feel you would like to do it you are advised to remove everything from cca:$SCRATCH/hm_home/$EXP and ecgb:$SCRATCH/hm_home/$EXP after you have checked that the necessary restart files are available on ecfs. The other alternative is to start a new experiment with the same changes and make sure you start with initial conditions from your old experiment.","category":"page"},{"location":"Fast_start_on_cca/#Updated-HARMONIE-configurations-1","page":"Fast start on cca","title":"Updated HARMONIE configurations","text":"","category":"section"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"The changes will progressively be implemented in the used configurations as listed below. If you miss any configuration please contact us. Note that the default settings will not be changed for the tagged versions. Note that for the trunk or for branches a new ROOTPACK is required for every update in the src directory and that the new ROOTPACK may not always be available.","category":"page"},{"location":"Fast_start_on_cca/#","page":"Fast start on cca","title":"Fast start on cca","text":"\r\n  harmonie-38h1\r\n\r\n   tags:\r\n\r\n   ~hlam/harmonie_release/tags/harmonie-38h1.1 ROOTPACK=/project/hirlam/harmonie/pack/38h1_main.01.gnu.x\r\n   ~hlam/harmonie_release/tags/harmonie-38h1.2 ROOTPACK=/project/hirlam/harmonie/pack/38h1_main.02.gnu.x\r\n\r\n   branches:\r\n\r\n   ~hlam/harmonie_release/branches/harmonie-38h1 ROOTPACK=/scratch/ms/spsehlam/hlam/common_rootpack/38h1_branch_harmonie_38h1_13749.01.gnu.x\r\n   ~hlam/harmonie_release/branches/harmonEPS-38h1.1 ROOTPACK=/project/harmonie/pack/38h1_harmonEPS_13706.01.gnu.x\r\n                                                    ROOTPACK=/project/harmonie/pack/38h1_harmonEPS_13827.01.gnu.x\r\n\r\n  harmonie-40h1\r\n\r\n   tags:\r\n   ~hlam/harmonie_release/tags/harmonie-40h1.1.beta.1 ROOTPACK=/project/hirlam/harmonie/pack/40h1_beta_1.01.gnu.x\r\n\r\n   branches:\r\n\r\n   ~hlam/harmonie_release/trunk ROOTPACK=/scratch/ms/spsehlam/hlam/common_rootpack/40h1_trunk_NNNNN.01.gnu.x\r\n\r\n","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Namelists?action=edit\"","category":"page"},{"location":"Namelists/#Controlling-the-namelists-in-HARMONIE-1","page":"Namelist","title":"Controlling the namelists in HARMONIE","text":"","category":"section"},{"location":"Namelists/#Introduction-1","page":"Namelist","title":"Introduction","text":"","category":"section"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"IFS is largely driven by namelists and has thousands of options. For each configuration a number of namelists controlling different parts are read. To make the maintenance of the namelists manageable and to assure consistency in terms on e.g. name conventions for fields, packing accuracy, physics settings and parallel options all namelists are generated as they are needed during the run. All the basic settings are defined in a perl dictionary harmone_namelists.pm for IFS and surfex_namelists.pm and surfexselectedoutput.pm for SURFEX. There is a preliminary work on commenting the reference namelist model forecast settings and surfex reference namelist settings. In future versions the commented namelists will be included and maintained as part of the code.   The IFS dictionary is structured in several sections:","category":"page"},{"location":"Namelists/#harmone_namelists.pm-1","page":"Namelist","title":"harmone_namelists.pm","text":"","category":"section"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Global settings\nTechnical settings\nHost specific settings\nMPP options\nFile settings","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"DYNAMICS SETTINGS\nMain dynamics switches\nNon-hydrostatic settings\nVertical finite element\nDFI","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Main physics options. NB! These may contain switches for dynamics as well\nALADIN\nAROME\nEDMFM switches, to be applied after AROME\nAlaro\nOld surface\nSURFEX\nDDH","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"E927 Interpolation settings\nMain fullpos settings\nE927\nE927 nh\nSURFEX initial file generation\nAladin e927\nALARO e927\nArome e927","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"General postprocessing switches \nDefault fullpos settings\nNH postprocessing\nSwitches for postprocessing with surfex\nSpecial cases for arome","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Assimilation\nCanari\nArome canari\nVarbc_rad\nVarbc_coldstart\nScreening\nArome screening\nAlaro screening\nMinimization  *Alaro minimization\n4DVAR \n4DVAR minimization\n4DVAR screening\n4DVAR trajectory","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Climate generation\nClimate generations (e923)","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Misc\nGeneral namelist settings for Tangent-Linear and Adjoint tests \nExtra Adjoint test options \nOulan\nBator","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"The final namelists are build through the rules given in Get_namelist and are generated by gen_namelists.pl. Note that in several cases environment variables are still parsed in the scripts.","category":"page"},{"location":"Namelists/#surfex_namelists.pm-1","page":"Namelist","title":"surfex_namelists.pm","text":"","category":"section"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"All possible SURFEX namelist setting are documented at the SURFEX web site. Use the search text area in the upper right corner to search for a specific namelist or namelist option. Please, keep in mind that the SURFEX web site documents the latest SURFEX version, i.e. SURFEXv8, while in cy40h SURFEXv7.3 is used. Therefore, some of the settings may be different or not available.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#PGD-1","page":"Namelist","title":"PGD","text":"","category":"section"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"PGD represents in general the preparation of physiography data. The default PGD settings are listed here. Some modifications can be done for specific model configurations and will be specified as e.g. alaro_pgd or arome_pgd.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"# 2 layer ISBA scheme\r\n%isba_2L=(\r\n NAM_ISBA=>{\r\n  CISBA          => '\"2-L\",',\r\n  NGROUND_LAYER  => '2,',\r\n },\r\n);\r\n\r\n# 3 layer ISBA scheme\r\n%isba_3L=(\r\n NAM_ISBA=>{\r\n  CISBA          => '\"3-L\",',\r\n  NGROUND_LAYER  => '3,',\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"The section used here is decided by setting CISBA=\"3-L\" (default) in config_exp.h.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%isba_pgd=(\r\n NAM_ISBA=>{\r\n   YCLAY         => 'YCLAY,',\r\n   YCLAYFILETYPE => '\"DIRECT\",' ,\r\n   YSAND         => 'YSAND,',\r\n   YSANDFILETYPE => '\"DIRECT\",'\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"The clay/sand used is decided by setting SOIL_TEXTURE_VERSION=FAO (default) in config_exp.h. \"FAO\" corresponds to 10 km resolution clay/sand according to SURFEX Soil texture description. The 1 km HWSD_v2 is not used by default since is shows strange vales over Scandinavia.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%pgd=(\r\n NAM_IO_OFFLINE=>{\r\n  CSURF_FILETYPE => 'CSURF_FILETYPE,',\r\n   CPGDFILE      => 'CPGDFILE,',\r\n },\r\n NAM_PGD_GRID=>{\r\n   CGRID         => '\"CONF PROJ\",',\r\n },\r\n NAM_CONF_PROJ=>{\r\n   XLAT0         => $ENV{LAT0},\r\n   XLON0         => $ENV{LON0},\r\n   XRPK          => $ENV{SINLAT0},\r\n   XBETA         => 0.0,\r\n },\r\n NAM_CONF_PROJ_GRID=>{\r\n   XLATCEN       => $ENV{LATC},\r\n   XLONCEN       => $ENV{LONC},\r\n   NIMAX         => 'BNIMAX,',\r\n   NJMAX         => 'BNJMAX,',\r\n   XDX           => 'BXDX,', \r\n   XDY           => 'BXDY,',\r\n },\r\n NAM_COVER=> {\r\n   YCOVER        => 'YCOVER,',\r\n   YCOVERFILETYPE=> '\"DIRECT\",',\r\n },\r\n NAM_ZS=>{\r\n   YZS           => 'YTOPO,',\r\n   YZSFILETYPE   => '\"DIRECT\",',\r\n },\r\n NAM_SEABATHY=>{\r\n   XUNIF_SEABATHY=>'0.,', \r\n },\r\n NAM_PGD_SCHEMES=>{\r\n    CNATURE => '\"ISBA \",',\r\n    CSEA    => '\"SEAFLX\",',\r\n    CWATER  => '\"WATFLX\",',\r\n    CTOWN   => '\"TEB \",',\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Most options here are specified in different scripts and are normally not supposed to be modified. Exceptions are e.g.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"ECOCLIMAP version used (YCOVER) is decided by setting ECOCLIMAP_VERSION=2.2 (default) in config_exp.h. Available ECOCLIMAP versions provided via the SURFEX team are documented in SURFEX Land use description. Some of these can be available on your system, see your $HM_CLDATA setting.\nOrography version used (YTOPO) is decided by setting TOPO_SOURCE=gmted2010 (default) in config_exp.h.","category":"page"},{"location":"Namelists/#PREP-1","page":"Namelist","title":"PREP","text":"","category":"section"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"PREP represents in general initialisation of prognostic variables. The default PREP settings are listed here. Some modifications can be done for specific model configurations and will be specified as e.g. alaro_prep or arome_prep.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%sice_prep=(\r\n NAM_SEAFLUXn=>{\r\n    LHANDLE_SIC            =>'.TRUE.,',\r\n    LSIC_FROM_FILE         =>'.TRUE.,',\r\n    CSEA_ICE               =>'\"SICE\",',\r\n    NICE_LAYER             =>'4,',\r\n },\r\n NAM_PREP_SEAFLUX=>{\r\n    CFILE_SIC           =>'\"CFILE_SIC\",',\r\n    CTYPE_SIC           =>'\"GRIB  \"',\r\n },\r\n NAM_SIMPLE_ICE=>{\r\n    XICE_THICKNESS      =>'.75,',\r\n    LICE_HAS_SNOW       =>'.FALSE.,',\r\n    CICE_SNOW           =>'\"S-D\",',\r\n    NICE_SNOW_NLAYERS   =>'4,',\r\n    XICE_SNOW_HEIGHT    =>'.3,',\r\n    LSIC_DRIVEN_THICKNESS=>'.FALSE.',\r\n    XSIC_DRIVEN_MAX_THICKNESS=>'1.',\r\n },\r\n NAM_PREP_SIMPLE_ICE=>{\r\n    LINIT_FROM_SST => '.TRUE.,',\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"CSEA_ICE : selects preferred sea ice scheme.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"'NONE' – use default SURFEX ICEFLUX diagnostic scheme\\  'SICE' – use SICE","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"LHANDLE_SIC : activates ice fraction handling\nLSICFROMFILE : ice fraction data from an external source","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":".TRUE. – use the externally provided ice fraction data\\\n.FALSE. – assume that ice fraction data is encoded within SST field","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"NICELAYER : number of ice layers (2 < NICELAYER < 100)","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"CFILE_SIC : external data file that stores ice fraction data\nCTYPE_SIC : type of external data source","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"XICE_THICKNESS : uniform thickness of the ice field\nLICEHASSNOW : snow upon the ice","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":".TRUE. – preform snow-enabled run\\\n.FALSE. – use bare ice configuration","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"CICE_SNOW : snow scheme that used to parametrize snow upon the ice","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"'S-D' – test heat diffusion scheme\\\n> NICESNOWNLAYERS : number of snow layers for S-D snow scheme\\\n> XICESNOWHEIGHT : thickness of snow pack for S-D snow scheme\\\n'3-L' – use 3-L explicit snow scheme ","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"LSICDRIVENTHICKNESS : use ice fraction to estimate ice thickness. Untested, should be set to .FALSE.\nXSICDRIVENMAXTHICKNESS : unused if `LSICDRIVEN_THICKNESS == .FALSE.`","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"LINITFROMSST : use composite SST/SIST field to initialize sea ice temperatures","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"This part represents settings connected to the Simple Sea-ice Scheme (SICE) by Yurii Batrak. Please note that SICE is not yet an official contribution to SURFEX and therefore you will not find any documentation of SICE via the SURFEX web site. ","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%isba_prep=(\r\n NAM_PREP_ISBA=>{\r\n   LISBA_CANOPY  => '.TRUE.,',\r\n   LEXTRAP_TG    => '.TRUE.,',\r\n   LEXTRAP_WG    => '.TRUE.,',\r\n   LEXTRAP_WGI   => '.TRUE.,',\r\n   LEXTRAP_SN    => '.TRUE.,',\r\n   NDIM_EXTRAP   => '20,',\r\n },\r\n NAM_PREP_ISBA_SNOW=>{\r\n   LSWEMAX       => '.TRUE.,',\r\n },\r\n NAM_DIAG_ISBAn=>{\r\n   LPATCH_BUDGET=>'.TRUE.,',\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"LISBA_CANOPY : activates surface boundary multi layer scheme over vegetation\nLEXTRAP_XX : extrapolate XX points where LSM < 0.5 (buffer only)\nNDIM_EXTRAP : Size of search domain for extrapolation (not in official SURFEX)\nLSWEMAX : logical switch to set an upper limit on initial snow water equivalent (set by XSWEMAX (=500 kg/m2 default) ).","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%fullpos_prep=(\r\n NAM_FILE_NAMES=>{\r\n   HPGDFILE      =>'\"PGDFILE\",',\r\n   CINIFILE      =>'\"SURFXINI\",',\r\n },\r\n);\r\n\r\n%offline_prep=(\r\n NAM_IO_OFFLINE=>{\r\n   CSURF_FILETYPE       => '\"LFI   \",',\r\n   CPREPFILE            => '\"SURFXINI\",',\r\n   CPGDFILE             => '\"PGD\",',\r\n },\r\n NAM_PREP_SURF_ATM=>{\r\n   CFILEPGD      =>'\"PGD_host\",',\r\n   CFILEPGDTYPE  =>'\"LFI\",',\r\n   CFILE      =>'\"INFILE\",',\r\n   CFILETYPE  =>'CFILETYPE,',\r\n   NYEAR      =>'NYEAR,',\r\n   NMONTH     =>'NMONTH,',\r\n   NDAY       =>'NDAY,',\r\n   XTIME      =>'XTIME,',\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Most options here are specified in different scripts and are normally not supposed to be modified.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%arome_prep=(\r\n NAM_PREP_SEAFLUX=>{\r\n   LSEA_SBL     => '.FALSE.,',\r\n },\r\n NAM_SEAFLUXn=>{\r\n    CSEA_ICE               =>'\"NONE\",',\r\n    LHANDLE_SIC            =>'.FALSE.,',\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Please note these special settings for the AROME model configuration.","category":"page"},{"location":"Namelists/#FORECAST-1","page":"Namelist","title":"FORECAST","text":"","category":"section"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"FORECAST represents in general the namelist settings used during Forecast. The default FORECAST settings are listed here. Some modifications can be done for specific model configurations and will be specified as e.g. alaro_forecast or arome_forecast.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%sice_forecast=(\r\n NAM_SEAFLUXn=>{\r\n    LHANDLE_SIC            =>'.TRUE.,',\r\n    LSIC_FROM_FILE         =>'.TRUE.,',\r\n    CSEA_ICE               =>'\"SICE\",',\r\n    NICE_LAYER             =>'4,',\r\n },\r\n NAM_SIMPLE_ICE=>{\r\n    XICE_THICKNESS            => '.75,',\r\n    LICE_HAS_SNOW             => '.FALSE.,',\r\n    CICE_SNOW                 => '\"S-D\",',\r\n    NICE_SNOW_NLAYERS         => '4,',\r\n    XICE_SNOW_HEIGHT          => '.3,',\r\n    LSIC_DRIVEN_THICKNESS     => '.FALSE.',\r\n    XSIC_DRIVEN_MAX_THICKNESS => '1.',\r\n },\r\n NAM_DIAG_SURFn=>{\r\n   LCOEF             => '.TRUE.,',\r\n   LSURF_VARS        => '.TRUE.,',\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"This part represents settings connected to the Simple Sea-ice Scheme (SICE) by Yurii Batrak. Please note that SICE is not yet an official contribution to SURFEX and therefore you will not find any documentation of SICE via the SURFEX web site.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%isba_forecast=(\r\n NAM_ISBAn=>{\r\n   CROUGH        => '\"NONE\",',\r\n },\r\n NAM_DIAG_ISBAn=>{\r\n   LPGD     => '.TRUE.,',\r\n   LSURF_MISC_BUDGET=> '.TRUE.,',\r\n },\r\n);\r\n\r\n%forecast=(\r\n NAM_IO_OFFLINE=>{\r\n  'CSURF_FILETYPE'      => '\"LFI    \",',\r\n  'CFORCING_FILETYPE'   => '\"ASCII\",',\r\n  'CTIMESERIES_FILETYPE'=> '\"LFI\",',\r\n  'XTSTEP_SURF'         => $ENV{TSTEP}.\",\",\r\n  'XTSTEP_OUTPUT'       => '3600.,',\r\n  'LRESTART'            => '.TRUE.,',\r\n  'CPREPFILE'           => '\"PREP\",',\r\n  'CPGDFILE'            => '\"PGD\",',\r\n },\r\n NAM_SURF_ATM=>{\r\n   XRIMAX=>'0.0,',\r\n },\r\n NAM_DIAG_SURFn=>{\r\n   LSURF_BUDGET      => '.TRUE.,',\r\n   N2M      =>'2,',\r\n },\r\n NAM_DIAG_SURF_ATMn=>{\r\n   LT2MMW            => '.TRUE.,',\r\n },\r\n NAM_DIAG_ISBAn=>{\r\n   LPATCH_BUDGET  => '.TRUE.,',\r\n },\r\n NAM_SSOn=>{\r\n   CROUGH   => \"'\".$ENV{CROUGH}.\"'\",\r\n   XFRACZ0  => '15.,',\r\n },\r\n NAM_SEAFLUXn=>{\r\n  CSEA_FLUX => '\"ECUME\",',\r\n  LPWG      => '.FALSE.,',\r\n  LPRECIP   => '.FALSE.,',\r\n  LPWEBB    => '.FALSE.,',\r\n  CSEA_ICE    =>'\"NONE\",',\r\n  LHANDLE_SIC =>'.FALSE.,',\r\n  LPERTFLUX   => 'LPERTSURF,',\r\n },\r\n NAM_ISBAn=>{\r\n  LCANOPY_DRAG => '.TRUE.,',\r\n  XCDRAG       => '0.01,',\r\n  LPERTSURF    => 'LPERTSURF,',\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"XRIMAX: limitation of Richardson number in drag computation (=0 default).\nN2M : flag to compute surface boundary layer characteristics (=0 default). N2M=2 computes temperature at 2 m, specific humidity at 2 m, relative humidity, zonal and meridian wind at 10 m, and Richardson number. 2m and 10m quantities are calculated interpolating between atmospheric forcing variables and surface temperature and humidity. Please note that if the surface boundary multi layer scheme is activated over any tile (as with LISBA_CANOPY=T over land) it overrides the diagnostic N2M method. \nLT2MMW : Alternative weighting of grid average T2M giving more weight to the land tile (=FALSE default).\nCROUGH: type of orographic roughness length. CROUGH is decided by setting CROUGH=\"NONE\" in config_exp.h which means that no orographic treatment is applied.\nXFRACZ0 : Z0=Min(Z0, Href/XFRACZ0). Not applied here since CROUGH=\"NONE\".\nLPERTFLUX: multiplicative perturbation of Ecume fluxes for ensemble forecasting. In HARMONIE this is set in a number of scripts under scr.\nLPERTSURF: if .True. modification of surface fluxes for ensemble forecasting. In HARMONIE this is set in a number of scripts under scr.\nLCANOPY_DRAG: drag activated in SBL scheme within the canopy.\nXCDRAG: drag coefficient in canopy (=0.15 default in SURFEX).","category":"page"},{"location":"Namelists/#ASSIMILATION-1","page":"Namelist","title":"ASSIMILATION","text":"","category":"section"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"ASSIMILATION represents in general the surface assimilation namelist settings used for CANARI and SURFEX. The default ASSIMILATION settings are listed here. The SURFEX assimilation method used (OI or EKF) is decided by setting ANASURF=CANARI_OI_MAIN in config_exp.h. OI is default and EKF is still experimental.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%sice_assim=(\r\n NAM_SEAFLUXn=>{\r\n    LHANDLE_SIC            =>'.TRUE.,',\r\n    LSIC_FROM_FILE         =>'.TRUE.,',\r\n    CSEA_ICE               =>'\"SICE\",',\r\n    NICE_LAYER             =>'4,',\r\n },\r\n NAM_SIMPLE_ICE=>{\r\n   LICE_HAS_SNOW       =>'.FALSE.,',\r\n   XICE_THICKNESS      =>'.75,',\r\n   CICE_SNOW           =>'\"S-D\",',\r\n   NICE_SNOW_NLAYERS   =>'4,',\r\n   XICE_SNOW_HEIGHT    =>'.3,',\r\n   LSIC_DRIVEN_THICKNESS      =>'.FALSE.',\r\n   XSIC_DRIVEN_MAX_THICKNESS  =>'1.',\r\n \r\n},\r\n NAM_PREP_SEAFLUX=>{\r\n    CFILE_SIC          => 'CFILE_SIC,',\r\n    CTYPE_SIC          => '\"GRIB  \"',\r\n    LSEA_SBL           => '.FALSE.',\r\n },\r\n NAM_PREP_SIMPLE_ICE=>{\r\n    LINIT_FROM_SST             =>'.TRUE.,',\r\n    LPREP_ONLY_NEW_ICE         =>'.TRUE.,',\r\n    LEXTRAPOLATE_FROM_FORECAST =>'.TRUE.,',\r\n    CFORECAST_GRIB             =>'CFORECAST_GRIB',\r\n },\r\n);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"LPREPONLYNEW_ICE : perform prep in current grid cell only if ice state is undefined\nLEXTRAPOLATEFROMFORECAST : use previous forecast to fill areas with new ice. If LINIT_FROM_SST == .TRUE. .AND. LEXTRAPOLATE_FROM_FORECAST == .TRUE. option LINITFROMSST is forced to .FALSE.\nCFORECAST_GRIB : previous forecast in GRIB format","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"This part represents settings connected to the Simple Sea-ice Scheme (SICE) by Yurii Batrak. Please note that SICE is not yet an official contribution to SURFEX and therefore you will not find any documentation of SICE via the SURFEX web site. ","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%assim_surfex=(\r\n NAM_NACVEG=>{\r\n   NECHGU      => ''.$ENV{FCINT}.',',\r\n   RCLIMCA     => '0.,',\r\n   RCLISST     => '0.05,',\r\n   SIGH2MO     => '0.10,',\r\n   SIGT2MO     => '1.0,',\r\n   LOBS2M      => '.TRUE.,',\r\n   LOBSWG      => '.FALSE.,',\r\n },\r\n NAM_IO_OFFLINE=>{\r\n   CSURF_FILETYPE       => 'CSURF_FILETYPE,',\r\n   CTIMESERIES_FILETYPE => '\"LFI \",',\r\n   CFORCING_FILETYPE    => '\"ASCII\",',\r\n   LRESTART             => '.TRUE.,',\r\n   XTSTEP_SURF          => '3600.,',\r\n   XTSTEP_OUTPUT        => '3600.,',\r\n },\r\n NAM_ASSIM=>{\r\n   LASSIM              => '.TRUE.,',\r\n   LEXTRAP_WATER       => '.TRUE.,',\r\n   LEXTRAP_SEA         => '.FALSE.,',\r\n   LEXTRAP_NATURE      => '.FALSE.',\r\n   LREAD_SST_FROM_FILE => '.TRUE.,',\r\n   LWATERTG2           => '.TRUE.,',\r\n   LAESNM              => 'LAESNM,',\r\n   LECSST              => 'LECSST,',\r\n   LAROME              => 'LAROME,',\r\n   NPRINTLEV           => '1,',\r\n },\r\n);\r\n\r\n%oi_main=(\r\n NAM_ASSIM=>{\r\n   CASSIM_ISBA         => '\"OI\",',\r\n },\r\n);","category":"page"},{"location":"Namelists/#surfex*selected*output.pm-1","page":"Namelist","title":"surfexselectedoutput.pm","text":"","category":"section"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"The output from SURFEX to the .sfx fa-files (e.g. ICMSHHARM+0002.sfx) is in general decided by SURFEX NAMDIAG namelist settings. These settings activate or deactivate groups of variables in output files. When one or more such groups are activated it is possible to limit the output to a specific list of variables by the use of the LSELECT/CSELECT options in SURFEX. This way of specifying output from SURFEX is the default way in cy40h. The setting is `SURFEXLSELECT=\"yes\"` in config_exp.h. When SURFEXLSELECT=\"yes\" the namelist [surfexselectedoutput.pm](https://hirlam.org/trac/browser/Harmonie/nam/surfexselectedoutput.pm) is used to specify the output variables. The style of surfexselected_output.pm is","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"%surfex_output=(\r\n NAM_WRITE_DIAG_SURFn=>{\r\n   NSTEP_DUMP_STATE => 'NSTEP_DUMP_STATE,',\r\n   LSELECT     => '.TRUE.,',\r\n   CSELECT     => '\r\n\"Z0\",\r\n\"RNC\",\r\n\"HC\",\r\n\r\n\r\n\"T2M_P\",\r\n\"T2MMIN_P\",\r\n\"T2MMAX_P\",'\r\n },);","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Please note the \" ' \" character at the end of the last variable line \"T2MMAX_P\",'. Don't miss it, it is very important! The naming convention for variables in this file follows the SURFEX naming convention which is not exactly how they appear in fa-files. A fa-file output example from a .sfx file may look:","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"SFX.SST         > 001:011-  000-102@20160301_15:00+002h00m tri:000 000 SST\r\nSFX.TS_WATER    > 001:011-  770-105@20160301_15:00+002h00m tri:000 000 TS_WATER\r\nX001TG1         >                   20160301_15:00+002h00m         000\r\nX001TG2         >                   20160301_15:00+002h00m         000\r\nX001WG1         >                   20160301_15:00+002h00m         000\r\nX001WG2         >                   20160301_15:00+002h00m         000\r\nSFX.TROAD1      >                   20160301_15:00+002h00m         000\r\nSFX.WS_ROAD     > 001:024-  950-105@20160301_15:00+002h00m tri:000 000 WS_ROAD","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"You get the corresponding SURFEX names by removing \"SFX.\" or \"X001\" at the beginning of these fa-names.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"The .sfx files are used as first guess for next forecast. However, the first guess needs ALL SURFEX variables and not only a subset as defined by LSELECT/CSELECT. Therefore, a full .sfx file (e.g. ICMSHFULL+0003.sfx) is created for each assimilation cycle hour in addition to the corresponding limited file ICMSHHARM+0003.sfx. The output frequency of full files is defined by SURFEX_DUMP_STATE_STEPS=\"\" in config_exp.h.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"The content of the FULL-files can be used to identify additional variables to add to surfexselectedoutput.pm.","category":"page"},{"location":"Namelists/#Change-your-namelists-1","page":"Namelist","title":"Change your namelists","text":"","category":"section"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"There are several ways of changing namelists generated from the dictionary.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"Copy the harmonie_namelist.pm file to your local experiment directory and change the right section like for any source or script modification.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"If you feel uncertain where to change in the dictionary you can copy the actual namelist used in your run. Every namelist used is listed in the logfile so copy it from there and put it under the nam directory in your local experiment. Make sure you give it a unique name. You must then also change the script(s) using this namelist like in the Forecast script.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"#  Get namelist name\r\n#NAMELIST=$WRK/$WDIR/namelist_forecast\r\n#Get_namelist forecast $NAMELIST\r\nNAMELIST=$HM_LIB/nam/namelist_forecast_with_a_unique_name\r\n","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"For namelists not present in the dictionary you just copy them to you local nam directory.","category":"page"},{"location":"Namelists/#","page":"Namelist","title":"Namelist","text":"There is also a description on how to generate new namelist dictionaries in  [HarmonieSystemDocumentation/UpdateNamelists here].","category":"page"},{"location":"Namelists/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Namelist","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ClimateSimulation?action=edit\"","category":"page"},{"location":"ClimateSimulation/#How-to-run-a-Climate-simulation-with-Harmonie-1","page":"Climate Simulation","title":"How to run a Climate simulation with Harmonie","text":"","category":"section"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"Introduction Harmonie for climate applications is available from the trunk (cycle37). In climate mode, the model makes montly restarts. Only historical simulations driven by ERA-Interim have been made so far. SST is forced as a lower boundary and is updated at the same time as the lateral boundaries.","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"Experiment Settings In ecf/config_exp.h  a few changes are made.","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"SIMULATION_TYPE=climate\nBDSTRATEGY=era\nNo assimilation\nSet BDDIR to your BD location","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"Start the experiment in the same way as NWP e.g Harmonie start DTG=2012010100 DTGEND=2012060100","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"Nested runs SURFEX is used in all climate simulations so HOSTSURFEX has to be true. Use SURFEXPREP to interpolate SURFEX data to the inner domain.","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"HOST_SURFEX=\"yes\"\nBDSTRATEGY=same_forecast","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"Optional","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"SURFEX_PREP=\"yes\"","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"Ongoing work In SURFEX there are some settings that are not tested but planned to be used as default values.","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"FLake\n3-L snow scheme\nCISBA=DIF","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"Atmosphere","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"Use RCP in scenarious\nForced by EC-Earth","category":"page"},{"location":"ClimateSimulation/#","page":"Climate Simulation","title":"Climate Simulation","text":"NetCDF with gl There is a possibilty to convert FA-files to netcdf with gl. The code is still under development but a first test can soon be found in trunk.  We aim to use the CF1.4 convention.","category":"page"},{"location":"ClimateSimulation/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Climate Simulation","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PlatformConfiguration?action=edit\"","category":"page"},{"location":"PlatformConfiguration/#Platform-Configuration-1","page":"Platform","title":"Platform Configuration","text":"","category":"section"},{"location":"PlatformConfiguration/#Overview-1","page":"Platform","title":"Overview","text":"","category":"section"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"This wiki page outlines the configuration files required by HARMONIE for successful compilation and running of the system.","category":"page"},{"location":"PlatformConfiguration/#Basic-requirements-1","page":"Platform","title":"Basic requirements","text":"","category":"section"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"All experiments require a valid host to \"setup\" an experiment using the Harmonie script. Recall from the quick start instructions that in order to setup a new experiment on your platform, called YOURHOST, using HARMONIE downloaded to PATHTOHARMONIE one must issue the following command:","category":"page"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"cd hm_home/my_exp\r\nPATH_TO_HARMONIE/config-sh/Harmonie setup -r PATH_TO_HARMONIE -h YOURHOST","category":"page"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"hmhome/myexp contains:","category":"page"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"Env_submit -> config-sh/submit.YOURHOST           ## YOURHOST platform specific settings\r\nEnv_system -> config-sh/config.YOURHOST           ## YOURHOST task submission settings\r\n./config-sh/hm_rev                                ## contains PATH_TO_HARMONIE\r\n./config-sh/Main                                  ## The script used to run HARMONIE\r\n./config-sh/submit.YOURHOST                       ## YOURHOST platform specific settings\r\n./config-sh/config.YOURHOST                       ## YOURHOST task submission settings\r\n./suites/harmonie.pm                              ## perl module to define ensemble settings\r\n./ecf/config_exp.h                                ## your experiment definition (scientific type options)\r\n./scr/include.ass                                 ## assimilation specific settings","category":"page"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"But, what if your host configuration is not available in the HARMONIE system? Host specific configuration files in PATHTOHARMONIE/config-sh must be available for your host and configuration files for the compilation of the code must be available. This documentation attempts to describe what is required.","category":"page"},{"location":"PlatformConfiguration/#Host-config-files-1","page":"Platform","title":"Host config files","text":"","category":"section"},{"location":"PlatformConfiguration/#Env_system-config-sh/config.YOURHOST-1","page":"Platform","title":"Env_system -> config-sh/config.YOURHOST","text":"","category":"section"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"The config.YOURHOST file defines host specific variables such as some input directory locations. If your YOURHOST is not already included in HARMONIE it may be work looking at config.* files in config-sh to see what other people have done. The table below outlines variables set in config-sh/config-sh.YOURHOST and what the variables do:","category":"page"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"= Variable name        = = Description                                                                                                                      =\nCOMPCENTRE controls special ECMWF solutions (such as MARS) where required. Set to LOCAL if you are unsure\nHARMONIE_CONFIG defines the config file used by Makeup compilation\nMAKEUPBUILDDIR location of where Makeup compiles the HARMONIE code\nMAKEOWNPRECOMPILED yes=>install pre-compiled code in PRECOMPILED\nPRECOMPILED location of (optional) pre-compiled HARMONIE code\nE923DATAPATH location of input data for E923, climate generation\nPGDDATAPATH location of input data for PGD, surfex climate generation\nECOSGDATAPATH location of input data for ECOCLIMAP2G\nGMTED2010DATAPATH location of HRES DEM\nSOILGRIDDATAPATH location of SOILGRID data\nHMSATCONST location of constants for satellite assimilation\nRTTOV_COEFDIR location of RTTOV coefficients\nHM_DATA location of top working directory for the experiment\nHM_LIB location of src/scripts and compiled code\nTASK_LIMIT Maximum number of jobs submitted by ECFLOW\nRSYNC_EXCLUDE used to exclude .git* sub-directories from copy of source code for compilation\nDRHOOKIGNORE_SIGNALS environment variable used by Dr Hook to ignore certain \"signals\"\nHOST0 define primary host name\nHOSTN define other host name(s)\nHOST_INSTALL 0=> install on HOST0, 0:...:N => install on HOST0,...,HOSTN\nMAKE make command may need to be explicity defined. Set to make for most platforms\nMKDIR mkdir command (default: mkdir -p)\nJOBOUTDIR where ECFLOW writes its log files\nECCODESDEFINITIONPATH location of local ecCodes definition files\nBUFR_TABLES location of local BUFR tables","category":"page"},{"location":"PlatformConfiguration/#Env_submit-config-sh/submit.YOURHOST-1","page":"Platform","title":"Env_submit -> config-sh/submit.YOURHOST","text":"","category":"section"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"The Env_submit file uses perl to tell the HARMONIE scheduler how to execute programs - which programs should be run on multiple processors and define batch submissions if required.","category":"page"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"= perl                = = description\n%backg_job defines variables for jobs run in the background on HOST0\n%scalar_job defines variables for single processor batch jobs\n%par_job defines variables for multi-processor batch jobs\n@backg_list list of tasks to be submitted as a background job\n@scalar_list list of tasks to be submitted as a scalar job\n@par_list list of tasks to be submitted as parallel job\ndefault \"wildcard\" task name to defined default type of job for unlisted tasks","category":"page"},{"location":"PlatformConfiguration/#Host-summary-1","page":"Platform","title":"Host summary","text":"","category":"section"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"= YOURHOST            = = Host type                   = = batch     = = Contact            =\nKNMI-Altix KNMI SGI HPC none \nLinuxPC General Linux PC no MPI none \nLinuxPC-MPI General Linux PC with MPI none \nLinuxPC-MPI-ubuntu Ubuntu Linux PC with MPI none \nMETIE.LinuxPC METIE CentOS 6 PC with MPI none Eoin Whelan\nMETIE.LinuxRH7gnu METIE Redhat 7 server with MPI none Eoin Whelan\nMETIE.fionn METIE SGI HPC PBS Eoin Whelan\nSMHI.Linda4 SMHI ???  \nSMHI.LinuxPC SMHI PC  \nbi   \ncrayx1   \ncrayxt5m   \necgb   \necgb-cca ECMWF HPC with MPI dual host slurm/PBS \nfmisms   \njumbo   \nxt5intel   \nxtpathscale   ","category":"page"},{"location":"PlatformConfiguration/#Compilation-config-files-1","page":"Platform","title":"Compilation config files","text":"","category":"section"},{"location":"PlatformConfiguration/#Makeup-1","page":"Platform","title":"Makeup","text":"","category":"section"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"config files required for compilation of code using Makeup ...","category":"page"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"More information on Makeup is available here: Build with Makeup","category":"page"},{"location":"PlatformConfiguration/#Obsmon-1","page":"Platform","title":"Obsmon","text":"","category":"section"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"For config files required for compilation of obsmon check here","category":"page"},{"location":"PlatformConfiguration/#","page":"Platform","title":"Platform","text":"","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ObservationOperators?action=edit\"","category":"page"},{"location":"ObservationOperators/#Observation-operators-1","page":"Observation operators","title":"Observation operators","text":"","category":"section"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"This documentation summarises the observation operator in HARMONIE and the use of the HOPDIRVER tool. The test harness, HOPDRIVER, calls the observation operator and generates FG departures without calling any model code or initialising any model modules. Firstly, the IFS is used to dump a single-observation gomplus to file from the 1st trajectory of an experiment. Dumping multiple observations would require a more complex and full-featured dump (good file format, multi-process parallel). For code refactoring HOPDRIVER can be used to test changes to the observation operator of a particular observation type.","category":"page"},{"location":"ObservationOperators/#HARMONIE-and-HOP_DRIVER-1","page":"Observation operators","title":"HARMONIE and HOP_DRIVER","text":"","category":"section"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"The HOPDRIVER program was first added to CY42R2 code. The tool was initially implemented to test refactoring of the IFS observation operator code src/arpifs/opobs/hop.F90. At the moment the refactor branch (branches/refactor/harmonie) is the only HARMONIE code set that includes HOPDRIVER. Instructions on how to prepare the code and run HOPDRIVER using HARMONIE are outlined below. Presentation made at OOPS Observation Operator Workshop may provide some useful background information.","category":"page"},{"location":"ObservationOperators/#Comments-on-the-branch-1","page":"Observation operators","title":"Comments on the branch","text":"","category":"section"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"Code changes were required in order to compile cy42r2bf.04 + mods (provided by MF/ECMWF) in the HARMONIE system: [14312], [14325], [14326], [14330], [14331], [14332], [14333], [14334].\nChanges were made to makeup in order to compile HOP_DRIVER correctly: [14310], [14327], [14328], [14329], [14335], [14362], [14382], [14392].\nIncluded in [14362] is a change to ODBSQLFLAGS which is set to \"ODBSQLFLAGS=-O3 -C -UCANARI -DECMWF ODBEXTRAFLAGS\" in order to use ECMWF flavoured ODB used by HOP_DRIVER\nOn cca GNU compilers 4.9 are not fully supported, ie I had to build GRIB-API and NetCDF locally using gcc/gfortran 4.9 on cca\nAn environment variable, HOPDIR, is used to define the location of necessary input data for HOP_DRIVER\nAn environment variable, HOPCOMPILER, is used by the HOP_driver script to define the compiler used. This is used to compare results.","category":"page"},{"location":"ObservationOperators/#Running-on-ecgb/cca-1","page":"Observation operators","title":"Running on ecgb/cca","text":"","category":"section"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"cd $SCRATCH\r\nmkdir -p harmonie_releases/branches/refactor\r\ncd harmonie_releases/branches/refactor\r\nsvn co https://svn.hirlam.org/branches/refactor/harmonie-42R2\r\ncd $HOME\r\nmkdir -p hm_home/rfexp\r\ncd hm_home/rfexp\r\n$SCRATCH/harmonie_releases/branches/refactor/harmonie-42R2/config-sh/Harmonie setup -r $SCRATCH/harmonie_releases/branches/refactor/harmonie-42R2\r\n$SCRATCH/harmonie_releases/branches/refactor/harmonie-42R2/config-sh/Harmonie hop_driver","category":"page"},{"location":"ObservationOperators/#Running-on-local-platforms-1","page":"Observation operators","title":"Running on local platforms","text":"","category":"section"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"So far, only METIE.LinuxRH7gnu, which uses gfortran 4.9 and openmpi, has been tested. Input data for the amsua test case is available on ECFS at ECMWF: ec:/dui/hopdata.tar.gz","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"cd $HOME\r\nmkdir -p harmonie_releases/branches/refactor\r\ncd harmonie_releases/branches/refactor\r\nsvn co https://svn.hirlam.org/branches/refactor/harmonie-42R2\r\ncd $HOME\r\nmkdir -p hm_home/rfexp\r\ncd hm_home/rfexp\r\n$HOME/harmonie_releases/branches/refactor/harmonie-42R2/config-sh/Harmonie setup -h METIE.LinuxRH7gnu -r $HOME/harmonie_releases/branches/refactor/harmonie-42R2\r\n$HOME/harmonie_releases/branches/refactor/harmonie-42R2/config-sh/Harmonie hop_driver","category":"page"},{"location":"ObservationOperators/#HOPOBS:-amsua-1","page":"Observation operators","title":"HOPOBS: amsua","text":"","category":"section"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"Currently there is only one observation type, AMSU-A (HOPOBS=amsua), available for testing with HOPDRIVER. Alan Geer (ECMWF) has already carried out the refactoring of the HOP code related to AMSU-A observations. A single observation is provided in the ECMA and is used to test the refactoring of the HOP code. To carry out the testing of the amsua refactoring HOPOBS should be set to amsua in ecf/configexp.h .","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"|=reportype@hdr=|=obstype@hdr=|=sensor@hdr=|=statid@hdr =|=stalt@hdr=|=date@hdr =|=time@hdr=|=degrees(lat)=|=degrees(lon)=|=reportstatus@hdr=|=datumstatus@body=|=obsvalue@body=|=varno@body=|=vertco_type@body=| | –- | –- | –- | –- | –- | –- | –- | –- | –- | –- | –- | –- | –- | –- |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 12                | 173.28        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 12                | 158.86        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 3                 | 227.40        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 3                 | 260.82        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 1                 | 256.90        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 1                 | 239.60        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 12                | NULL          | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 3                 | 217.69        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 1                 | 209.39        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 1                 | 214.05        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 1                 | 223.02        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 1                 | 234.42        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 1                 | 245.14        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 1                 | 257.18        | 119        | 3                |  | 1007          | 7           | 3          | '        4' | 832800    | !20140131 | 215914   | -29.5906     | 0.3113       | 1                 | 12                | 227.91        | 119        | 3                |","category":"page"},{"location":"ObservationOperators/#HOP_DRIVER-1","page":"Observation operators","title":"HOP_DRIVER","text":"","category":"section"},{"location":"ObservationOperators/#Using-HOP_DRIVER-1","page":"Observation operators","title":"Using HOP_DRIVER","text":"","category":"section"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"With LHOP_RESULTS=.TRUE. HOPDRIVER will write results to a file called *hopresultsMYPROC* for comparison between online and offline results (The results file is opened by srcarpifsvartaskobF90(httpshirlamorgtracbrowserbranchesrefactorharmoniesrcarpifsvartaskobF90)) HOP_DRIVER results are written to *hop_results{MYPROC}* in src/arpifs/op_obs/hop.F90:","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":" :\r\n :\r\nIF(LHOP_RESULTS) THEN\r\n!$OMP CRITICAL\r\n  ! Output for comparison between online and offline results:\r\n  WRITE(CFILENAME,'(\"hop_results\",I4.4)') MYPROC\r\n  OPEN(NEWUNIT=IU,FILE=CFILENAME,POSITION='APPEND',ACTION='WRITE',FORM='FORMATTED')\r\n  DO JOBS = 1,KDLEN\r\n    DO JBODY=1,IMXBDY\r\n      IF (JBODY>ICMBDY(JOBS)) CYCLE\r\n      IBODY = ROBODY%MLNKH2B(JOBS)+(JBODY-1)\r\n      WRITE(IU,'(6I8,2F30.14)') MYPROC, KSET, JOBS, NINT(ROBHDR%DATA(JOBS,ROBHDR%SEQNO_AT_HDR)),&\r\n        & NINT(ROBODY%DATA(IBODY,ROBODY%VERTCO_REFERENCE_1_AT_BODY)), &\r\n        & NINT(ROBODY%DATA(IBODY,ROBODY%VARNO_AT_BODY)), ZHOFX(JOBS,JBODY), ZXPPB(JOBS,JBODY)\r\n\r\n    ENDDO\r\n  ENDDO\r\n  CLOSE(IU)\r\n!$OMP END CRITICAL\r\nENDIF\r\n :\r\n :","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"The HOPdriver script (based a script provided by MF) sorts the contents of the hopresults0001 file for comparison with some results made available by ECMWF/MF:","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":" :\r\n :\r\n#\r\n# Check HOP_DRIVER results (available for gfotran and intel)\r\n#\r\nln -s $HOPDIR/${HOPOBS}/results.$HOPCOMPILER .\r\ncat hop_results* | sort -k1,1n -k2,2n -k3,3n -k5,5n -k6,6n > results.driver\r\necho\r\ncmp -s results.$HOPCOMPILER results.driver\r\nif [ $? -eq 0] ; then\r\n  echo \"RESULTS ARE STRICTLY IDENTICAL TO THE REFERENCE FOR HOPCOMPILER=$HOPCOMPILER :-)\"\r\nelse\r\n  echo Compare exactly against the results dumped from hop:\r\n  echo \"xxdiff results.$HOPCOMPILER results.driver &\"\r\n  diff results.$HOPCOMPILER results.driver\r\n  exit 1\r\nfi\r\n :\r\n :","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"On cca you will find useful output from HOPDRIVER in cca:TEMP/hmhome/rfexp/archive/HOPDRIVEROUT:","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"fort.4\r\nNODE.001_01\r\nhop_results0001\r\nresults.gfortran\r\nresults.driver","category":"page"},{"location":"ObservationOperators/#The-code-1","page":"Observation operators","title":"The code","text":"","category":"section"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"HOPDRIVER is a short program written by Deborah Salmond (ECMWF) to test code changes made to the observation operator. The program [src/arpifs/programs/hopdriver.F90](https://hirlam.org/trac/browser/branches/refactor/harmonie/src/arpifs/programs/hop_driver.F90) is summarised here.","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"The program sets up the model geometry and observations:","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":" :\r\n :\r\nCALL GEOMETRY_SET(YRGEOMETRY)\r\nCALL MODEL_SET(YRMODEL)\r\n\r\nCALL IFS_INIT('gc7a')\r\n\r\nCALL SUINTDYN\r\n\r\nCALL SUGEOMETRY(YRGEOMETRY)        !From GEOMETRY_SETUP\r\n\r\nCALL SURIP(YRGEOMETRY%YRDIM)             !From MODEL_CREATE\r\n\r\n! Set up Observations, Sets\r\nCALL SUDIMO(YRGEOMETRY,NULOUT)     !From SU0YOMB\r\nCALL SUOAF              !From SU0YOMB\r\nCALL SUALOBS            !From SU0YOMB\r\nCALL SURINC             !From SU0YOMB\r\nCALL SETUP_TESTVAR      !From SU0YOMB\r\nCALL SUOBS(YRGEOMETRY)              !From CNT1\r\nCALL ECSET(-1,NOBTOT,0) !From OBSV\r\nCALL SUPHEC(YRGEOMETRY,NULOUT)\r\n\r\n! Setup varbc (from cnt1.F90) and read VARBC.cycle\r\nCALL YVARBC%SETUP_TRAJ\r\n :\r\n :","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":"HOP_DRIVER then loops over the number of observation sets (NSETOT) and reads a GOM PLUS for each observation set. HRETR and HOP are then called:","category":"page"},{"location":"ObservationOperators/#","page":"Observation operators","title":"Observation operators","text":" :\r\n :\r\nDO ISET=1,NSETOT\r\n  IDLEN   = MLNSET(ISET)\r\n  IMXBDY = MAX(MMXBDY(ISET),1)\r\n\r\n  ALLOCATE(ZHOFX(IDLEN,IMXBDY))\r\n  ZHOFX=RMDI\r\n\r\n  ! READ GOM_PLUS FROM DUMP\r\n  CALL GOM_PLUS_READ_DUMP(YGP5,ISET)\r\n\r\n  IF(IDLEN /= YGP5%NDLEN) THEN\r\n    CALL ABOR1('Sets are incompatible')\r\n  ENDIF\r\n\r\n  :\r\n  :\r\n  :\r\n\r\n  CALL HRETR(YRGEOMETRY%YRDIMV,IDLEN,IMXBDY,ISET,1,YGP5,YVARBC)\r\n\r\n  CALL HOP(YRGEOMETRY%YRDIMV,YGP5,YVARBC,IDLEN,IMXBDY,ISET,1,LDOOPS=.TRUE.,PHOFX=ZHOFX)\r\n\r\n  !write(0,*)'ZHOFX',ZHOFX\r\n  DEALLOCATE(ZHOFX)\r\n\r\n  CALL GOM_PLUS_DESTROY(YGP5)\r\n\r\nENDDO\r\n\r\n :\r\n :","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ObservationPreprocessing/Bator?action=edit\"","category":"page"},{"location":"ObservationPreprocessing/Bator/#ODB-creation:-Bator-1","page":"Bator","title":"ODB creation: Bator","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#General-Description-1","page":"Bator","title":"General Description","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"The pre-processing step creates ODB (Observational Data Base) from various observation data files possibly in different formats.","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"Software: The programs used for pre-processing (!ShuffleBufr, oulan and BATOR) are not part of the IFS code. oulan is software developed at Météo France to extract (conventional) observations from their local database (BDM). The ASCII output from oulan, the OBSOUL file, is one of the inputs of BATOR. By default, oulan is no longer part of the observation processing chain. BATOR is also developed at Météo France to generate the ODB (Observational !DataBase) database for the ARPEGE/ALADIN/HARMONIE analysis system. ODB is a tailor made database software developed at ECMWF to manage very large observational data volumes assimilated in the IFS 4DVAR system, and to enable flexible post-processing of this data (Sami Saarinen, 2006). HARMONIE's BATOR originates from the MF export-pack. The figure below describes the mechanism of the observation pre-processing in HARMONIE DA. To sum it up, !ShuffleBufr splits different observations into BUFR files and BATOR creates the ODB file using from BUFR/HDF5/NetCDF input files.","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"Compilation: BATOR is compiled using gmakpack or makeup.\nScripts: scr/Bator.\nInput: BUFR/HDF5/NetCDF\nOutput: ODB databases for surface and upper-air data assimilation","category":"page"},{"location":"ObservationPreprocessing/Bator/#BATOR-1","page":"Bator","title":"BATOR","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"BATOR creates the ODB files from observational data in BUFR/HDF5/NetCDF format. BATOR also includes filtering (blacklisting) of parameters from stations of different observation types. To run the BATOR program one needs files containing blacklist rules/information, namelist(s), file containing information about observations and their format – refdata -, and some setting for the ODB environment. Documentation provided by Météo France is available at http://www.umr-cnrm.fr/gmapdoc/spip.php?article229. In particular: BATOR namelists, the param_bator.cfg file and the batormap files.","category":"page"},{"location":"ObservationPreprocessing/Bator/#observation-window-and-timeslots-1","page":"Bator","title":"observation window and timeslots","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"The timeslots characteristics are provided by BATOR using the following environment variables. These are defined in scr/Bator based on settings provided in scr/include.ass and ecf/config_exp.h.","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"=Environment variable = = Description                                                        =\nODBANALYSISDATE analysis date (YYYYMMDD)\nODBANALYSISTIME analysis time (hhmmss)\nBATOR_NBSLOT number of timeslots needed [1, 9999]\nBATORWINDOWLEN width of the temporal assimilation window (in minutes) [1, 9999]\nBATORWINDOWSHIFT shift of the temporal assimilation window relative to the analysis time (in minutes). Must be negative.\nBATORSLOTLEN width of a standard timeslot (in minutes) [1, 9999]\nBATORCENTERLEN width of the centred timeslot (in minutes) [1, 9999]","category":"page"},{"location":"ObservationPreprocessing/Bator/#batormap-1","page":"Bator","title":"batormap","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"The 'batormap' file lists all the input data files (BUFR,NETCDF,HDF5,OBSOUL) to translate and put in a particular ODB database. Several records can be stored in this file, each one composed by the following 4 fields (blank spaces are used as separator). The batormap file is created by scr/Bator based on settings provided in scr/include.ass and task arguments.","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"The ECMA database extension in which data will be stored, up to 8 characters.\nThe data filename extension, up to 8 characters.\nData filename format, up to 8 characters.\nKind of data or instrument, up to 16 characters. Must match a kind of data in the subroutine batorinitlong (src/odb/pandormodule/batorinit_mod.F90)","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"For example:","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"conv     conv     OBSOUL   conv\r\nconv     synop    BUFR     synop","category":"page"},{"location":"ObservationPreprocessing/Bator/#param.cfg-1","page":"Bator","title":"param.cfg","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"BATOR reads BUFR data according to definitions describing BUFR templates in the param.cfg file. The general layout of definitions in the param.cfg file is as follows:","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"BUFR label\r\na b c d\r\ncodage  a1  desc_a1\r\n...\r\ncodage  an   desc_an\r\ncontrol b1   val1\r\n...\r\ncontrol bn   valn\r\noffset  c1   inc1\r\n...\r\noffset  cn   incn\r\nvalues  pos_d1 desc_d1\r\n...\r\nvalues  pos_dn desc_dn\r\n/BUFR label","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"where: ","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"a: number of unexpanded descriptors (NTDLEN if you are familiar with bufrdc software).\nb: number of \"control\" entries - \"control\" values used by src/odb/pandor/module/batordecodbufrmod.F90\nc: number of \"offset\" entries - \"jump\" values used by src/odb/pandor/module/batordecodbufrmod.F90\nd: number of \"values\" entries - bufrdc VALUES array indices of parameters\ncodage desc: FXY's of NTDLST array values\nvalues desc: FXY's of NTDEXP array values","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"param.cfg files are stored in const/bator_param and linked for use by BATOR in scr/Bator","category":"page"},{"location":"ObservationPreprocessing/Bator/#Namelists-1","page":"Bator","title":"Namelists","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"Namelists are needed for BATOR to deal with observations having format structure different than that of MF. For example to read local Seviri data in grib format, one should set some parameters (NLONGRIB and NLATGRIB) in the NADIRS group. Note: If my last modifications will be accepted, we will need to set parameters in the mentioned group, so the use of this namelist become obligatory for “local” (outside MF) HARMONIE system. The namelist looks like this:","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":" &NADIRS\r\n   LMFBUFR=.FALSE.,                                         # we are not using Météo France BUFR\r\n   ASCAT_XYGRID=12500.,                                     # ASCAT XYGRID RESOLUTION /LR=25000m/HR=12500m/\r\n   GPSSOLMETHOD=\"CENT\",                                     # Selection method for GNSS data \"CENT\"/\"MEAN\"\r\n   NbTempMaxLevels=6000,                                    # Maximum number of radiosonde levels read\r\n   TempSondOrTraj=.FALSE.,                                  # .TRUE. = sondage vertical, .FALSE. = trajectoire\r\n   TempSondSplit=.FALSE.,                                   # .TRUE. = on coupe le radiosondage/timeslot, .FALSE. = profil simple\r\n   ElimTemp0=.FALSE.,                                       # suppression des TEMP sans delta lat/lon/time si .TRUE.\r\n   ElimPilot0=.FALSE.,                                      # suppression des PILOT sans delta lat/lon/time si .TRUE.\r\n   NFREQVERT_TPHR=100,                                      # thinning factor for radiosonde data\r\n   NbMinLevelHr=300,                                        # level threshold for high-resolution treatement of sonde data\r\n   TS_AMSUA(206)%t_select%ChannelsList(:) = -1,             # ...\r\n   TS_AMSUA(206)%t_select%TabFov(:) = -1,                   # ...\r\n   TS_AMSUA(206)%t_select%TabFovInterlace(:) = -1,          # ...\r\n   :                                                        # :\r\n   :                                                        # :\r\n   :                                                        # :\r\n   SIGMAO_COEF(1:18)=18*1.0,                                # Scaling of sigmo-o coefficients\r\n /\r\n &NAMSCEN\r\n /\r\n &NAMDYNCORE\r\n /\r\n &NAMSATFREQ\r\n /\r\n","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"Namelist to activate (bator) LAMFLAG (needed to extract the observations for the model + extension zone domain): one needs to fetch the bator_lamflag namelist using the following command","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"        lamflag_namelist VAR","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":" &NAMFCNT\r\n   LOBSONLY=.FALSE.,\r\n /\r\n &NAMFGEOM\r\n   EFLAT0=$LAT0,\r\n   EFLON0=$LON0,\r\n   EFLATC=$LATC,\r\n   EFLONC=$LONC,\r\n   EFLAT1=$LAT1,\r\n   EFLON1=$LON1,\r\n   EFDELX=$GSIZE,\r\n   EFDELY=$GSIZE,\r\n   NFDLUN=1,\r\n   NFDGUN=1,\r\n   NFDLUX=$NDLUXG,\r\n   NFDGUX=$NDGUXG,\r\n   Z_CANZONE=1500.,\r\n   REDZONE=$REDZONE_BATOR,\r\n   LVAR=$LVAR,\r\n   LNEWGEOM=.TRUE.,\r\n /\r\n &NAMFOBS\r\n   LSYNOP=$LSYNOP,\r\n   LAIREP=$LAIREP,\r\n   LDRIBU=$LDRIBU,\r\n   LTEMP=$LTEMP,\r\n   LPILOT=$LPILOT,\r\n   LPAOB=$LPAOB,\r\n   LSCATT=$LSCATT,\r\n   LSATEM=$LSATEM,\r\n   LSATOB=$LSATOB,\r\n   LSLIMB=$LSLIMB,\r\n   LRADAR=$LRADAR,","category":"page"},{"location":"ObservationPreprocessing/Bator/#Environment-variables-1","page":"Bator","title":"Environment variables","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"ODB settings for BATOR:","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"\t\texport ODB_CMA=ECMA\r\n\t\texport ODB_SRCPATH_ECMA=${d_DB}/ECMA.${base}\r\n\t\texport ODB_DATAPATH_ECMA=${d_DB}/ECMA.${base} \r\n\t\texport ODB_ANALYSIS_DATE=${YMD}\r\n\t\texport ODB_ANALYSIS_TIME=${HH}0000\r\n\t\texport IOASSIGN=${d_DB}/ECMA.${base}/IOASSIGN\r\n\t\texport BATOR_NBPOOL=${NPOOLS}\r\n\r\n\t\t#--- prepare db dir\r\n\t\tRecreateDir ${d_DB}/ECMA.${base}\t   \r\n\t\t#-- create IOASSIGN file for the given sub-base\r\n\t\tcd ${d_DB}/ECMA.${base}\t\r\n\t\texport ODB_IOASSIGN_MAXPROC=${NPOOLS}\r\n\t\t$HM_LIB/scr/create_ioassign -l \"ECMA\" -n ${BATOR_NBPOOL}","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"where base is the ODB base (base can be conv (for conventional data), amsu (ATOVS/AMSU-A,AMSU-B/MHS), sev (for Sevir), iasi, radarv (radar) for example). Important: If you would like to have more bases, do not forget to take that into consideration when generating the \"batormap\" file for BATOR to define which observations you would like to have in each base.","category":"page"},{"location":"ObservationPreprocessing/Bator/#Blacklisting-1","page":"Bator","title":"Blacklisting","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"To avoid model forecast degradation, two files can be used to blacklist or exclude data from the analysis. They are also used to blacklist observations that the model cannot deal with because they are not representative (orography, breeze effects...). The reason for the existence of this method of 'blacklisting', built-in Bator, alongside with 'hirlam_blacklist.b' (built-in Screening) is to allow simple and quick changes (and especially without changing binary) in the operational suite.","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"The selection of an observation to be 'blacklisted' can be done using multi-criteria (SID/STATID, obstype, codetype, varno, channel/level, production center, sub-center producer, network (s) concerned (s), cycle (prod / assim), ..).","category":"page"},{"location":"ObservationPreprocessing/Bator/#LISTE_LOC-1","page":"Bator","title":"LISTE_LOC","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"The LISTELOC file can be used to blacklist satellite data and also for other data by type and / or subtype for a given parameter (described by varno or not). The contents of the LISTELOC are as follows:","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"=Column = = Description                                                         = = Format =\n1 Type of action: N: blacklisted, E: exclude a1\n2 The observation type (obsytpe@hdr) i3\n3 The observation code-type (codetype@hdr) i4\n4 The satellite ID with leading zeros (satid@sat) a9\n5 The centre that produced the satellite data i4\n6 The parameter ID (varno@body) or the satellite sensor ID (sensor@hdr) i4\n7 Optional keywords of ZONx4, TOVSn, PPPPn, PROFn ","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"TOVSn C1 C2 ... Cn","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"can be aplied to ATOVS radiances\nn can be at most 9 indicating the involved channels\nthe Ci values specify the channels to be blacklisted","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"PPPPn P1 P2 ... Pn","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"can be aplied to blacklist di\u000berent pressure levels\nn can be at most 9 indicating the involved levels\nthe Pi values specify the pressure levels (in hPa) to be blacklisted","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"PROFn P1a P2 ... Pn-1 I1 I2 ... In-1","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"n can be at most 9 indicating the involved layers\nthe Pi values specify the bottom and top levels of pressure layers (in hPa).\nThe \frst layer is always [1000,P1]\nthe Ii values indicate if blacklisting should be applied (=1) or not (=0) to the given layer.","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"ZONx4 latmin latmax lonmin lonmax","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"can be applied to SATOB/GEOWIND data\nif x=B then the pixels with lat < latmin or lat > latmax or lon < lonmin or lon > lonmax will be blacklisted\nif x=C then the pixels with lat < latmin or lat > latmax or (lon > lonmin and lon < lonmax) will be blacklisted.","category":"page"},{"location":"ObservationPreprocessing/Bator/#LISTE*NOIRE*DIAP-1","page":"Bator","title":"LISTENOIREDIAP","text":"","category":"section"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"The LISTENOIREDIAP (const/batorliste) can be used to blacklist conventional observations by station identifier. The contents of the LISTENOIRE_DIAP are as follows:","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"= Column  = = Description                      = = Format =\n1 Observation type (obstype@hdr) i2\n2 Observation name a10\n3 Observation codetype (codetype@hdr) i3\n4 Parameter ID (varno@body) i3\n5 Station ID (statid@hdr) a8\n6 Start date of blacklisting yyyymmdd a8\n7 Optional layer blacklisting (PROFn) a180","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"PROFn P1a P2 ... Pn-1 I1 I2 ... In","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"n can be at most 9 indicating the involved layers\nthe Pi values specify the bottom and top levels of pressure layers (in hPa).The \frst layer is always [1000,P1]\nthe Ii values indicate if blacklisting should be applied (=1) or not (=0) to the given layer. \nThe Hxx keyword speci\ffies the analysis hour that should be blacklisted e.g. H00 or H06 etc","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"Particularities - the blacklisting of certain parameters involves the automatic blacklisting of other parameter summarized in the table below:","category":"page"},{"location":"ObservationPreprocessing/Bator/#","page":"Bator","title":"Bator","text":"=obstype = = speci\fed parameter = = blacklisted parameters              =\nSYNOP 39 (t2) 39 (t2), 58 (rh2), 7 (q)\nSYNOP 58 (rh2) 58 (rh2), 7 (q)\nTEMP 1 (z) 1 (z), 29 (rh), 2 (t), 59 (td), 7 (q)\nTEMP 2 (t) 2 (t), 29 (rh), 7 (q)\nTEMP 29 (rh) 29 (rh), 7 (q)","category":"page"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Scalability_and_Refactoring?action=edit\"","category":"page"},{"location":"Scalability_and_Refactoring/#Scalability-and-refactoring-1","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"","category":"section"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"Preliminary docs, presentations and links","category":"page"},{"location":"Scalability_and_Refactoring/#Purpose-1","page":"Scalability and refactoring","title":"Purpose","text":"","category":"section"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"Create a reference webpage for docs, presentations and web links related with code scalability and refactoring","category":"page"},{"location":"Scalability_and_Refactoring/#ESCAPE-project-1","page":"Scalability and refactoring","title":"ESCAPE project","text":"","category":"section"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"ESCAPE stands for Energy-efficient Scalable Algorithms for Weather Prediction at Exascale.","category":"page"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"1st ESCAPE Dissemination and Training Workshop\nAtlas documentation\nPantarhei project for development of non-hydrostatic IFS related to ESCAPE and ATLAS","category":"page"},{"location":"Scalability_and_Refactoring/#HPC-for-Meteorology-1","page":"Scalability and refactoring","title":"HPC for Meteorology","text":"","category":"section"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"[http://www.ecmwf.int/en/learning/workshops-and-seminars/17th-workshop-high-performance-computing-meteorology]","category":"page"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"AROME France Optimizations Philippe Marguinaud AROME Single Precision and New IO server","category":"page"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"ecProof vs Dr Hook ecProof profiling tool","category":"page"},{"location":"Scalability_and_Refactoring/#OOPS-and-C-1","page":"Scalability and refactoring","title":"OOPS and C++","text":"","category":"section"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"C++ and OOPS training \nTechnical presentations of recent IFS changes (OOPS re-factoring), February 2016","category":"page"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"During the 2016 OOPS Seminar at ECMWF, were given some presentations of the recent changes in IFS in the OOPS re-factoring context :","category":"page"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"OOPS refactoring in IFS-Arpège Fortran - Cycles CY42-CY43, Deborah Salmon pdf\nMISO : Modifying the Ifs Source for Oops, Olivier Marsden pdf\nOOPS observation cleaning (new HOP code + TL/AD) , Alan Geer, Peter Lean, Deborah Salmond, Thibaut Montmerle, Christophe Payan pdf\nA new framework for working with observational data in IFS (new IFS/ODB interfaces), Peter Lean, Alan Geer, Deborah Salmond pdf\nOOPS Jb Changes, Mike Fisher pdf\nNew fields storage in IFS (GMV/GFL), Tomas Wilhelmsson pdf","category":"page"},{"location":"Scalability_and_Refactoring/#Benchmarking-1","page":"Scalability and refactoring","title":"Benchmarking","text":"","category":"section"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"RAPS\nVtune \nPMU Intel\nPAPI CUDA ","category":"page"},{"location":"Scalability_and_Refactoring/#Technical-Videoconferences-IFS/Arpege-1","page":"Scalability and refactoring","title":"Technical Videoconferences IFS/Arpege","text":"","category":"section"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"Minutes 20161013 pdf  \nMinutes 20160606 pdf \nMinutes 20160121 pdf\nTable 20161018 pdf","category":"page"},{"location":"Scalability_and_Refactoring/#Atlas-documentation-1","page":"Scalability and refactoring","title":"Atlas documentation","text":"","category":"section"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"[ Atlas 0.6 User guide]","category":"page"},{"location":"Scalability_and_Refactoring/#System-Videoconference-1","page":"Scalability and refactoring","title":"System Videoconference","text":"","category":"section"},{"location":"Scalability_and_Refactoring/#","page":"Scalability and refactoring","title":"Scalability and refactoring","text":"System Status Presentation","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/scripts/mXCdp?action=edit\"","category":"page"},{"location":"scripts/mXCdp/#A-new-client-/-server-solution-for-mXCdp-/-mSMS-1","page":"mXCdp","title":"A new client / server solution for mXCdp / mSMS","text":"","category":"section"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"The original mini-XCdp monitor was written as a set of (perl/Tk) subroutines running inside the mini-SMS scheduler. Although working fairly well for almost 10 years, this solution has a number of weaknesses:","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"If the monitor crashes, the scheduler will also crash. This has been observed frequently, especially after logging out and trying to revive the graphical window in a new login session. A solution to this problem has never been found because the problem is believed to originate from within the Tk toolkit.\nThe mSMS scheduler can have only one monitoring window.\nMonitoring from a different computer than the one that is running the mSMS scheduler is difficult (although a solution with limited functionality, using the –lead and –follow options of mSMS does actually exist).\nIf the Hirlam/Harmonie toplevel job is submitted to a batch queueing system, monitoring may not be possible at all, because the DISPLAY variable is lost or not meaningful.","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"In order to improve on this situation, a new solution separating mSMS and mXCdp into two programs (server and client) has been developed. Communication between them goes via the HTTP protocol, familiar from web servers and browsers. A new set of subroutines (in a new file WebServer.pl, included by mSMS.pl) turns the mSMS scheduler into a little web server that accepts HTTP connections. There are two types of clients:","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"The special client mXCdp (in mXCdp.pl), which is written in perl and reuses most of the old code from mXCdp.plib.\nAny web browser that can handle !JavaScript.","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"The mXCdp client is started by typing 'Hirlam mxcdp' or 'Harmonie mxcdp' from the user's experiment directory (in just the same way as was supposed to revive the monitoring window in the old solution ... but often crashed). This can now actually be done whether the mini-SMS scheduler is running or not. If the scheduler is not running, the mXCdp client will read the definition and checkpoint files, and show the status of mini-SMS when it last terminated, whether it was complete or aborted. It is also possible to e.g. inspect log files of failed tasks. It is even possible to restart the mini-SMS server from where it left off, if this is desirable. In this case mini-SMS is restarted in the halted state, so that you can sort out any inconsistencies (e.g. as a result of lost signals) before continuing.","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"The look and feel of the new client is very similar to the old one. The only slight disadvantage of the new client is that the status of the various tasks and families is not immediately updated as in the old solution, but instead every time the client polls the server. By default this is every 10 seconds (it can be changed via the menus of mXCdp). In practice this is frequent enough to not be of much annoyance. A new icon on the menu bar will indicate the status of the communication. The meaning is as follows:","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"[[Image(no_server.png)]] There is no running mini-SMS server for the experiment.\n[[Image(no_comm.png)]] mini-SMS is alive, but no communication is taking place right now.\n[[Image(comm_active.png)]] Communication between the mini-SMS server and the mXCdp client is ongoing.","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"If the server is alive its URL (see below) will be displayed in a tooltip if you pass your cursor over the status icon.","category":"page"},{"location":"scripts/mXCdp/#How-to-activate-/-disable-1","page":"mXCdp","title":"How to activate / disable","text":"","category":"section"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"The usage of the new client/server solution is controlled by the environment variable mSMS_WEBPORT, which is expected to be an integer. It is interpreted as follows:","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"If mSMS_WEBPORT <= 0, the web server is disabled, and the old monitor can still be used (unless mXCdp=DISABLE).\nIf 1 <= mSMSWEBPORT < 1024, the port that the server will listen on is selected at random, in the range 10000 to 30000. If mSMSWEBPORT=1 (the default), the new mXCdp client will start automatically whenever Hirlam or Harmonie is started or resumed/prodded. If you don't want automatic startup of the client (e.g., for batch queue submitted runs), but still want a random port, set e.g. mSMS_WEBPORT=2.\nIf mSMS_WEBPORT >= 1024 (i.e., a non-privileged port), the mSMS server will try to listen on the given port.","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"If mSMS_WEBPORT >=1 (i.e., the web server is enabled), the old monitor is disabled. In other words, both solutions should not be active at the same time (although technically possible), to avoid confusion.","category":"page"},{"location":"scripts/mXCdp/#Security-1","page":"mXCdp","title":"Security","text":"","category":"section"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"The URL (which could be something like 'http://ecgb:12345/') of the mSMS web server is written to a file .webserver in the mSMS working directory. This directory is $HL_DATA for Hirlam and $HM_DATA for Harmonie. The file has permissions 0600, i.e., it is only readable by the owner of the experiment. This is because there is no mechanism to prevent other users from connecting to your server's port and trying to control your experiment. So with a port chosen at random you will at least have security comparable to that of the pin code on your bank card. If you're not satisfied with that, or for some reason want a fixed port to listen on (e.g. to set up an ssh tunnel from a remote machine), more security is possible. You can place a file in your experiment directory (~/hl_home/$EXP or ~/hm_home/$EXP) called .htpasswd, containing username/password combinations generated with the htpasswd utility. In this case any action that implies control over the mSMS server (status changes, job submission, termination etc.) will request authentication. If successfully authenticated, your credentials will be remembered for the duration of the monitoring session.","category":"page"},{"location":"scripts/mXCdp/#Local-installation-1","page":"mXCdp","title":"Local installation","text":"","category":"section"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"If your local computer platform has a fairly recent perl version, you should not have to do anything special in order to use the new client / server solution. The code is built on the perl libwww library, which is now included in the base perl installation. More specifically, the server is built upon the module HTTP::Daemon and the client around LWP::UserAgent. The graphical part of the client uses the Tk toolkit as before, so you may still have to install this toolkit.","category":"page"},{"location":"scripts/mXCdp/#Removed-features-1","page":"mXCdp","title":"Removed features","text":"","category":"section"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"A few minor features have been removed compared to the old built-in monitor. The menu entries","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"Allow unsafe operations for 60s\nSingle sweep\nLead mode control\nAuto exit after ...\nAuto abort after ...\nOpen single-task families\nClose single-task families","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"are no longer present. In addition, if the popup menu entry \"submit job\" is chosen, the buttons marked","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"Edit command\nEdit jobfile\nRecreate job and command","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"have all been removed. Some of this might reappear depending on feedback (and inspiration).","category":"page"},{"location":"scripts/mXCdp/#New-features-1","page":"mXCdp","title":"New features","text":"","category":"section"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"As indicated above, the client/server solution opens up some new possibilities:","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"You can have as many monitoring windows as you like connected to your mSMS server. For example, if you have an interesting experiment running at ECMWF when leaving work, you can (if you bring your Actividentity keychain token with you) log in from home and open a new monitor to watch how your experiment is going.\nMonitoring of operational runs (e.g. by operators) should be easier to achieve, also if these jobs are submitted to a batch queueing system.\nYou can start the monitor even if the experiment is no longer running, to see in what state it was when it terminated. If not complete, you may also be able to resume it from the monitor.","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"Another new feature, which is not directly related to the client / server separation, is that mXCdp will now remember the size and placement of the toplevel windows of the application between invocations. These data are stored in ~/.mxcdprc.","category":"page"},{"location":"scripts/mXCdp/#The-!JavaScript-client-1","page":"mXCdp","title":"The !JavaScript client","text":"","category":"section"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"If you sit on a computer where the URL of the mSMS web server makes sense (i.e., it is within your domain) and you have access to a good web browser like e.g. Firefox, you can try to open a connection to the server from your browser. The window will split into two frames, on the left you will have the suite/family/task tree as in mXCdp, and on the right you will by default see the html version of the suite definition file. This frame will also be used if you want to inspect job or log files. The graphics of the !JavaScript client is based on the Yahoo User Interface library (YUI). You need to be connected to the internet to download the necessary files from Yahoo servers to use it (this will happen automatically). This client is not as well tested as the mXCdp client however, and does not (yet?) have all the same possibilities for interaction with the server. So mXCdp would be your preferred client if you can use it.","category":"page"},{"location":"scripts/mXCdp/#","page":"mXCdp","title":"mXCdp","text":"Enjoy!","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/HarmonieBenchMark?action=edit\"","category":"page"},{"location":"HarmonieBenchMark/#Harmonie-RAPS-benchmark-1","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"","category":"section"},{"location":"HarmonieBenchMark/#Background-1","page":"Harmonie RAPS benchmark","title":"Background","text":"","category":"section"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"This page describes the current situation for harmonie as a benchmarking tool. During 2013 several HIRLAM countries will start the procurement for new computers. We hope that by coordinating the efforts we can make a win-win situation for all concerned parties, both vendors and institutes. The benchmarkers on the vendors' side will be able to concentrate their efforts on a single source code base for better productivity and enhanced feedback to the community. Moreover, we believe that the efforts with a common benchmark package will improve the model and might be found useful also in other Harmonie institutes. For the current effort cy38h1 have been chosen as the baseline version. The cycle is currently under preparation and evaluation within the ALADIN/HIRLAM community.","category":"page"},{"location":"HarmonieBenchMark/#Getting-the-package-1","page":"Harmonie RAPS benchmark","title":"Getting the package","text":"","category":"section"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"The package is under preparation and is based on harmonie-38h1.alpha.2 plus [11688] and [11708].","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"The second, version is available here: [https://hirlam.org/portal/download/benchmark/src/HMbenchcy38a2export.tar.gz].","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"Input data and some simple scripts can also be found on hirlam.org [https://hirlam.org/portal/download/benchmark/data/cy38].","category":"page"},{"location":"HarmonieBenchMark/#Organization-of-the-package-1","page":"Harmonie RAPS benchmark","title":"Organization of the package","text":"","category":"section"},{"location":"HarmonieBenchMark/#Input-files-1","page":"Harmonie RAPS benchmark","title":"Input files","text":"","category":"section"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"Please note that it is crucial to have right namelist settings to enable reproducibility. A set of input files including feasible namelists for different problem sizes is provided to ease up the startup for testing. The problem sizes are sorted according to the international clothing sizes as follows:     ","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":" XS)\r\n   # 50x50x65, 2.5km resolution\r\n   BDDIR=XS\r\n   MBX_SIZE=20000000\r\n   TSTEP=60\r\n\r\n  M)\r\n   #  384x400x65, 2.5km resolution\r\n   BDDIR=M\r\n   MBX_SIZE=200000000\r\n   TSTEP=60\r\n\r\n  L)\r\n   #  Nlon,Nlat,Nlev :         750         960          65, 2.5km resolution\r\n   BDDIR=L\r\n   BDINTERVAL=10800.\r\n   TSTEP=60\r\n\r\n  XL)\r\n   #  Nlon,Nlat,Nlev :1200        1200          65, 2.5km resolution\r\n   BDDIR=XL\r\n   MBX_SIZE=200000000\r\n   TSTEP=60\r\n\r\n  XXL)\r\n   # 1600x1600x65, 2.5km resolution\r\n   BDDIR=XXL\r\n   MBX_SIZE=2000000000\r\n   TSTEP=60","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"You will also need the files covers.tar and rrtm_const.tar.","category":"page"},{"location":"HarmonieBenchMark/#Status-1","page":"Harmonie RAPS benchmark","title":"Status","text":"","category":"section"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"The model is not reproducible for different NPROCX/NRPOCY with the default HARMONIE edmfm scheme. Until solved reproducibility can be achieved by removing from &NAMPARAR:","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"   CMF_CLOUD='STAT',\r\n   CMF_UPDRAFT='DUAL',\r\n   LMIXUV=.TRUE.,","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"* This makes the the code reproducible on c2a(IBMP7) with the default compilation flags. UPDATE: also with multiple OpenMP threads. \r\n* Not reproducible on Intel Sandy Bridge (ifort 12.0.5.220 ) with -O2 -fp-model precise but with -O0. OpenMP not reproducible even with -O0.","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"OpenMP works technically (on Intel Sandy Bridge, ifort 12.0.5.220) but we don't get reproducible results when changing the number of openmp threads.\nOpenMP now also tested with ifort 13.0.1 on Sandy Bridge (not using -xAVX flag). Still reproducibility cannot be achieved with any combination of (the many!) compiler flags and environment variable settings tested.\nIf linked without MKL libraries reproducibility is retained.","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"Gfortran 4.6.3 on an Ubuntu 12.04 workstation, domain XS, gives full reproducibility against variations in NPROCX, NPROCY and OMPNUMTHREADS.","category":"page"},{"location":"HarmonieBenchMark/#","page":"Harmonie RAPS benchmark","title":"Harmonie RAPS benchmark","text":"Back to the main page of the HARMONIE System Documentation","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Redhat7Install?action=edit\"","category":"page"},{"location":"Redhat7Install/#Redhat-7-instructions-1","page":"Redhat7","title":"Redhat 7 instructions","text":"","category":"section"},{"location":"Redhat7Install/#Requirements-1","page":"Redhat7","title":"Requirements","text":"","category":"section"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"This is a HOWTO for building and running Harmonie on a Redhat 7 server with GNU compilers using Open MPI. This should probably work on a CentOS 7 PCs too.","category":"page"},{"location":"Redhat7Install/#bit-OS-1","page":"Redhat7","title":"64-bit OS","text":"","category":"section"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Enter the following command in a terminal to check you actually have a 64-bit Linux PC:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"uname  -m -i -p","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"This should return:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"x86_64 x86_64 x86_64","category":"page"},{"location":"Redhat7Install/#OS-software-1","page":"Redhat7","title":"OS software","text":"","category":"section"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"This list of required software is a guess at the moment. Your system may require the installation of other libraries. The following instructions require root access to your PC.","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Install subversion to permit easy download of the code:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"yum install subversion.x86_64","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"To use the mXCdp GUI to monitor the HARMONIE mini-SMS system the perl-Tk library is required. At the time of writing I could not find a trustworthy perl-Tk rpm to install the software. Some system libraries may be required (this list may not be complete):","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"yum install perl-devel.x84_64 perl-Time-HiRes.x86_64\r\nyum install gcc.x864_64\r\nyum install libX11-devel.x86_64 libxcb-devel.x86_64 xorg-x11-proto-devel.noarch libXau-devel.x86_64\r\nyum install libpng-devel.x86_64 zlib-devel.x86_64","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"... and here is how to install perl-Tk from source:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"cd $HOME\r\nwget http://search.cpan.org/CPAN/authors/id/S/SR/SREZIC/Tk-804.032.tar.gz\r\ngunzip Tk-804.032.tar.gz\r\ntar -xvf Tk-804.032.tar\r\ncd Tk-804.032\r\nperl Makefile.PL\r\nmake\r\nmake test\r\nmake install","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"The compilers","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"yum install gcc-gfortran.x86_64 libgfortran.x86_64 libquadmath.x86_64 libquadmath-devel.x86_64","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"ksh for the makeup:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"yum install ksh","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Get yacc/bison","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"yum install flex.x86_64\r\nyum install bison.x86_64 byacc.x86_64","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Get Open MPI:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"yum install environment-modules.x86_64 infinipath-psm.x86_64 libesmtp.x86_64 opensm-libs.x86_64libibumad.x86_64 tcl.x86_64\r\nyum install openmpi.x86_64 openmpi-devel.x86_64","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Enable access to EPEL software:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"wget https://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm\r\nyum install epel-release-7-5.noarch.rpm","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Get BLAS/LAPACK (the requirement to create soft-links for BLAS and LAPACK may be corrected in EPEL at some stage).","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"yum install blas.x86_64 blas-devel.x86_64\r\nyum install lapack.x86_64 lapack-devel.x86_64\r\ncd /usr/lib64\r\nln -s liblapack.so.3 liblapack.so\r\nln -s libblas.so.3 libblas.so","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"I also installed NetCDF and HDF5 from the EPEL:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"yum install netcdf.x86_64 netcdf-cxx.x86_64 netcdf-cxx-devel.x86_64 netcdf-cxx-static.x86_64 netcdf-devel.x86_64 netcdf-fortran.x86_64 netcdf-fortran-devel.x86_64 netcdf-static.x86_64 hdf5.x86_64 hdf5-devel.x86_64 libcurl-devel.x86_64","category":"page"},{"location":"Redhat7Install/#Get-the-code-1","page":"Redhat7","title":"Get the code","text":"","category":"section"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"For trunk:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"mkdir -p $HOME/harmonie_releases\r\ncd $HOME/harmonie_releases\r\nsvn co https://svn.hirlam.org/trunk/harmonie \r\nln -s harmonie trunk","category":"page"},{"location":"Redhat7Install/#Compile-Harmonie-1","page":"Redhat7","title":"Compile Harmonie","text":"","category":"section"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Now let's create our first Harmonie experiment (METIE.LinuxPC setup is designed for standard CentOS 6 Linux PCs):","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"cd $HOME\r\nmkdir -p hm_home/trunkexp\r\ncd $HOME/hm_home/trunkexp\r\n$HOME/harmonie_releases/trunk/config-sh/Harmonie setup -r $HOME/harmonie_releases/trunk -h METIE.LinuxRH7gnu","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Local changes that may be required ... in the Env_system:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":":\r\n:\r\n:\r\n# Climate data location\r\nexport HM_CLDATA=/data/nwp/harmonie_climate/40h1\r\nexport HM_SAT_CONST=/data/nwp/harmonie_sat_const\r\n:\r\n:\r\n# Jb data location\r\nexport JBDIR=/data/nwp/harmonie_jbdata\r\n:\r\nexport SMSTASKMAX=4","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Local changes that may be required ... in the Env_submit:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"  $nprocy=2; # instead of 8 if you only have a dual-/quad-core PC","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Now use the Harmonie system to build the software:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"cd $HOME/hm_home/trunkexp\r\n$HOME/harmonie_releases/trunk/config-sh/Harmonie Install","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"This uses the Harmonie MAKEUP utility to compile the code and create libraries and executables required. Further details on MAKEUP are available here: wiki:HarmonieSystemDocumentation/Buildwithmakeup","category":"page"},{"location":"Redhat7Install/#Run-an-experiment-1","page":"Redhat7","title":"Run an experiment","text":"","category":"section"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Instructions for testbed and/or local experiment are detailed here:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Your first experiment will require changes to be made to the default settings in HOME/hmhome/trunkexp/ecf/configexp.h :","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"DOMAIN=IRELAND150       ## choose a small domain to run on your limited PC.\r\n                        ## See $HOME/harmonie_releases/trunk/scr/Harmonie_domains.pm for existing definitions\r\nVLEV=HIRLAM_60          ## I only have (easy access) to HIRLAM model level files on my PC \r\nANASURF_INLINE=\"no\"     ## I have experienced some issues with my setup calling SODA from inside CANARI\r\nHOST_MODEL=\"hir\"        ## tell boundary processing that you are using HIRLAM model boundary files\r\nOBDIR=$HOME/scratch/obs ## tell Harmonie where your BUFR observation files are\r\nBDDIR=$HOME/scratch/bnd ## tell Harmonie where your input boundary files are (HIRLAM or IFS files normally)\r\nBDSTRATEGY=available    ## I use a more forgiving boundary file strategy\r\nBDINT=3                 ## I only have (HIRLAM) boundary files every 3 hours","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Once you think you have all your ducks in a row you can try to run your first experiment:","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"cd $HOME/hm_home/trunkexp\r\n$HOME/harmonie_releases/trunk/config-sh/Harmonie start DTG=2014040100 DTGEND=2014040112 LL=03 BUILD=no","category":"page"},{"location":"Redhat7Install/#","page":"Redhat7","title":"Redhat7","text":"Further details on how to use the Harmonie mini-SMS script system are available here: wiki:HarmonieSystemDocumentation/Harmonie-mSMS","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/General?action=edit\"","category":"page"},{"location":"General/#General-software-requirements-1","page":"General Software Requirements","title":"General software requirements","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"This page outlines, in a general way, the software requirements for compiling HARMONIE on a non-ECMWF platform","category":"page"},{"location":"General/#Download-HARMONIE-1","page":"General Software Requirements","title":"Download HARMONIE","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"To obtain the HARMONIE source, assuming the computer platform has a git client available, one may check out from the repository at the host hirlam.org:","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"git clone https://git.hirlam.org/Harmonie\r\ncd Harmonie\r\ngit checkout release-43h2.beta.3 # For the latest tagged version\r\ngit checkout develop             # For the development branch","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"At ECMWF, the \"checked-out\" versions are available on ecgb:","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"ecgb:/home/ms/spsehlam/hlam/harmonie_release/git/tags\r\necgb:/home/ms/spsehlam/hlam/harmonie_release/develop","category":"page"},{"location":"General/#Compilers-and-standard-software-1","page":"General Software Requirements","title":"Compilers and standard software","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"The system requires the following standard unix/linux software ","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"A fortran compiler\nA C compiler\nflex & bison for lex & yacc\nksh and bash\nperl\npython","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"Read more about the tested compilers under installation.","category":"page"},{"location":"General/#MPI-and-OpenMP-1","page":"General Software Requirements","title":"MPI and OpenMP","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"Harmonie supports parallelization through message passing or shared memory multiprocessing. ","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"mpi libraries such as mpich2, openmpi or similar.\nOpenMP libraries","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"The system can be compiled without support for MPI, but not all parts of the system can be run without MPI. The forecast model should however work fine without MPI.","category":"page"},{"location":"General/#BLAS-and-LAPACK-libraries-1","page":"General Software Requirements","title":"BLAS and LAPACK libraries","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"You need BLAS and LAPACK-lite libraries.","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"If they are already on your system, verify they have been made with the correct compiler, or rebuild them. Instructions on how to (re-)build BLAS and LAPACK follow below:","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"Download BLAS and LAPACK\nFirst build BLAS (untarring blas.tgz places it in the BLAS directory). Go to that directory, and edit make.inc to set the compiler and linker to gfortran. Then type 'make'.\nSubsequenty, for LAPACK, after untarring lapack-lite-3.1.1.tgz, go to the lapack-lite-3.1.1 directory.\nCopy make.inc.example to make.inc.\nEdit make.inc to point to the proper compiler/loader (gfortran) and to put the variable PLAT to the empty string. Set TIMER to INT_ETIME.\nCopy the blas.a library from the BLAS directory to the lapack-lite-3.1.1 directory, run ranlib on it, then type 'make'.\nThen copy the libraries in /usr/local/lib with names libblas.a and liblapack.a, respectively, otherwise the default configuration will not find them. Run ranlib on them.","category":"page"},{"location":"General/#NETCDF-1","page":"General Software Requirements","title":"NETCDF","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"Netcdf is required for some routines. Make sure you have the development version installed on your system.","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"http://www.unidata.ucar.edu/software/netcdf","category":"page"},{"location":"General/#ecCodes-1","page":"General Software Requirements","title":"ecCodes","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"ecCodes is used to access GRIB1/GRIB2","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"https://confluence.ecmwf.int/display/ECC ","category":"page"},{"location":"General/#GRIB,-BUFR-and-auxiliary-software-1","page":"General Software Requirements","title":"GRIB, BUFR and auxiliary software","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"The old software for reading GRIB1 and BUFR is included in the HARMONIE system and comprises","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"bufr 000405\ngribex 000370","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"In addition there are some extra support libraries.","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"dummies_006\nrgb_001","category":"page"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"Makeup build these libraries for you. ","category":"page"},{"location":"General/#GMTED-processing-1","page":"General Software Requirements","title":"GMTED processing","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"To process the GMTED tiff files gdal and python modules for gdal is required.","category":"page"},{"location":"General/#Observation-monitoring-1","page":"General Software Requirements","title":"Observation monitoring","text":"","category":"section"},{"location":"General/#","page":"General Software Requirements","title":"General Software Requirements","text":"To be able to extract observation feedback information sqlite3 is required.","category":"page"},{"location":"General/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"General Software Requirements","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Installation?action=edit\"","category":"page"},{"location":"Installation/#HARMONIE-System-Installation-1","page":"Installation","title":"HARMONIE System Installation","text":"","category":"section"},{"location":"Installation/#Introduction-1","page":"Installation","title":"Introduction","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"In the following the installation and compilation of system is described. Read more about how to get the system in here","category":"page"},{"location":"Installation/#Rootpack-Installation-1","page":"Installation","title":"Rootpack Installation","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Gmkpack is the ALADIN utility to compile ARPEGE/IFS","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Handle dependencies (includes/modules)\nHandle exceptions\nCompile the code\nBuild the binaries","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"A mainpack installs and builds a complete HARMONIE source (ALADIN/HIRALD/ALARO/AROME models). Generate a set of pre-compiled libraries (rootpack) and modules available for USE.  Each single user buils their own  local \"target\" pack, which synchronise local source modifications with the reference libraries.  ","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"gmapdoc","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"gmkpack vs make","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"gmkpack is intended to be installed and maintained separately. In HARMONIE it is a part of the system and used in Buildgmkpack, Buildrootpack and Build_pack","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Available main packs on cca:/project/hirlam/harmonie/pack could look like:","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"37h1harmonEPS11389.01.XLF130100000009.x 37h1harmonEPS11842.01.XLF130100000009.x 37h1harmonEPS11899.01.XLF130100000009.x 37h1main.01.XLF130100000009.x 37h1main.02.XLF130100000009.x 38h1alpha.01.XLF130100000009.x 38h1alpha.02.XLF130100000009.x 38h1_beta.01.XLF130100000009.x ","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"ie. CYCLEBRANCH.VERIONS.COMPILERVERSION.OPTION For the latest available packs please check on cca.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Supported platforms and compilers\nIBM power 7, xlf95\nIntel (g95, gfortran, intel)\nNEC\nCray, ftn","category":"page"},{"location":"Installation/#Configure-your-system-1","page":"Installation","title":"Configure your system","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"We assume you have a copy of the repository under PATHTOHARMONIE. To start the build, create an experiment directory HOME/hm_home/trunk and run","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"   PATH_TO_HARMONIE/config-sh/Harmonie setup -r PATH_TO_HARMONIE -h YOURHOST","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"The above command creates the following files/directories under","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"   config-sh/hm_rev                         # gives the path to the reference installation, similar to hl_rev in synoptic-Hirlam\r\n   config-sh/Main                           # a script to enable start Harmonie, similar to Start in synoptic-Hirlam\r\n   Env_system -> config-sh/config.YOURHOST  # describing your system, similar to Env_system in synoptic-Hirlam\r\n   Env_submit -> config-sh/submit.YOURHOST  # describing your submit commands, comparable to submission.db in synoptic-Hirlam\r\n   ecf/config_exp.h                          # defines your experiment, comparable to Env_expdesc in synoptic-Hirlam","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"In ecf/config_exp.h  you may identify the options sent to gmkpack","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"# Definitions about gmkpack, should fit with hm_rev\r\n      BUILD_ROOTPACK=${BUILD_ROOTPACK-yes}    # Build your own ROOTPACK if it doesn't exists (yes|no)\r\n                                              # This may take several hours!\r\n                                              # Make sure you have write permissions in ROOTPACK directory defined in Env_system\r\n      REVISION=38h1                           # Revision ( or cycle ) number, has to be set even for the trunk!\r\n      BRANCH=trunk\r\n      VERSION=01                              # Version of revision/branch to use\r\n      OPTION=x                                # Which gmkpack/arch/SYSTEM.HOST.OPTION file to use\r\n      OTHER_PROGRAMS=\"soda pgd blend odbtools bator ioassign odbsql blendsur addsurf surfex mandalay prep lfitools sfxtools\" # Other things to compile with gmkpack","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"You could run something different than defined in hm_rev, but then there would be a mismatch between your source code and the pre-compiled libraries/modules.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Identify your system in one of the config files in config-sh or write a new config.YOURHOST definition, make sure that some of the important optional settings are defined in this file:","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":" COMPCENTRE       # should be something else than ECMWF\r\n HM_DATA          # where you run your experiments and where you \r\n HM_LIB           # where you find the copy of the source code and the compiled libraries\r\n ROOTPACK         # where you refer/put your rootpack installations\r\n HARMONIE_CONFIG  # identifies your configuration\r\n AUXLIBS/EMOSLIB  # Path to your external libraries","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Compare e.g. with config.ecgb-cca or config.krypton.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"You also have to identify your system for gmkpack in:","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"        util/gmkpack/arch/YOURMACHINE.HARMONIE_CONFIG","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"The source code for utilities not compiled with gmkpack you find under util. There should be five config files created/edited.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"        util/gl/config/config.HARMONIE_CONFIG\r\n        util/gl_grib_api/config/config.HARMONIE_CONFIG\r\n        util/monitor/config/config.HARMONIE_CONFIG\r\n        util/oulan/config.HARMONIE_CONFIG\r\n        util/conrad/config.HARMONIE_CONFIG\r\n","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"The makefiles themselves should not have to be edited.","category":"page"},{"location":"Installation/#Submission-rules-1","page":"Installation","title":"Submission rules","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Next you have to identify your submit file in config-sh or write a new submit.YOURHOST file. This file defines how you submit your jobs in your local batch system.  The routine get_job is called from submission.db and should return the appropriate batch header including some environment variables specifying the parallel decomposition. The way the header is constructed could be different on different hosts as long as the appropriate header is returned.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"On ecgb-cca three list of jobs are created:","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"backg_list for jobs running as background jobs on ecgb\nscalar_list single PE jobs on cca\npar_list for parallel jobs on cca","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"The scalar_list is the default one, meaning that any unspecified job will be run as a single PE job on HPCE. Default values are defined for each list. Special settings for special jobs can be set like:","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":" $job_list{'Prep_ini_surfex'}{'RESOURCES'} = $submit_type.'resources = ConsumableCPUs(1) ConsumableMemory(6000 MB)' ;","category":"page"},{"location":"Installation/#Running-the-installation-1","page":"Installation","title":"Running the installation","text":"","category":"section"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Start the compilation of the rootpack :","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"      PATH_TO_HARMONIE/config-sh/Harmonie install","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"The suite definition file used for the installation is  Install_rootpack.tdf. The installation is just like running an experiment.","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Where are things happening","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Build_gmkpack \nBuild_rootpack\nrsync the sources from HMREV, HMCMODS, HM_LIB\ncleanpack\ncompiles the ODB compiler\ncompiles IFS\nlocks the pack","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"Build_pack\nbuild everything in the OTHERPROGRAMS list. This is done inside HMDATA/gmkpack_build\nbuild the utilities (gl/verobs/oulan)","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"When things goes wrong","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"ics* can be run stand alone from the ROOTPACK or `HMDATA/gmkpack_build` directory\nTurn off the compilation and linking\nbuild the libraries by running the ics_* file by hand\nBUILD_ROOTPACK=no, put the corrections to the failing code in your experiment\nrerun Harmonie install","category":"page"},{"location":"Installation/#","page":"Installation","title":"Installation","text":"The main task for the installation is to compile the rootpack. However, the binaries created are never used by any other experiment.","category":"page"},{"location":"Installation/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Installation","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"Content/#","page":"Directories","title":"Directories","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Content?action=edit\"","category":"page"},{"location":"Content/#Harmonie-Content-1","page":"Directories","title":"Harmonie Content","text":"","category":"section"},{"location":"Content/#Overview-1","page":"Directories","title":"Overview","text":"","category":"section"},{"location":"Content/#","page":"Directories","title":"Directories","text":"Harmonie is HIRLAM's adaptation of the LAM version of the IFS/ARPEGE project. The common code shared with the ALADIN program, Meteo France and ECMWF only contains the source code. Harmonie adds the build environment, scripts, support for a scheduler, and a number of diagnostics tools for file conversion and postprocessing. In summary a download of harmonie from the repository, [https://git.hirlam.org/Harmonie] contains the following main directories","category":"page"},{"location":"Content/#","page":"Directories","title":"Directories","text":"config-sh : Configuration and job submission files for different platforms.\nconst : A selected number of constant files for bias correction, assimilation and different internal schemes. A large number of data for climate generation and the RTTOV software is kept outside of the repository. See [* ecf : Directory for the main configuration file config_exp.h(../HarmonieSystemDocumentation.md#Downloaddata].","category":"page"},{"location":"Content/#","page":"Directories","title":"Directories","text":") and the containers for the scheduler ECFLOW.","category":"page"},{"location":"Content/#","page":"Directories","title":"Directories","text":"suites Scripts and suit definition files for mSMS, the scheduler for HARMONIE. \nnam : Namelists for different configurations.\nscr : Scripts to run the different tasks.\nsrc : The IFS/ARPEGE source code.\n[#util util] : A number of utilities and support libraries.","category":"page"},{"location":"Content/#util-1","page":"Directories","title":"util","text":"","category":"section"},{"location":"Content/#","page":"Directories","title":"Directories","text":"The util directory contains the following main directories","category":"page"},{"location":"Content/#","page":"Directories","title":"Directories","text":"auxlibs : Contains gribex, bufr, rgb and some dummy routines\nbinutils : https://www.gnu.org/software/binutils/\nchecknorms : Script for code norm checking\nglgribapi : Boundary file generator and file converter\nmakeup : HIRLAM style compilation tool\nmusc : MUSC scripts\nobsmon : Code to produce obsmon sqlite files\noffline : SURFEX offline code\noulan : Converts conventional BUFR data to OBSOUL format read by bator.\nRadarDAbyFA : Field alignment code","category":"page"},{"location":"Content/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Directories","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"UpdateNamelists/#","page":"Update Namelist","title":"Update Namelist","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/UpdateNamelists?action=edit\"","category":"page"},{"location":"UpdateNamelists/#Update-the-namelist-hashes-1","page":"Update Namelist","title":"Update the namelist hashes","text":"","category":"section"},{"location":"UpdateNamelists/#Introduction-1","page":"Update Namelist","title":"Introduction","text":"","category":"section"},{"location":"UpdateNamelists/#","page":"Update Namelist","title":"Update Namelist","text":"Each namelists is build from a perl dictionary of different settings,  harmonie_namelists.pm as the deviation from the default setup. One section takes care of the general file settings, one of the mpp options and the large ones of different configurations. The script  gen_namelists.pl allows us to build new namelists adding the settings on top of each other. In the following we describe how to add new namelists and include them in the suite.","category":"page"},{"location":"UpdateNamelists/#Create-a-new-hash-module-1","page":"Update Namelist","title":"Create a new hash module","text":"","category":"section"},{"location":"UpdateNamelists/#","page":"Update Namelist","title":"Update Namelist","text":"Let us assume we have some new 4DVAR namelists we would like to merge. Create a directory, 4dvar, and put your new namelists in here. Run the script  Create_hashes.pl","category":"page"},{"location":"UpdateNamelists/#","page":"Update Namelist","title":"Update Namelist","text":"./Create_hashes.pl 4dvar\r\nCreate namelist hash for 4dvar \r\nScan 4dvar/namscreen_dat_4d \r\nScan 4dvar/namtraj_1_4d \r\nScan 4dvar/namvar_dat_4d \r\nCreate namelist hash 4dvar.pm \r\nCreate updated empty namelist hash empty_4dvar.pm for 4dvar","category":"page"},{"location":"UpdateNamelists/#","page":"Update Namelist","title":"Update Namelist","text":"We have now created a perl module for the new namelists. One with empty namelist entries, 4dvar_empty.pm, and one with all namelists in the right format, 4dvar.pm. To get one of your namelists back ( sorted ) you can write:","category":"page"},{"location":"UpdateNamelists/#","page":"Update Namelist","title":"Update Namelist","text":"./gen_namlist.pl -n 4dvar_empty.pm -n 4dvar.pm namscreen_dat_4d","category":"page"},{"location":"UpdateNamelists/#","page":"Update Namelist","title":"Update Namelist","text":"To get the module integrated in the system the module has to be merged with the conventions in harmonie_namelists.pm, but as a start the full namelists can be used. Copy the new empty*.pm to empty.pm to get the updated list of empty namelists.","category":"page"},{"location":"UpdateNamelists/#Create-the-new-namelist-1","page":"Update Namelist","title":"Create the new namelist","text":"","category":"section"},{"location":"UpdateNamelists/#","page":"Update Namelist","title":"Update Namelist","text":"Add the new namelists to the script Get_namelist. In this case we would add a new case for 4dvar","category":"page"},{"location":"UpdateNamelists/#","page":"Update Namelist","title":"Update Namelist","text":"4dvartraj) \r\n   NAMELIST_CONFIG=\"$DEFAULT minimization dynamics ${DYNAMICS} ${PHYSICS} ${PHYSICS}_minimization ${SURFACE} ${EXTRA_FORECAST_OPTIONS} varbc minim4d\"\r\n    ;;","category":"page"},{"location":"UpdateNamelists/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Update Namelist","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/TheHarmonieScript?action=edit\"","category":"page"},{"location":"TheHarmonieScript/#The-Harmonie-main-script-1","page":"The Harmonie Script","title":"The Harmonie main script","text":"","category":"section"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"The Harmonie script is the main user interface to the harmonie system. It is used to setup, start, check and control your experiment and environment. Below follows the most useful commands. There are other commands inherited from the HIRLAM environment that may or may not work. For a full list check Start, Actions, Actions.pl.","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"Harmonie setup [ -r REVISION] [ -h HOST] [ -d DOMAIN] [ -c CONFIGURATION] [ -l LEVELS] where:\nREVISION is the path to the version of harmonie you are working with.\nHOST is the name of the host you are working on. There should exist corresponding config-sh/config.HOST. \nCONFIGURATION is one of the predefined configurations in scr/Harmonie_testbed.pl. It a fast way to setup your favourite configuration.\nDOMAIN is one of the predefined domains in ecf/config_exp.h \nLEVELS is one of the predefined level definitions in scr/Vertical_levels.pl","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"Harmonie start DTG=YYYYMMDDHH [ DTGEND=YYYYMMDDHH] [ optional environment variables] launches a cold start run.\nDTG is the initial time of your experiment\nSeveral other optional variables can be given like\nPLAYFILE=FILENAME use a different ecflow suite definition file. Default is harmonie.tdf\nBUILD=yes|no to turn on and off compilation\nCREATE_CLIMATE=yes|no to turn on and off generation of climate files\nAny environment variable that you would like to send to the system.","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"Harmonie prod will continue from the DTG given in your progress.log file. The rest of the arguments is as for Harmonie start. This should be used to continue and experiment. It is assumed that a first guess file is available and the run will fail if this is not found.    ","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"Harmonie mon will restart your ecflow_ui window and try to connect to an existing ecflow server.","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"Harmonie co [FILE|PATH/FILE] will copy the request file from the version chosen in your setup ( as pointed out in the config-sh/hm_rev file ) to your local directory. If the PATH is not given a search will be done. If the name matches several files you will be given a list to choose from.","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"Harmonie install will build your libraries and binaries but not start any experiment","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"Harmonie testbed will launch the Harmonie testbed","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"Harmonie diff [--xxdiff] will look for differences between the revision in config-sh/hmrev and HMLIB.","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"Harmonie CleanUp -ALL -go will clean the following directories: HMDATA,HMLIB,HM_EXP. Instructions from Actions.pl:","category":"page"},{"location":"TheHarmonieScript/#","page":"The Harmonie Script","title":"The Harmonie Script","text":"# args: if -go: remove, (default is to list but not remove the matching files)\r\n#       if -k*: do not do the long term archive HM_EXP - so keep it\r\n#       if -d*: combination of -k and -ALL (-d* means: disks)\r\n#       if -ALL: treat all files and also (if -go) remove the directories\r\n#       a pattern is usually a string without meta-characters. To this\r\n#       a * is appended (so e.g. ob will affect all files ob*); this can\r\n#       be inhibited by appending ~ (so ob~! translates to ob).\r\n#       Also, files in all subdirectories P*_* will be affected\r\n#       where P is the pattern [0-9][0-9], This resembles\r\n#       a `CYCLEDIR'. So ob will result in 'ob* P*_*/ob*'.\r\n#       The pattern P*_* will be prepended to every / in the pattern,\r\n#       unless the / is preceded by ~ (which will be removed).\r\n#       Hence, to remove e.g. all analyses from 1995, use 1995/an,\r\n#       which translates to 1995[0-9][0-9]*_*/an*\r\n#       (to be precise: use: CleanUp(\"REMOVE:1995/an\", \"-go\");","category":"page"},{"location":"TheHarmonieScript/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"The Harmonie Script","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ObservationHowto/GNSS?action=edit\"","category":"page"},{"location":"ObservationHowto/GNSS/#GNSS-ZTD-observations-1","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"","category":"section"},{"location":"ObservationHowto/GNSS/#Introduction-1","page":"GNSS ZTD observations","title":"Introduction","text":"","category":"section"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"The NRT GNSS delay data contain information about the amount of water vapour above the GNSS sites.  E-GVAP European program’s aim is to provide its EUMETNET members with European GNSS delay and water vapour estimates for operational meteorology in near real-time. Currently, the E-GVAP network consists of more than 1500 GNSS sites.","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"E-GVAP Programme here: [http://egvap.dmi.dk]","category":"page"},{"location":"ObservationHowto/GNSS/#GNSS-ZTD-data-1","page":"GNSS ZTD observations","title":"GNSS ZTD data","text":"","category":"section"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"Raw data from GNSS sites are collected by a number of GNSS analysis centers, which process the data to estimate the Zenith Total Delays (ZTD) and other parameters. The ZTDs are then forwarded to a data server, for distribution to meteorological institutes. The observations are currently distributed from Met Office, in two different formats: BUFR that are distributed via GTS to the meteorological centers or in ASCII format, that may be download via ftp.","category":"page"},{"location":"ObservationHowto/GNSS/#Preprocessing-the-GNSS-ZTD-data-1","page":"GNSS ZTD observations","title":"Preprocessing the GNSS ZTD data","text":"","category":"section"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"The preprocessing of these data should be local, depending if you want to have them in BUFR or ASCII format.  ASCII option needs a local script to get the files from Metoffice server and transform them from COST format (EGVAP) into OBSOUL format. (In this case there is an optional script inside scr directory in Harmonie called GNSStoOBSOUL that could transforms ascii into OBSOUL format).","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"Apart of the preprocessing, a White List of sites to be assimilated in your domain is needed. It will contain the values of:","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"   statid lat lon alt dts bias sd obserr","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"where statid is the name of the site (NNNNPPPP: NNNN=site PPPP=Procesing centre) , dts is the frequency in minutes between obs, and sd the standard deviation of that station  and obserr the observation error. You are supposed to have calculated these values before launching the experiment.","category":"page"},{"location":"ObservationHowto/GNSS/#Harmonie-changes-to-assimilate-GNSS-ZTD-data-1","page":"GNSS ZTD observations","title":"Harmonie changes to assimilate GNSS ZTD data","text":"","category":"section"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"scr/","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"Bator and Fetchassimdata have the white list path.\nOulan : has the white list and gnss observation files paths and cat this one to the rest of conventional observation file.   \ninclude.ass: ","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"This script has two options about gnss bias correction: static bias correction (LSTATICBIAS) or variational bias correction (LVARBCGNSS).  For the first case, a fix bias value from each site is read from the White List and then substracted from the corresponding observation value. For the second case, VarBC, it is also  needed to set in this script the  cold start option.","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":" export GNSS_OBS=1            #GNSS\r\n export LSTATIC_BIAS=F        #Swich for bias correction or not,(T|F)\r\n export LVARBC_GNSS=T         #Swich for GNSS varbc\r\n export VARBC_COLD_START=yes  #yes/no","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"nam/  Here it should be the White list, called list.gpssol.201512 for example  /src/arpifs/obs_preproc/","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"redgps.F90 : This routine is where the horizontal thinning is done (Cy40) , so the thinning distance  could be selected here.","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"/src/blacklist/","category":"page"},{"location":"ObservationHowto/GNSS/#","page":"GNSS ZTD observations","title":"GNSS ZTD observations","text":"mf_blacklist.b: here is posible to blacklist the gnss observations so to calculate the varbc coefficients. It can be done tuning to experimental the apdss variable.","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ClimateGeneration?action=edit\"","category":"page"},{"location":"ClimateGeneration/#Generation-of-climate-and-physiography-files-1","page":"Climate","title":"Generation of climate and physiography files","text":"","category":"section"},{"location":"ClimateGeneration/#Introduction-1","page":"Climate","title":"Introduction","text":"","category":"section"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"The generation of climate files includes two parts. The first part is the generation of climate files for the atmospheric model, the so called  e923 configuration. The second part is the generation of the physiography information for  SURFEX. In the following we describe how it is implemented in HARMONIE.","category":"page"},{"location":"ClimateGeneration/#Input-data-for-climate-generation-1","page":"Climate","title":"Input data for climate generation","text":"","category":"section"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"The location of your input data for the climate generation is defined by the HM_CLDATA environment variable defined in the config.yourhost file. At ECMWF the climate data is stored on cca here: cca:/project/hirlam/harmonie/climate_in_order","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"Information on what data to download is available here: [wiki:HarmonieSystemDocumentation#Downloadinputdata]. The input data contains physiography data, topography information and climatological values determined from a one year ARPEGE assimilation experiment with a resolution of T79. ","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"In the current version the option to use pre-generated climate files has been introduced to saver time for quick experiments. To use pre-generated domains you need to set USEREFCLIMDIR=yes in Envsystem. The regenerated domains location is defined in configexp.h and in ECMWF are located in REFCLIMDIR=ec:/hlam/harmonieclimdir/release-43h2.1.rc1/DOMAINECOCLIMAP_VERSION.","category":"page"},{"location":"ClimateGeneration/#Preparation-of-SURFEX-physiography-file-1","page":"Climate","title":"Preparation of SURFEX physiography file","text":"","category":"section"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"SURFEX needs information about the distribution of different available tiles like nature, sea, water and town. The nature tile also needs information about type of vegetation and soiltypes. The main input sources for this are found at SURFEX physiographic maps.","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"The data base for SURFEX-file preparation is located under HM_CLDATA/PGD","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"ecoclimats_v2.* : Landtypes\ngtopo30.* : Topography\nsand_fao.* : Soil type distribution\nclay_fao.* : Soil type distribution","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"The generation of SURFEX physiography file (PGD.lfi) is done in Prepare_pgd. The script creates the namelist OPTIONS.nam based on the DOMAIN settings in Harmonie_domains.pm. Note that the SURFEX domain is only created over the C+I area. In the namelist we set which scheme that should be activated for each tile.","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"| ||||| Tile |  | –- | –- | –- | –- | –- | –- |  |= PHYSICS =|= Nature =|= Sea =|= Water =|= Town =|  |AROME  |ISBA  |SEAFLX|WATFLX |TEB         |  |ALARO  |ISBA  |SEAFLX|WATFLX |Town as rock|","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"The program PGD produces one SURFEX physiography file (PGD.lfi), which is stored in CLIMDIR directory.","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"To make sure we have the same topography input for the atmospheric part we call Prepare_pgd two times. One time to produce a PGD.lfi for SURFEX and a second time to produce a PGD.fa file that can be used as input for the climate generation described below. Note that for the atmosphere the topography will be spectrally filtered and the resulting topography will be imposed on SURFEX again.","category":"page"},{"location":"ClimateGeneration/#Generation-of-a-non-SURFEX-climate-file-1","page":"Climate","title":"Generation of a non SURFEX climate file","text":"","category":"section"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"Climate is a script, which prepares climate file(s) for  prefered forecast range. Climate files are produced for past, present and following month. The outline of Climate is as follows:","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"Check if climate files already exists.\nCreation of namelists. The definition of domain and truncation values is taken from Harmonie_domains.pm.\nPart 0: Read the PGD.fa file generated by SURFEX and write it to Neworog\nPart 1: Filter  Neworog to target grid with spectral smoothing to remove 2dx waves.\nPart 2: generation of surface, soil and vegetation variables, without annual variation.\nPart 3: creation of monthly climatological values and  modification of albedo and emissivity according to the climatology of sea-ice limit.\nPart 4: definition and modification of the vegetation and surface characteristics\nPart 5: modification of fields created by step 2 and 4 over land from high resolution datasets (for each month)\nPart 6: modification of climatological values","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"The result is climate files for the previous, current and next month. The files are named after their month like m01, m02 - m12 and stored in CLIMDIR.","category":"page"},{"location":"ClimateGeneration/#","page":"Climate","title":"Climate","text":"Further reference e923","category":"page"},{"location":"ClimateGeneration/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Climate","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/MFaccess?action=edit\"","category":"page"},{"location":"MFaccess/#Using-Météo-France-Servers-1","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"","category":"section"},{"location":"MFaccess/#Introduction-1","page":"Using Météo-France Servers","title":"Introduction","text":"","category":"section"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"The procedure to get access to MF servers and their read-only git repository is outlined here","category":"page"},{"location":"MFaccess/#First-steps-1","page":"Using Météo-France Servers","title":"First steps","text":"","category":"section"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"Discuss your requirements for access to MF servers with the HIRLAM System project leader, Daniel Santos (dsantosm@aemet.es).\nDownload two forms \"Undertaking for the use of Météo-France computer resources\" and \"Demande d'authorisation de conexion au résau de Météo Franc\" from http://www.cnrm.meteo.fr/aladin/spip.php?article157. \nThe \"Undertaking for the use of Météo-France computer resources\" form  is to be signed by you only\nThe \"Demande d'authorisation de conexion au résau de Météo Franc\" must be signed by you and your department head. It must also include an institute stamp. You should enter details in Contacts, Compte d'accesés aux machines du Centre de Cacul and at the bottom with authorization from you institute manager with institute stamp.   - A scan of both forms with a brief introductory note should be sent to Eric Escaliere (eric.escaliere@meteo.fr) and cc'ed to Daniel Santos (dsantosm@aemet.es) and Claude Fischer (claude.fischer@meteo.fr).\nBe careful with the \"Machine du client\". I had to specify the name and IP address of my institute's Firewall server as this is what the outside world sees when I access external servers from my PC.\nMétéo-France will send (by post) your username (Identificateur) and password (Mot de passe) for log in.\nThe authentication process itself remains in two steps (first “parme”, then target), as before. \nA few specific examples follow (see howtoconnecttoFWafterCorr.pdf, MF's instructions for full details):\nbeaufix:","category":"page"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"ewhelan@realin23:gcc-8.3.1:.../~> which beaufix\r\nalias beaufix='telnet beaufix.meteo.fr'\r\n\t/usr/bin/telnet\r\newhelan@realin23:gcc-8.3.1:.../~> beaufix \r\nTrying 137.129.240.110...\r\nConnected to beaufix.meteo.fr.\r\nEscape character is '^]'.\r\nCheck Point FireWall-1 authenticated Telnet server running on mascarpone\r\nUser: whelane\r\npassword: your_parme_password\r\nUser whelane authenticated by FireWall-1 authentication\r\n\r\nConnected to 137.129.240.110\r\nRed Hat Enterprise Linux Server release 6.9 (Santiago)\r\nKernel 2.6.32-696.6.3.el6.x86_64 on an x86_64\r\nbeaufixlogin0 login: whelane\r\nPassword: your_ldap_password\r\nLast login: Tue Oct 13 10:15:53 from gw2.met.ie\r\n _                           __  _       \r\n| |                         / _|(_)      \r\n| |__    ___   __ _  _   _ | |_  _ __  __\r\n| '_ \\  / _ \\ / _` || | | ||  _|| |\\ \\/ /\r\n| |_) ||  __/| (_| || |_| || |  | | >  < \r\n|_.__/  \\___| \\__,_| \\__,_||_|  |_|/_/\\_\\ \r\n\r\n[whelane@beaufixlogin0 ~]$ ","category":"page"},{"location":"MFaccess/#What-next?-**TO-BE-CONFIRMED**-1","page":"Using Météo-France Servers","title":"What next? TO BE CONFIRMED","text":"","category":"section"},{"location":"MFaccess/#Access-to-MF-servers-via-parme-1","page":"Using Météo-France Servers","title":"Access to MF servers via parme","text":"","category":"section"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"Once you are happy that you can access PARME from your PC you should once again contact Eric Escaliere (eric.escaliere@meteo.fr) and request login details for merou (Eric will send you a temporary password) and LDAP login details to front-id to enable access to COUGAR, YUKI, BEAUFIX and ID-FRONT\nAn automatic e-mail will be sent from expl-identites@meteo.fr with you LDAP repository password.\nfront-id requires certain criteria for your password. These are detailed in French below. When you have received LDAP login details for front-id:","category":"page"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"ewhelan@eddy:~> telnet parme.meteo.fr\r\nTrying 137.129.20.1...\r\nConnected to parme.meteo.fr.\r\nEscape character is '^]'.\r\nCheck Point FireWall-1 authenticated Telnet server running on parmesan\r\nUser: whelane\r\npassword: ********\r\nUser whelane authenticated by FireWall-1 authentication\r\nHost: front-id\r\n\r\nConnected to id-front\r\nRed Hat Enterprise Linux AS release 4 (Nahant Update 5)\r\nKernel 2.6.9-55.ELsmp on an x86_64\r\nlogin: whelane\r\nPassword: \r\nLast login: Mon Nov  4 05:14:22 from gw2.met.ie\r\nBienvenue EOIN WHELAN\r\nVous pouvez changer votre mot de passe\r\n-------------------------------------------------------------------------\r\n- Controle de validite sur les mots de passe avant de poster la demande -\r\n- Le OLD doit etre fourni. -\r\n- Au moins 8 car, au plus 20 car. -\r\n- Au moins 2 car. alpha et 2 car. non-alpha. -\r\n- Ne pas ressembler a UID NAME et OLD sur une syllabe de + de 2 car. -\r\n-------------------------------------------------------------------------\r\n-------------------------------------------------------------------------\r\nHello EOIN WHELAN\r\nYou may change your password\r\n-------------------------------------------------------------------------\r\n- Validity control before demand acceptation -\r\n- You must enter the old password first -\r\n- The new password must contain: -\r\n- At least 8 characters, 20 characters maximum -\r\n- At least 2 alphanumeric characters and 2 non-alphanumeric characters -\r\n- The passwd must contain a part of UID NAME -\r\n-------------------------------------------------------------------------\r\nChanging password for user 'whelane(56064)'.\r\nEnter login(LDAP) password: \r\nNew password: \r\nRe-enter new password: \r\nVotre mot de passe a ete change\r\n","category":"page"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"When you have received login details for merou from Eric:","category":"page"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"ewhelan@eddy:~> telnet parme.meteo.fr\r\nTrying 137.129.20.1...\r\nConnected to parme.meteo.fr.\r\nEscape character is '^]'.\r\nCheck Point FireWall-1 authenticated Telnet server running on parmesan\r\nUser: whelane\r\npassword: ********\r\nUser whelane authenticated by FireWall-1 authentication\r\nHost: merou\r\n\r\nConnected to merou\r\nRed Hat Enterprise Linux Server release 5.6 (Tikanga)\r\nKernel 2.6.18-238.el5 on an x86_64\r\nlogin: whelane\r\nPassword: \r\nLast login: Tue Nov  5 10:06:35 from gw2.met.ie\r\n[whelane@merou ~]$ passwd\r\nChanging password for user whelane.\r\nChanging password for whelane\r\n(current) UNIX password: \r\nNew UNIX password: \r\nRetype new UNIX password: \r\npasswd: all authentication tokens updated successfully.\r\n[whelane@merou ~]$ ","category":"page"},{"location":"MFaccess/#Access-to-(read-only)-MF-git-arpifs-git-repository-1","page":"Using Météo-France Servers","title":"Access to (read-only) MF git arpifs git repository","text":"","category":"section"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"MF use ssh keys to allow access to their read-only git repository. If approved by the HIRLAM System PL you should request access to the repository by sending a request e-mail to Eric Escaliere (eric.escaliere@meteo.fr) and cc'ed to Daniel Santos (dsantosm@aemet.es) and Claude Fischer (claude.fischer@meteo.fr) your ssh public key attached.","category":"page"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"Once you have been given access you can create a local clone by issuing the following commands:","category":"page"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"cd $HOME\r\nmkdir arpifs_releases\r\ncd arpifs_releases\r\ngit clone ssh://reader054@git.cnrm-game-meteo.fr/git/arpifs.git","category":"page"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"Happy gitting!","category":"page"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"Back to the main page of the HARMONIE System Documentation","category":"page"},{"location":"MFaccess/#","page":"Using Météo-France Servers","title":"Using Météo-France Servers","text":"","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PostPP/Verification?action=edit\"","category":"page"},{"location":"PostPP/Verification/#HARMONIE-Verification-1","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"","category":"section"},{"location":"PostPP/Verification/#Introduction-1","page":"HARMONIE Verification","title":"Introduction","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The verification package in HARMONIE is designed to be a self contained stand alone package dealing with pre-extracted model and observational data. The package calculates several standard verification scores such as:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"* Error as function of forecast lead time summarises the bias and rms­ error and their growth rate over a set of forecasts\r\n* Time sequences and vertical profiles show how your data or error characteristic is distributed in time or in the vertical\r\n* Error charts and tables show how some error is distributed in space, and station­wise linear correlation\r\n* Scatter plots show the correspondence between forecast and observed values\r\n* Mean diurnal cycles show how your mean error changes in the course of the day\r\n* Histograms show the correspondence between the distributions of forecast and observed values\r\n* Student t-test to show how reliable differences between different experiments are","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"In addition there are a number of scores based on contingency tables like:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"* **Frequency bias (bias score)**: (h+fa)/(h+m); Compares the frequency of predicted events to the frequency of observed events. *Range: 0 -> infinite. Perfect score: 1*\r\n* **Hit rate (probability of detection)**: h/(h+m); What fraction of the observed events were correctly forecast. *Range: 0 to 1.  Perfect score: 1.* \r\n* **False alarm ratio**: fa/(h+fa); What fraction of the predicted events did not occur. *Range: 0 to 1.  Perfect score: 0.*\r\n* **False alarm rate**: fa/((cn+fa); What fraction of the observed \"no\" events were incorrectly forecast as \"yes\". *Range: 0 to 1. Perfect score: 0.*\r\n* **Threat score**: h/(h+m+fa); How well did the forecast \"yes\" events correspond to the observed \"yes\" events. *Range: 0 to 1. Perfect scrore: 1.*\r\n* **The Equitable threat score** takes into account the number of random hits (R) and is less sensitive to climatology: ETS=(h­R)/(h+m+fa­R),  R=(h+m)(h+fa)/(h+m+fa+cn). Often used in verification of precipitation. *Range: -1/3 to 1, 0 indicates no skill.   Perfect score: 1.* \r\n* **Hansen­Kuipers score**: (h/(h+m) ­ fa/(fa+cn)), How well did the forecast separate events from non­events. *Range: -1 to 1, 0 indicates no skill. Perfect score: 1.*\r\n* **Extreme Dependency Scores**: What is the association between forecast and observed rare events? *Range: -1 to 1, 0 indicates no skill. Perfect score: 1*","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"A more detailed explanation about verification can found at [http://www.cawcr.gov.au/projects/verification/]","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The scores can be presented per station for the whole data set or filtered through different selection criteria based on e.g. a geographical domain or properties of the data itself. One key feature missing in earlier HIRLAM verification packages is that the comparison is done over exactly the same set of data ( in time and space ) when comparing different experiments or models. The scores are finally presented with a portable web interface, [#WebgraF WebgraF], that allows you to easily share the information with others. Since the verification is station based it is less suitable for moving platforms or fields.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Other examples on how products from the verification package looks like today can be found here:     * The monitor test data set     * FMI     * Mast verification     * HIRLAM verification portal","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"In the following we describe the different parts of the verification package. For preparation of verification data read more here.","category":"page"},{"location":"PostPP/Verification/#Getting-and-compiling-the-code-1","page":"HARMONIE Verification","title":"Getting and compiling the code","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The verification code can be fetched from the hirlam code repository by","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"git clone https://git.hirlam.org/monitor\r\ncd monitor","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"For a specific version do ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\ngit ls-remote \r\nUsername for 'https://git.hirlam.org': uandrae\r\nPassword for 'https://uandrae@git.hirlam.org': \r\nFrom https://git.hirlam.org/monitor\r\n6e733fdaf0b47aefbd62721a33c10d30b9320759\tHEAD\r\n6e733fdaf0b47aefbd62721a33c10d30b9320759\trefs/heads/master\r\n9c0aa45d658edc052f427c9f1d750f31732f64cb\trefs/tags/v1.0\r\n20dcc868000e94e3f3178e38cf661befff6d9e03\trefs/tags/v1.0^{}\r\n7817776b7676ecf80020d0e4994a02fef3870d36\trefs/tags/v1.1\r\n2989b8ff40de90abb2dde1521350107e2770aef5\trefs/tags/v1.1^{}\r\n...\r\n\r\ngit checkout vX.X\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The checkout gives you the following directories:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"cmastat: for assimilation monitoring, not covered here\nconfig: configuration files for different platforms\ndoc: README files\nmod: Different modules. module_data.f90 contains all namelist variables\nprg: Main programs\nrdr: Routines for reading data\nscr: Scripts\nsrc: The hard core verification routines\ntools: Compilation tools\nWebgraF: The web interface","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"You compile by finding the appropriate configuration file for your platform and type","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"gmake ARCH=YOUR_ARCH","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The package has no external dependencies but relies on gnuplot for generation of the graphics.","category":"page"},{"location":"PostPP/Verification/#The-verification-step-by-step-1","page":"HARMONIE Verification","title":"The verification step by step","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The strategy in the verification is to separate the data input from the calculations of the different scores. This allows as to go through the data several times using different filtering criteria. Of course keeping everything in memory sets a limit on how much data one can handle at the same time. In the way it's used in HARMONIE a typical sequence is:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Read namelist\nCall my_choices\nRead observations\nRead model data\nPerform quality control","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Loop over all namelists\nSelection of data \nCalculate the scores and write data\nCheck for new namelist","category":"page"},{"location":"PostPP/Verification/#Reading-the-data-1","page":"HARMONIE Verification","title":"Reading the data","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The program can handle several data sources. Which one you use is depending on the value of DATA_SOURCE and is controlled in the routine my_choices.f90. At namelist level we also control which experiments we should read, the period (SDATE,EDATE), interval between cycles (FCINT), which forecasts (FCLEN) and the interval of the observations (OBINT). We can also already at this point select which stations to use by specifying a station list (STNLIST). ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The HARMONIE tools to extract data for verifiation are described in here.","category":"page"},{"location":"PostPP/Verification/#A-general-input-format-1","page":"HARMONIE Verification","title":"= A general input format=","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"For the every day verification the model and observation data are read with the routines ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"read_vfld.f90read_vobs.f90readvfldtemp.f90readvobstemp.f90 Where the two first are for surface data and are used when DATA_SOURCE=vfld and the two latter for temp data and are used when DATASOURCE=vfldtemp. During the evolution of the verification package the format of the input data has changed and we are now at version four. The new format allows an arbitrary number of different types of point data to be included in the model vfld- or observation vobs- files.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The generalized input format is defined as ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"nstation_synop nstation_temp version_flag  # written in fortran format '(1x,3I6)' )\r\n# where version_flag == 4\r\n# If ( nstation_synop > 0 ) we read the variables in the file, their descriptors and\r\n# their accumulation time\r\n#\r\nnvar_synop\r\nDESC_1 ACC_TIME_1\r\n...\r\nDESC_nvar_synop ACC_TIME_nvar_synop\r\n# Station information and data N=nstation_synop times\r\nstid_1 lat lon hgt val(1:nvar_synop)\r\n...\r\nstid_N lat lon hgt val(1:nvar_synop)\r\n\r\n# If ( nstation_temp > 0 )\r\nnlev_temp\r\nnvar_temp\r\nDESC_1 ACC_TIME_1\r\n..\r\nDESC_nvar_temp ACC_TIME_nvar_temp\r\n# Station information and data nstation_temp times\r\n# and station data nlev_temp times for each station\r\nstid_1 lat lon hgt\r\npressure(1) val(1:nvar_temp)\r\n...\r\npressure(nlev_temp) val(1:nvar_temp)\r\nstid_2 lat lon hgt\r\n...","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The accumulation time allows us to e.g. easily include different precipitation accumulation intervals. Any variable can be included in the file and verified without any code changes. Once you have defined a variable in your data you have to describe its properties in the plotdefs.pm described in the [#Settingsfordifferentmeteorologicalparameters parameter setting section].","category":"page"},{"location":"PostPP/Verification/#Quality-control-1","page":"HARMONIE Verification","title":"Quality control","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The quality control is activated by the namelist flag LQUALITY_CONTROL. It is mainly there as a gross error check to remove the unrealistic observations. The check has the following features:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The forecast lengths used for quality control can be set by namelist variable QCFCLEN. If QCFCLEN is not set The forecasts < FORECAST_INTERVAL will be used.\nAn observation is accepted if ABS(mod - exp) < err_limit for ANY experiment used in the verification. \nThe quality control limits can be set explicitly in namelist by VARPROP%LIM for any variable or by QC_LIM for all variables. See the section about [ #Settingsfordifferentmeteorologicalparameters parmeter settings] for further instructions.\nBy setting ESTIMATEQCLIMIT the QCLIM will be set as SCALEQCLIM * STDV for the forecasts in QCFCLEN.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"QC diagnostic information output may be controlled by PRINTQC={0,1,2}. It is also possible to blacklist stations through the *STNLISTBL* parameter.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"In the HARMONIE implementation all quality control levels are estimated on the fly with a limit where the standard deviation is scaled by 5.","category":"page"},{"location":"PostPP/Verification/#The-selection-process-1","page":"HARMONIE Verification","title":"The selection process","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Before we run through the actual comparison of data we can select a subset of the data depending on different criteria.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Initial time of the forecast (INI_HOURS)\nSelect data that are valid at a certain hour (SHOW_TIMES) \nPick only some of the forecast lengths in memory (USE_FCLEN)\nSelection using a station list (STNLIST)\nSelect to produce statistics for some selected stations in addition to the overall statistics (STNLIST_PLOT)\nDefine a geographical box through the definition of the corners (CBOX%ACTIVE,CBOX%S,CBOX%W,CBOX%N,CBOX%E).\nUse an area defined by a polygon (LPOLY,POLYFILE)\nSelect by station height (HGTLLIM,HGTULIM)\nConditions given by the data (described later)\nReverse all selections but the conditional (REVERSE_SELECTION)","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Of course all the selections can be combined.","category":"page"},{"location":"PostPP/Verification/#The-verification-loop-1","page":"HARMONIE Verification","title":"The verification loop","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"For each station we loop over all selected stations, initial times, forecast lengths for the given period and accumulate the statistics. Data is stored by:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Statistic by forecast length or time of day, for each station and accumulated for all stations and is used to generate error maps(MAP), vertical profiles(VERT), standard forecast length verification(GEN) and daily variation scores (DAYVAR)\nTime serie arrays for each station and accumulated for all stations (TIME)\nOne array containing all the selected data used for scatter plots (SCAT) and contingency table calculations (CONT). From the contingency table we can calculate several different scores described later.","category":"page"},{"location":"PostPP/Verification/#Output-format-1","page":"HARMONIE Verification","title":"Output format","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Early versions of the package was based on the ECMWF graphics package MAGICS. Due to the poor portability of MAGICS the package now a days produces text files that are parsed through a script that produces plots using gnuplot. It may not be the most elegant graphics package, but it is available almost everywhere. Some verification are also produced in form of tables. The contingency tables are parsed through contingency2gnuplot.pl to produce skill scores.","category":"page"},{"location":"PostPP/Verification/#HARMONIE-user-interface-1","page":"HARMONIE Verification","title":"HARMONIE user interface","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"In HARMONIE a set of scripts is build around the code for generation of plots and building the web page. There are two main scripts Runverobssurface for verification of surface variables and Runverobstemp for verification of radio sonde data. Both of them need a configuration file, Env_exp, as input:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"./Run_verobs_surface MY_ENV_EXP\r\n./Run_verobs_temp MY_ENV_EXP","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"There is also a master script Runverobsall which cleans the webpage, runs through both types of verification and creates a tar file suitable to add to an existing WebgraF page. It is used in the same way like:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"./Run_verobs_all MY_ENV_EXP","category":"page"},{"location":"PostPP/Verification/#The-main-configuration-file-1","page":"HARMONIE Verification","title":"The main configuration file","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"For most of the cases you can configure your verification by just editing the configuration file, Env_exp. The above mentioned script can take files with any name so it's a good idea to have different files for different sets of experiments. First you have to identify your experiments and their location. ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"# Experiment names and paths,should be space separated\r\nDBASE=/scratch/ms/dk/nhz/oprint\r\nEXP=\"RCR C22\"\r\nDISPLAY_EXP=\"$EXP\"\r\nOBSPATH=$DBASE/OBS2/\r\nP1=$DBASE/RCR/\r\nP2=$DBASE/C22/\r\nMODPATH=\"$P1 $P2\"","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The experiment name should of course match the name on the vfld files. At the moment there is an upper limit of ten experiments, but already at five the plots starts to get pretty messy. It is possible to disply more meaningful names by setting DISPLAY_EXP to something different.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"From harmonie-40h1.1.1.rc1 the output from the verification for the initial setup has changed so that ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"vfldEXPYYYYMMDDHH represents analysis data\nvfldEXPYYYYMMDDHHLL represents output from the forecast model at +00","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"To handle this USE_ANALYSIS has been introduced to allow different choices and combination of the new and old convention.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n# Use analysis at +00h, set per experiment\r\nUSE_ANALYSIS=\".FALSE.,.TRUE.,.FALSE.,.TRUE.,.TRUE.\"","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"We should now defined the name on the WebgraF page and write some text ( in simple html syntax ) describing the experiments.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n# Project name, will be the name on the web page\r\nPROJECT=monitor\r\n\r\n# Explanation on webpage\r\nHELP=\"Observation verification comparison between \\\r\n      <br> FMI(RCR) \\\r\n      <br> SMHI(C22) \\\r\n     \"","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"By having several configuration files with different PROJECT names you can gather all your verification plots under one web page. In next section we define the verification period. We can also say if we would like to verify the full period in one go or in monthly pieces by setting PERIOD_TYPE.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"# Date handling\r\n# PERIOD_TYPE 1 : SDATE - EDATE,\r\n#             2 : SDATE - EDATE in monthly pieces\r\n#\r\n# IDATE is the very first date for PERIOD_TYPE=2 it determines the\r\n# lentgh of the date menu in WebgraF\r\n#\r\nPERIOD_TYPE=1\r\n\r\nSDATE=20080901\r\nEDATE=20080905\r\nIDATE=$SDATE","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"For operational runs it might be useful to set PERIOD_TYPE=2 like FMI has done.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"If you would like to monitor some special stations you can list them by station number.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n#\r\n# Single stations can be defined with comma separated\r\n# station number and a text for the web page\r\n#\r\n# STNLIST_PLOT=\"00002574,00006348\"\r\n# STNLIST_PLOT_TXT=\"NORRKOPING,CABAUW\"\r\n#\r\nSTNLIST_PLOT=-1\r\nSTNLIST_PLOT_TXT=-1\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Note that the zeros in the name matters since the plots are created with station id as eight digit numbers. A list of parameters to be verified are selected through SURFPAR and TEMPPAR respectively. ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n######################\r\n# Surface parameters #\r\n######################\r\n#\r\n# Change in the file plotdefs.pm for text and limits\r\n#\r\n# PS : Mslp\r\n# TT : T2m\r\n# TTHA : T2m, adjusted for model and observation station height differences\r\n# TN : Min T2m\r\n# TX : Max T2m\r\n# TD : Td2m\r\n# FF : Wind speed\r\n# FX : Max wind speed\r\n# GG : Wind gust\r\n# GX : Max wind gust\r\n# DD : Wind direction\r\n# QQ : Specific humidity\r\n# RH : Relative humidity\r\n# PE : Precipitation\r\n# NN : Total Cloud cover\r\n# VI : Visibility, not in vfld files yet\r\n#\r\n\r\n# Active parameters\r\nSURFPAR=\"PS FF FX GG GX DD TT TN TX TD RH QQ NN PE\"\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Note that not all parameters are available in the vfld files for HARMONIE yet. The number of levels to be used for TEMP is set in LEV_LST.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Comment in the code fldextr_pp.f explains TTHA, the moist adiabatic adjustment:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"c adiabatic height correction of station values\r\nc T2M_corr=T2M+[(STATION_HEIGHT-MODEL_HEIGHT)*ADIABATIC_LAPSE_RATE]\r\nc ex: STATION_HEIGHT = 400 masl; MODEL_HEIGHT = 500 masl T2M = 10\r\nc     T2M_corr=10+(400-500)*(-0.0065)=10+0.6=10.6","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"By setting SURFPLOT and TEMPPLOT we choose what kind of statistics we would like to produce. ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"# Things to plot:\r\n# GEN    : General forcast length statistics\r\n# TIME   : Timeserie statistics\r\n# SCAT   : Scatterplot\r\n# MAP    : Bias maps\r\n# FREQ   : Frequency plots\r\n# DAYVAR : Daily variation\r\n# XML    : Station statistics in xml format\r\n# CONT   : Contingency tables\r\n# VERT   : Vertical profiles only available for TEMP data\r\n# SEAS   : Seasonal cycle\r\n#\r\nSURFPLOT=\"GEN TIME MAP FREQ SCAT CONT XML DAYVAR\"","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"From the contingency tables we are also able to produce a number of skill scores either defined by their classes or thresholds.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"# Select skill scores to be plotted if CONT is activated in SURFPLOT\r\n# Frequency     : Frequency\r\n# Frequencybias : Frequency bias\r\n# POD           : Probability of detection ( hit rate )\r\n# FAR           : False alarm ratio\r\n# FA            : False alarm rate\r\n# TS            : Threath score\r\n# WILSON        : Wilson diagram, a combination of POD, TS, FAR and frequency bias\r\n# KSS           : Hansen-Kupiers skill score\r\n# AI            : Area index\r\n# EDS           : Extreme Dependency Score\r\n# SEDS          : Symmetric Extreme Dependency Score\r\n# EDI           : Extremal Dependency Index\r\n# SEDI          : Symmetric Extremal Dependency Index\r\n# ETS           : Equitable threat score\r\n\r\nSCORELIST=\"WILSON KSS Frequency\"\r\n\r\n# Select whether skill scores are based on classes and/or thresholds (CONT must be activated)\r\nSCORETYPES=\"classes thresholds\"\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The meaning of the different abbreviations will be given in next section.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"A selection of data is done by SURFSELECTION and TEMPSELECTION. The name in these list refers to definitions in selection.pm. We also select time and forecast interval by the OBINT, FCINT and FCLEN parameters.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"At the end you would possibly like to change the graphics format of the output files.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n#####################\r\n# GRAPHICS and misc #\r\n#####################\r\n\r\n# Select output_type\r\n# 1  Postscript + PNG\r\n# 2  PNG\r\n# 3  JPEG\r\n# 4  SVG\r\nOUTPUT_TYPE=2\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The difference between the first OUTPUT_TYPE and the others is that in the first case gnuplot will produce postscript files that will be converted to PNG files and both files will be available on the web page. The SVG format (Scalable Vector Graphics) should allow plots with zoom functionality, but this does not yet work in the web interface. ","category":"page"},{"location":"PostPP/Verification/#Setting-parameters-for-different-types-of-plots-1","page":"HARMONIE Verification","title":"Setting parameters for different types of plots","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"If the settings in the main configuration file does not cover your needs you go to next level of the definition files. The namelists defining your verification run is build by Build_namelist.pl by using your configuration file and three perl modules defining different parts. The logics behind the GEN, MAP, TIME switches are hidden in maindefs.pm. The first part defines the reading part:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n%nameread=(\r\n 'read_section' => {\r\n    'SDATE'   => $ENV{SDATE},\r\n    'EDATE'   => $ENV{EDATE},\r\n    'NEXP'    => $nexp,\r\n    'EXPNAME' => $exp,\r\n    'MODPATH' => $modpath,\r\n    'OBSPATH' => '\\''.$ENV{OBSPATH}.'\\'',\r\n    'LQUALITY_CONTROL' => 'T',\r\n    'ESTIMATE_QC_LIMIT'=> 'T',\r\n    'MAXSTN'           => 5000,\r\n    'STNLIST'          => 0,\r\n    'STNLIST_PLOT'     => $ENV{STNLIST_PLOT},\r\n    'LVERIFY'          => 'F',\r\n    'PRINT_READ'       => 1,\r\n    'PERIOD_TYPE'      => $ENV{PERIOD_TYPE},\r\n    'OUTPUT_TYPE'      => $ENV{OUTPUT_TYPE},\r\n    'OUTPUT_MODE'      => 2,\r\n },\r\n) ;\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Any new variable added here will also be set in the reading part of the namelist. The next part, def, defines values that are reset every time we loop through the verification and reads a new namelist. In the selectionloop part  we find the magic switches for the different SURFPLOT/TEMPPLOT keywords. The first one SEAS is only interesting if you run with a few parameters over several seasons. In the normal case several years of data doesn't fit in the memory so this is left for the experienced user.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The next one is GEN:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n 'GEN' => {\r\n # Fclen plots\r\n 'LSTAT_GEN'  => 'T',\r\n 'LSIGN_TEST' => 'T',\r\n 'SIGN_TIME_DIFF' => '-1',\r\n 'LPLOT_STAT' => 'T',\r\n 'SHOW_BIAS' => 'T',\r\n 'SHOW_RMSE' => 'T',\r\n 'SHOW_VAR'  => 'T',\r\n },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Here we set things for standard forecast length verification. We can choose to show bias, rmse and stdv by the SHOW* variable. If SHOWVAR is set plots comparing the model variability to the observed one will be produced. The significance of the difference between different experiments can be shown by setting LSIGN_TEST.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The next section handles the production of bias maps","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n 'MAP' => {\r\n # Map plots\r\n 'PLOT_BIAS_MAP' => 'T',\r\n 'PLOT_RMSE_MAP' => 'T',\r\n 'LSTAT_GEN'     => 'T',\r\n 'LPLOT_STAT'    => 'F',\r\n 'LFCVER'        => 'F',\r\n 'SHOW_TIMES'    => '00,12',\r\n 'USE_FCLEN' => join(',',split(' ',$ENV{FCLEN_MAP})),\r\n },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Here we can show decide to show any of bias,rmse and stdv maps. The bias intervals for a given parameter are defined in plotdefs.pm discussed later. Here we have chosen to show only the 00 and 12 UTC maps.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Time serie statistics of the observed values and departures are produced by the TIME section.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n 'TIME' => {\r\n  # Timeseries\r\n  'LTIMESERIE_STAT'=> 'T',\r\n  'USE_FCLEN' => join(',',split(' ',$ENV{FCLEN_TIME})),\r\n },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Note that we explicitly set the forecast lengths we use. As for the GEN part the activation of bias, rmse and stdv plots are controlled by the SHOW* parameters. The averaging period for time series are controlled per variable through the *TWINDSURF* and TWIND_TEMP parameters in plotdefs.pm.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Scatter plots and contingency tables are set in","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":" 'scat_ver' => {\r\n  # Scatterplots and freq,\r\n  'LPREP_XML' => 'T',\r\n  'LPLOT_FREQ'=> 'T',\r\n  'LPLOT_SCAT'=> 'T',\r\n  'USE_FCLEN' => join(',',split(' ',$ENV{FCLEN_SCAT})),\r\n },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"By setting LPREPXML we will get a list of stations sorted by decreasing rmse on the web page. This allows you to find the worst stations for different variables. The contingency part of this is defined in plotdefs.pm. It is possible to create cross variable scatter plots where we compare different model parameters against each other or the observations. This is however not a part of the script system but be defined on the low level. Read more in [here](https://hirlam.org/trac/browser/monitor/doc/READMEverobs#L250).","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"In some cases it's interesting to see how the model handles the daily cycle. In DAYVAR we define the flags to get this. The LFCVER tell the program that we should organize the statistics by time of day rather than by forecast length. We have also chosen to allow for a special set of forecast length here through the environment variable FCLEN_DAYVAR set in your configuration file","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n 'DAYVAR' => {\r\n  # Daily variation\r\n  'LPLOT_STAT' => 'T',\r\n  'LSTAT_GEN'  => 'T',\r\n  'LFCVER'     => 'F',\r\n  'USE_FCLEN'  => join(',',split(' ',$ENV{FCLEN_DAYVAR})),\r\n  'SHOW_OBS'   => 'T',\r\n  'SHOW_VAR'   => 'F',\r\n },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The final part of maindefs.pm deals with the vertical profiles. LPLOTVERT is the flag telling us that we are doing a vertical profile. The major difference between this and GEN is that here we have chosen to split between night and daytime soundings by setting SHOWTIMES.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Any valid namelist variable added to these sections will be picked up and used in the verification. ","category":"page"},{"location":"PostPP/Verification/#Settings-for-different-meteorological-parameters-1","page":"HARMONIE Verification","title":"Settings for different meteorological parameters","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The different treatment of the different meteorological variables are done in plotdefs.pm. In the first section we define the default values for all variables.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n 'def'=>{\r\n   'TWIND_SURF' => 06,\r\n   'TWIND_TEMP' => 12,\r\n   'QC_LIM_SCALE' => 5.,\r\n   'MAP_BIAS_INTERVAL'=> '7*-1',\r\n },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The TWIND* parameter sets the time averaging window for time series for surface data and temp respectively. QCLIMSCALE is the scaling factor for the stdv used in the quality control. The TEXT variables sets the text for the title in the plots and the web page. For e.g. the cloud cover we have defined the classes for the contingency tables by setting CONTCLASS and CONTLIM. MAPBIAS_INTERVAL set, as the name indicates, the intervals for the bias maps.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n'NN'=>{\r\n   'TEXT'        => 'Cloud cover',\r\n   'CONT_CLASS'  => 7,\r\n   'CONT_LIM'    => '1.,2.,3.,4.,5.,6.,7.',\r\n   'PRE_FCLA'    => '1.,2.,3.,4.,5.,6.,7.',\r\n   'MAP_BIAS_INTERVAL'=> '-6.,-4.,-2.,0.,2.,4.,6.',\r\n },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"It is also possible to set the time window for timeseries separately for each variables like it is done for e.g. precipitation (PE). For accumulated and max/min parameters we also need to set the accumulation period. E.g. the maximum temperature for the past 12 hours is defined as","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n 'TX'=>{\r\n   'TWIND_SURF'  => 12,\r\n   'TEXT'        => 'Max T2m',\r\n   'MAP_BIAS_INTERVAL'=> '-6.,-4.,-2.,0.,2.,4.,6.',\r\n   'ACC'         => 12,\r\n   'ACCTYPE'     => 3,\r\n },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Where ACCTYPE defines if it's an accumulated (1), minimum (2) or maximum (3)  parameter.","category":"page"},{"location":"PostPP/Verification/#Defining-a-new-verification-parameter-1","page":"HARMONIE Verification","title":"= Defining a new verification parameter=","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"As described in the [#Ageneralinputformat input format] section you can add any variable to the verification. Let's say you would like to verify precipiation accunulated over three hours and that you have called it PE3H in your data files.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n 'PE3H'=>{\r\n   'TEXT' => 'Precipitation 3h',\r\n   'ACC'  => 3,\r\n   'UNIT' => 'mm/3h',\r\n },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Where TEXT is the description to be displayed on the plot and the webpage, ACC is the accumulation period in hours and UNIT is the unit to be written to the plot. Of course the above mentioned properties can be set as well. Remember to add PE3H to the SURFPAR list in your definition file.","category":"page"},{"location":"PostPP/Verification/#Selection-options-1","page":"HARMONIE Verification","title":"Selection options","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"It easy to select a subset of your data for verification and we have already discussed how it can be done by setting a list of stations or select different forecast lengths. In selection.pm a number of different kind of selections have been defined. Several of them are just a list of stations like e.g. the well known (but perhaps not so well defined) EWGLAM list. An example of how a box can be defined is found for the Netherlands.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n 'Netherland' => {\r\n   'CBOX%ACTIVE' => 'T',\r\n   'CBOX%SLAT' => '51.',\r\n   'CBOX%WLON' => '1.5',\r\n   'CBOX%NLAT' => '54.5',\r\n   'CBOX%ELON' => '9.',\r\n   }\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"We may also define our area of selection through a polygon.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n 'BalticSea' => {\r\n   'STNLIST'=> 0,\r\n   'LPOLY'               => 'T',\r\n   'POLYFILE'            => '\\'Baltic_sea.poly\\'',\r\n   },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"A more specialized case is the selection of stations by station height where the upper and lower limits are given.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n  'masl_300m' => {\r\n   'STNLIST'=> 0,\r\n   'LSTN_HGT_CHECK'=>'.T.',\r\n   'HGT_ULIM'=>1.e6,\r\n   'HGT_LLIM'=>300.,\r\n   },\r\n","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Finally we can also do the selection based on meteorological criteria. In the example below we are interested in cases with low temperatures and weak winds.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"\r\n  'temp_and_wind_limit' => {\r\n    'COND%IND' => 'FF,TT',\r\n    'COND%ULIM' => ' 5.,-10.',\r\n    'COND%LLIM' => '-1.,-55.',\r\n    'COND%LOBS' => 'T,F',\r\n    'COND%ALL_MOD' => 'T,F',\r\n  },","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Example of conditional selection","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"COND%IND sets the parameters\nCOND%LLIM sets the lower limits\nCOND%ULIM sets the upper limits\nCOND%LOBS T means apply condition on observations, F applies condition on model data\nCOND%ALL_MOD, T means condition is required for ALL models, F for ANY model","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"All the above mentioned selections can of course be combined in any way you can imagine.","category":"page"},{"location":"PostPP/Verification/#WebgraF-1","page":"HARMONIE Verification","title":"WebgraF","text":"","category":"section"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"One idea with the HARMONIE verification packages is that it should be easy to share you results with others. This is where WebgraF comes in. It was originally written to mimic the ECMWF \"chart\" facility like here. The ECMWF solution is a perl based server solution and needs some installation and WebgraF is a javascript running locally which makes it more portable. The idea with WebgraF is that each page is defined by a simple definition file which spans the space of the menu axes on the page. ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Examples :       * GLAMEPS Definition file       * Daily maps Definition file","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"At the end of both of the scripts Runverobssurface/Runverobstemp there is a call to Createverjs.pl that builds the webpage depending on your configuration file. It is also possible to (re)generate the webpage directly by running:","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Create_ver_js YOUR_CONFIG_FILE","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The WebgraF page is controlled by the WebgraF script. It has commands to e.g. list, add, remove the content of a page. To start mastering your own page you first have to let the script know the location of the page by setting the environment variable WEBGRAF_BASE ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"in bash\r\nexport WEBGRAF_BASE=SOME_PATH/monitor/WebgraF\r\nor in tcsh\r\nsetenv WEBGRAF_BASE SOME_PATH/monitor/WebgraF","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Now you can list the content of you page by","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"WebgraF/bin/WebgraF -l ","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"A more comprehensive list of commands can be found in the README file. The rules and functions available for your definition file is found here.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Two useful tools is the export and transport commands. Both creates an portable extraction of your verification page but in two different ways.","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"The export.tar file is a stand alone web page that you can untar anywhere and open in your browser.\nThe transport.tar file is suitable to add to an already existing WebgraF page by  WebgraF -a TARFILE","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Both are accessible through the script Transport_ver which is used like","category":"page"},{"location":"PostPP/Verification/#","page":"HARMONIE Verification","title":"HARMONIE Verification","text":"Transport_ver YOUR_CONFIG_FILE","category":"page"},{"location":"PostPP/Verification/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../../HarmonieSystemDocumentation.md)-1","page":"HARMONIE Verification","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ECFLOW?action=edit\"","category":"page"},{"location":"ECFLOW/#Running-Harmonie-under-ecFlow-1","page":"ECFlow","title":"Running Harmonie under ecFlow","text":"","category":"section"},{"location":"ECFLOW/#Introduction-1","page":"ECFlow","title":"Introduction","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"This document describes how to run Harmonie under ecFlow scheduler at ECMWF. ecFlow is the ECMWF workflow manager and it has been written using python to improve maintainability, allow easier modification and introduce object orientated features as compared to the old scheduler SMS. ecFlow can be used in any HARMONIE version in and above harmonie-40h1.1.beta.1.","category":"page"},{"location":"ECFLOW/#Start-your-experiment-supervised-by-ecFlow-1","page":"ECFlow","title":"Start your experiment supervised by ecFlow","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"Launch the experiment in the usual manner by giving start time, DTG, end time, DTGEND and other optional arguments","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"      ~hlam/Harmonie start DTG=YYYYMMDDHH","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"If successful, ecFlow will identify your experiment name and start building your binaries and run your forecast. If not, you need to examine the ecFlow log file $HM_DATA/ECF.log. $HM_DATA is defined in your Env_system file. At ECMWF $HM_DATA=$SCRATCH/hm_home/$EXP where $EXP is your experiment name.","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"The ecflow viewer stars automatically. To view any suite for your server or other servers, the server must be added to ecflowview Edit/Preferences/Servers and selected in Servers. See below on how to find the port and server name.","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"More than one experiment is not allowed with the same name monitored in the same server so Harmonie will start the server and delete previous non-active suite for you.\nFor deleting a suite manually using ecflowclient –port XXXX –host XXXX –delete force yes /suite or using the GUI Collector node+CTRL+click1 selecting ###ecflowclient –delete force yes <full_name>\nIf other manual intervention in server or client is needed you can use ecflow commands [https://software.ecmwf.int/wiki/display/ECFLOW/Home].","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"At ECMWF there are two server options ECF_HOST=ecgate or ECF_HOST=ecgb-vecf where the latter available since release-43h2.beta.5. Set ECF_HOST in Env_system to choose between the servers.","category":"page"},{"location":"ECFLOW/#ecFlow-control-1","page":"ECFlow","title":"ecFlow control","text":"","category":"section"},{"location":"ECFLOW/#Finding-the-port-and-host-of-the-ecFlow-server-1","page":"ECFlow","title":"Finding the port and host of the ecFlow server","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"Information about server variables can be found by running","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"      ecflow_server status ","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"At ECMWF you can also find ECF_PORT/ECF_HOST by checking the files under /hpc/perm/ms/$GROUP/$USER/HARMONIE, like ","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"hlam@ecgb11:~/hm_home/43_aug> ls -rlt /hpc/perm/ms/spsehlam/hlam/HARMONIE/*.ecf.*\r\n-rw-r-----. 1 hlam hirald     10443 Aug  8 13:11 /hpc/perm/ms/spsehlam/hlam/HARMONIE/ecgb-vecf.4531.ecf.log\r\n-rw-r-----. 1 hlam hirald      8804 Aug  8 13:12 /hpc/perm/ms/spsehlam/hlam/HARMONIE/ecgate.4531.ecf.log","category":"page"},{"location":"ECFLOW/#Check-the-status-of-your-server-1","page":"ECFlow","title":"Check the status of your server","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"To check the status of your server you can use","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"ecflow_client --stats  --port ECF_POST  --host ECF_HOST","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"or","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"ecflow_client --port ECF_PORT  --host ECF_HOST  --ping","category":"page"},{"location":"ECFLOW/#Open-the-viewer-of-a-running-ecFlow-server-1","page":"ECFlow","title":"Open the viewer of a running ecFlow server","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"If you know that your ecFlow server is running but you have no viewer attached to it you can restart the viewer:","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"ecflow_ui &","category":"page"},{"location":"ECFLOW/#Stop-your-ecFlow-server-1","page":"ECFlow","title":"Stop your ecFlow server","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"If you are sure you're running the server on the login node of your machine you can simply run","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"ecflow_stop.sh","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"A more complete and robust way is","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"export ECF_PORT=<your port>\r\nexport ECF_HOST=<your server name>\r\necflow_client  --halt=yes\r\necflow_client  --check_pt\r\necflow_client  --terminate=yes","category":"page"},{"location":"ECFLOW/#Restart-your-ecFlow-server-1","page":"ECFlow","title":"Restart your ecFlow server","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"If the server is not running you can start again using the script","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":" ecflow_start.sh -d /hpc/perm/ms/$GROUP/$USER/HARMONIE/","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"Again, if ecFlow is running on a different machine you have to login and start it on that machine. For the virtual server ecgb-vecf you would do","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":" ssh ecgb-vecf\r\n module load ecflow\r\n ecflow_start.sh -d /hpc/perm/ms/$GROUP/$USER/HARMONIE/","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"As an alternative you can let Harmonie start the server for you when starting your next experiment.","category":"page"},{"location":"ECFLOW/#Keep-your-ecFlow-server-alive-1","page":"ECFlow","title":"Keep your ecFlow server alive","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"The ecFlow server running on ecgate will eventually die causing an unexpected disruption in you experiments. To prevent this you can add a cron job restarting the server e.g. every fifth minute.","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"> crontab -l\r\n*/5 * * * * /home/ms/$GROUP/$USER/bin/cronrun.sh ecflow_start.sh -d /hpc/perm/ms/$GROUP/$USER/HARMONIE > ~/ecflow_start.out 2>&1","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"where to small script cronrun.sh make sure you get the right environment","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"#!/bin/bash\r\nsource ~/.bash_profile\r\nmodule unload ecflow\r\nmodule load ecflow/4.12.0\r\n$@","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"The ecFlow server version may change over time.","category":"page"},{"location":"ECFLOW/#Add-another-user-to-your-ecflowviewer-1","page":"ECFlow","title":"Add another user to your ecflowviewer","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"Sometimes it's handy to be able to follow, and control, your colleagues experiments. To be able to do this do the following steps:","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"Find the port number of your colleague as described above.\nIn the ecflowviewer choose edit->preferences->servers and fill in the appropriate host and port and give it a useful name. Click on add to save it.\nIf you click on Servers in the viewer the name should appear and you can make it visible by clicking on it.","category":"page"},{"location":"ECFLOW/#Changing-the-port-1","page":"ECFlow","title":"Changing the port","text":"","category":"section"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"By default, the port is set by ","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"export ECF_PORT=$((1500+usernumber))","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"in mSMS.job (40h1.1), or Start_ecFlow.sh (trunk). ","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"If you want to change this number (for example, if that port is in use already), you will also need to add a -p flag when calling ecflow_start.sh as follows:","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"ecflow_start.sh -p $ECF_PORT -d $JOBOUTDIR","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"Otherwise, ecflow_start.sh tries to open the default port. ","category":"page"},{"location":"ECFLOW/#","page":"ECFlow","title":"ECFlow","text":"Note: if you already have an ecFlow server running at your new port number before launching an experiment, this won't be an issue. ","category":"page"},{"location":"ECFLOW/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"ECFlow","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Screening?action=edit\"","category":"page"},{"location":"Screening/#Screening-1","page":"Screening","title":"Screening","text":"","category":"section"},{"location":"Screening/#Introduction-1","page":"Screening","title":"Introduction","text":"","category":"section"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"Screening (configuration 002 of ARPEGE/IFS model) carries out quality control of observations. ","category":"page"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"A useful presentation (Martin Ridal) from the \"Hirlam-B Training Week on HARMONIE system\" training course is available here: MR_screenandminim.pdf. Most of the information on this page is based on his presentation.","category":"page"},{"location":"Screening/#Inputs-1","page":"Screening","title":"Inputs","text":"","category":"section"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"First guess (the same file with 5  different names):\nICMSHMIN1INIT\nICMSHMIN1IMIN\nICMRFMIN10000\nELSCFMIN1ALBC000\nELSCFMIN1ALBC","category":"page"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"Input/output ODB directory structure\n{d_DB}\n/ECMA\nd_DBECMA\n{base1}","category":"page"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"Constants and statistics (MAY NEED TO BE UPDATED)\ncorrel.dat\nsigmab.dat\nrszcoef_fmt\nerrgrib\nrtcoefatovsnewpredieee.dat\nbcor_noaa.dat\nchanspec_noaa.dat\nrmtberr_noaa.dat\ncstlim_noaa.dat","category":"page"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"Namelist: See %screening in nam/harmonie_namelists.pm","category":"page"},{"location":"Screening/#Screening-tasks-1","page":"Screening","title":"Screening tasks","text":"","category":"section"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"(Based on Martin Ridal's presentation).","category":"page"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"Preliminary check of observations\nCheck of completeness of the reports\nCheck if station altitude is present\nCheck of the reporting practice for SYNOP & TEMP mass observations \nBlacklisting: A blacklist is applied to discard observations of known poor quality and/or that cannot be properly handled by the data assimilation. A selection of variables for assimilation is done using the data selection part of the blacklist file and the information hard-coded in Arpege/Aladin (orographic rejection limit, land-sea rejection...). Decisions based on the blacklist are feedback to the CMA. Blacklisting is defined in src/bla/mf_blacklist.b\nBackground quality control: flags are assigned to observations – 1 =>  probably correct, 2 => probably incorrect, 3 => incorrect.\nVertical consistency of multilevel report:\nThe duplicated levels, in multi-level reports, are removed from the reports\nIf 4 consecutive layers are found to be of suspicious quality then these layers are rejected\nRemoval of duplicated reports\nIn case of co-located airep reports of the same observation types (time, position), some or all of the content of one of the reports is rejected\nRedundancy check\nperformed for active reports that are co-located and originate from the same station\nLAND SYNOP: the report closest to the centre of the screening time window with most active data is retained\nSHIP SYNOP: redundant if the moving platforms are within a circle of 1^o^ radius (src/arpifs/obs_preproc/sufglim.F90: RSHIDIS = 111000._JPRB)\nTEMP and PILOT: same stations are considered at the same time in the redundancy check\nA SYNOP mass observation is redundant if there are any TEMP geopotential height observations (made in the same time and the same station) that are no more than 50hPa above the SYNOP mass observation\nThinning: High resolution data needs to be reduced to reduce correlated errors and reduce the amount of data","category":"page"},{"location":"Screening/#Output-1","page":"Screening","title":"Output","text":"","category":"section"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"The quality control information will be put into the input ECMA ODB(s) and a newly created CCMA to used by the 3DVAR minimization.","category":"page"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"A valuable summary about screening decisions can be found in HMDateYYYYMMDDHH.html:","category":"page"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"Look for “SCREENING STATISTICS” to get:\nSTATUS summary\nEVENT summary\nNumber of variables, departures and missing departures\nDiagnostic JO-table\nCCMA ODB and updated ECMA ODB","category":"page"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"Screening Events listed under \"EVENT SUMMARY OF REPORTS:\"","category":"page"},{"location":"Screening/#","page":"Screening","title":"Screening","text":"=  = = Description                              =\n1 NO DATA IN THE REPORT\n2 ALL DATA REJECTED\n3 BAD REPORTING PRACTICE\n4 REJECTED DUE TO RDB FLAG\n5 ACTIVATED DUE TO RDB FLAG\n6 ACTIVATED BY WHITELIST\n7 HORIZONTAL POSITION OUT OF RANGE\n8 VERTICAL POSITION OUT OF RANGE\n9 TIME OUT OF RANGE\n10 REDUNDANT REPORT\n11 REPORT OVER LAND\n12 REPORT OVER SEA\n13 MISSING STATION ALTITUDE\n14 MODEL SUR. TOO FAR FROM STAT. ALT.\n15 REPORT REJECTED THROUGH THE NAMELIST\n16 FAILED QUALITY CONTROL","category":"page"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ObservationHowto/Amv?action=edit\"","category":"page"},{"location":"ObservationHowto/Amv/#Atmospheric-Motion-Vectors-(AMV)-1","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"","category":"section"},{"location":"ObservationHowto/Amv/#Introduction-1","page":"Atmospheric Motion Vectors (AMV)","title":"Introduction","text":"","category":"section"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"In this short information about the (pre-)processing, assimilation, and post-processing, as well as access to the AMV data in the Harmonie system is shown.","category":"page"},{"location":"ObservationHowto/Amv/#AMV-data-1","page":"Atmospheric Motion Vectors (AMV)","title":"AMV data","text":"","category":"section"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"AMV data is available via EUMETCast (the EUMETAT processed), the MARS archive at ECMWF (both polar and geowind) or locally using NWCSAF software. Through the EUMETCast, both data are in BUFR format. An abstract from the 5th Winds Workshop on the quality control of EUMETSAT wind products (S2-3_Elliott-Parallel.pdf) provides some useful information on how AMV BUFR is encoded. We define two kinds of AMV data in the Harmonie system: Geostationary satellite based (GEOW) and polar satellite based (POLW). GEOW and POLW can be processed separately through the usual request in scr/include.ass as described below.","category":"page"},{"location":"ObservationHowto/Amv/#HARMONIE-changes-1","page":"Atmospheric Motion Vectors (AMV)","title":"HARMONIE changes","text":"","category":"section"},{"location":"ObservationHowto/Amv/#scr/include.ass-1","page":"Atmospheric Motion Vectors (AMV)","title":"scr/include.ass","text":"","category":"section"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"In [source:scr/include.ass] should be edited to \"switch on\" the use of AMVs (SATOB/geowinds):","category":"page"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"export GEOW_OBS=1               # Satob geowind / SAFNWC geowind\r\nexport GEOW_SOURCE=ears         # mars:MARS | else: file in $OBDIR\r\n[[  $GEOW_OBS -eq 1  ]] && types_BASE=\"$types_BASE geow\"\r\n\r\nexport POLW_OBS=1               # Polar winds\r\nexport POLW_SOURCE=ears         # mars:MARS | else: file in $OBDIR\r\n[[  $POLW_OBS -eq 1  ]] && types_BASE=\"$types_BASE polarw\"","category":"page"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"Important: Please note that data from MARS were not yet tested!!! Roger is happy to assist if you prefer to use this option. The Harmonie system is updated with the aim to be able to use these data in operational application.","category":"page"},{"location":"ObservationHowto/Amv/#param.cfg-1","page":"Atmospheric Motion Vectors (AMV)","title":"param.cfg","text":"","category":"section"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"The BUFR template used by your AMV data should be defined in the param.cfg file used by Bator. param.cfg files for Bator are in the const/bator_param directory. The geowind param.cfg template should be something like this:","category":"page"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"BEGIN geowind\r\nA 0 4 18\r\ncodage       1  aaaaaa\r\n  :          :    :\r\ncodage       A  aaaaaa\r\noffset       1      24  offset for QI_3 (eumetsat & tokyo)\r\noffset       2      28  offset for QI_1 (NOAA)\r\noffset       3      14  offset for QI_2 (NOAA)\r\noffset       4      48  offset for QI_2 (eumetsat & tokyo)\r\nvalues       1  001007  SATELLITE IDENTIFIER\r\nvalues       2  001031  IDENTIFICATION OF ORIGINATING/GENERATING CENTRE (SEE NOTE 10)\r\nvalues       4  002221  SEGMENT SIZE AT NADIR IN X DIRECTION\r\nvalues       5  002222  SEGMENT SIZE AT NADIR IN Y DIRECTION\r\nvalues       6  004001  YEAR\r\nvalues      12  005001  LATITUDE (HIGH ACCURACY)\r\nvalues      13  006001  LONGITUDE (HIGH ACCURACY)\r\nvalues      14  002252  SATELLITE INSTRUMENT DATA USED IN PROCESSING\r\nvalues      15  002023  SATELLITE DERIVED WIND COMPUTATION METHOD\r\nvalues      16  007004  PRESSURE\r\nvalues      17  011001  WIND DIRECTION\r\nvalues      18  011002  WIND SPEED\r\nvalues      21  012193  COLDEST CLUSTER TEMPERATURE\r\nvalues      22  002231  HEIGHT ASSIGNMENT METHOD\r\nvalues      23  002232  TRACER CORRELATION METHOD\r\nvalues      24  008012  LAND/SEA QUALIFIER\r\nvalues      25  007024  SATELLITE ZENITH ANGLE\r\nvalues     211  033007  % CONFIDENCE\r\nEND geowind","category":"page"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"Please be reminded that the processing of data from MARS was not yet tested. From 43h2.1, we have the all necessary content of the param file for processing of both GEOW and POLW in const/batorparam/parambator.cfg.geow.{GEOW_SOURCE / POLW_SOURCE}","category":"page"},{"location":"ObservationHowto/Amv/#BATOR-namelist-1","page":"Atmospheric Motion Vectors (AMV)","title":"BATOR namelist","text":"","category":"section"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"Depending on the satellite and channel you may have to add entries to the NADIRS namelist in the Bator script like the following:","category":"page"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"   TS_GEOWIND(isatid)%T_SELECT%LCANAL(ichanal)=.TRUE.,","category":"page"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"Satellite identifiers are available here: [https://software.ecmwf.int/wiki/display/ECC/WMO%3D27+code-flag+table]\nBator defaults for MSG AMV data are set in src/odb/pandor/module/batorinitmod.F90","category":"page"},{"location":"ObservationHowto/Amv/#Source-code-1","page":"Atmospheric Motion Vectors (AMV)","title":"Source code","text":"","category":"section"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"The reading of BUFR AMVs is taken care of by the [subroutine in source:Harmonie/src/odb/pandor/module/batordecodbufrmod.F90 src/odb/pandor/module/batordecodbufrmod.F90. This subroutine reads the following parameters defined in the param.cfg file:","category":"page"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"= Name            = = Description =\nDate and time derived from the tconfig(004001) - assumes month, day, hour and minute are in consecutive entries in the values array\nLocation latitude and longitude are read from tconfig(005001) and tconfig(006001)\nSatellite the satellite identifier is read from tconfig(001007)\nOrigin. center the originating center (of the AMV) is read from tconfig(001031)\nCompu. method the wind computation method (type of channel + cloudy/clear if WV) is read from tconfig(002023)\nDerivation method the height assignment method is read from tconfig(002163) and the tracking method from tconfig (002164)\nChannel frequency the centre frequency of the satellite channel is read from tconfig(002153)\nHeight (pressure) the height of the AMV observation is read from tconfig(007004)\nWind the wind speed and direction  are read from tconfig(011002) and tconfig(011001)\nTemperature the coldest cluster temperature is read from tconfig(012071)\nFG QI The QI (including FG consistency) for MSG AMVs is read from the first location where descriptor 033007 appears\nnoFG-QI The FG-independent QI for MSG AMVs is read from the first location where 033007 appears + offset(1)=24\nSat zenith angle the satellite zenith angle is read from tconfig(007024)\nLand/sea/coast a land/sea/coast qualifier is read from tconfig(008012)","category":"page"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"The geowind routine was adapted to handle MSG AMVs from MARS and its module src/odb/pandor/module/batordecodbufrmod.F90 uploaded to the trunk (Mar 2017) .","category":"page"},{"location":"ObservationHowto/Amv/#Blacklist-1","page":"Atmospheric Motion Vectors (AMV)","title":"Blacklist","text":"","category":"section"},{"location":"ObservationHowto/Amv/#","page":"Atmospheric Motion Vectors (AMV)","title":"Atmospheric Motion Vectors (AMV)","text":"The selection/blacklist of AMVs according to channel, underlying sea/land, QI, etc. is done in src/blacklist/mf_blacklist.b, section - SATOB CONSTANT DATA SELECTION -.","category":"page"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/FileFormats?action=edit\"","category":"page"},{"location":"FileFormats/#File-formats-in-HARMONIE-1","page":"File Formats","title":"File formats in HARMONIE","text":"","category":"section"},{"location":"FileFormats/#Introduction-1","page":"File Formats","title":"Introduction","text":"","category":"section"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"The HARMONIE system reads and writes a number of different formats. ","category":"page"},{"location":"FileFormats/#FA-files-1","page":"File Formats","title":"FA files","text":"","category":"section"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"Default internal format input/output for HARMONIE for gridpoint, spectral and SURFEX data. GRIB is used as a way to pack data, but the grib record cannot be used as such.","category":"page"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"The header contains information about model domain, projection, spectral truncation, extension zone, boundary zone, vertical levels. \nOnly one date/time per file.\nFA routines are found under ifsaux/fa\nList or convert a file with gl\nOther listing tool PINUTS","category":"page"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"Read more","category":"page"},{"location":"FileFormats/#GRIB/GRIB2-1","page":"File Formats","title":"GRIB/GRIB2","text":"","category":"section"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"All FA files may be converted to GRIB after the forecast run. For the conversion between FA names and GRIB parameters check this table.","category":"page"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"List or convert a GRIB file with gl","category":"page"},{"location":"FileFormats/#NETCDF-1","page":"File Formats","title":"NETCDF","text":"","category":"section"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"In climate mode all FA files may converted to NETCDF after the forecast run. For the conversion between FA names and NETCDF parameters check this table.","category":"page"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"For the manipulation and listing of NETCDF files we refer to standard NETCDF tools.\nNETCDF is also used as output data from some SURFEX tools.","category":"page"},{"location":"FileFormats/#BUFR-and-ODB-1","page":"File Formats","title":"BUFR and ODB","text":"","category":"section"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"BUFR is the archiving/exchange format for observations. Observation Database is used for efficient handling of observations on IFS. ODB used for both input data and feedback information.","category":"page"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"Read more about observations in HARMONIE here.","category":"page"},{"location":"FileFormats/#DDH-(LFA-files-)-1","page":"File Formats","title":"DDH (LFA files )","text":"","category":"section"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"Diagnostics by Horizontal Domains allows you to accumulate fluxes from different packages over different areas/points. ","category":"page"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"LFA files ( Autodocumented File Software )\ngmapdoc\nunder util/ddh","category":"page"},{"location":"FileFormats/#Misc-1","page":"File Formats","title":"Misc","text":"","category":"section"},{"location":"FileFormats/#","page":"File Formats","title":"File Formats","text":"vfld/vobs files in a simple ASCII format used by the verification.\nObsmon files are stored in sqlite format.","category":"page"},{"location":"FileFormats/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"File Formats","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ModelDomain?action=edit\"","category":"page"},{"location":"ModelDomain/#Model-Domain-1","page":"Model Domain","title":"Model Domain","text":"","category":"section"},{"location":"ModelDomain/#Introduction-1","page":"Model Domain","title":"Introduction","text":"","category":"section"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"There are four projections available in HARMONIE, polar stereographic, lambert, mercator and rotated mercator. The model itself chooses the best (least distortion) projection among the first three given your domain specifications. The rotated mercator projection is selected through the variable LROTMER. Note that the polar stereographic project is defined at 90^o^N(S) whereas in GRIB1 it is defined at 60^o^ N(S).","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"Polar stereographic, Lambert and Mercator projectionRotated mercator projection","category":"page"},{"location":"ModelDomain/#Model-domain-settings-1","page":"Model Domain","title":"Model domain settings","text":"","category":"section"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"For each domain we set variables related to the geometry and the resolution like:","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"HARMONIE model domains are defined in settings in Harmonie_domains.pm. The following variables related to the geometry and the resolution are required:","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"TSTEP is model timestep in seconds\nNLON is number of points in x-direction.\nNLAT is number of points in y-direction.\nLONC is the longitude of domain centre in degrees.\nLATC is the latitude of domain center in degrees.\nLON0 is the reference longitude of the projection in degrees.\nLAT0 is the reference latitude of the projection in degrees. __If LAT0 is set to 90, the projection is polar stereographic. If LAT0 < 90, the projection is lambert unless LMRT=.TRUE..___  \nGSIZE is grid size in meters in both x- and y-direction.\nEZONE is number of points over extension zone in both x- and y-direction. Default value 11. \nLMRT switch for rotated Mercator projection. If LMRT=.TRUE. LAT0 should be zero.","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"NLON and NLAT should satisfy the equation 5^b^ * 3^d^ * 2^e^, where a-e are integers >= 0.","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"~~BDNLON is number of points in x-direction for intermediate climate file. BDNLON > NLON.~~\n~~BDNLAT is number of points in y-direction for intermediate climate file. BDNLAT > NLAT.~~","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"The default area is the Denmark domain (DKCOECP). The following values for C+I zone and truncation are calculated in Harmonie_domains.pm from the values above. ","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"NDLUXG is number of points in x-direction without extension (E) zone.\nNDGUXG is number of points in y-direction without extension (E) zone.\nNMSMAX_LINE is truncation order in longitude. By default (NLON-2)/2. \nNSMAX_LINE is truncation order in latitude. By default (NLAT-2)/2. \nNMSMAX_QUAD is truncation order in longitude. By default (NLON-2)/3. It is used to create filtered orography with lower resolution.\nNSMAX_QUAD is truncation order in latitude. By default (NLAT-2)/3. It is used to create filtered orography with lower resolution.","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"~~Note that to run with LSPSMORO=yes you have to use a linear grid. I.e. NLON/NLAT must satisfy~~","category":"page"},{"location":"ModelDomain/#Domain-creation-tool-1","page":"Model Domain","title":"Domain creation tool","text":"","category":"section"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"To help with the design of a new domain, there is an interactive tool that lets you experiment with the grid parameters described above, and visualize the resulting domain immediately on a map, see figure below.","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"At present, it only works for Lambert and polar stereographic projection, not rotated mercator.","category":"page"},{"location":"ModelDomain/#Creating-a-new-domain-1","page":"Model Domain","title":"Creating a new domain","text":"","category":"section"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"If you are happy with your new domain created with the help of the domain creation tool you can add it to Harmonie_domains.pm for your experiment, my_exp (assuming you have set up the experiment):","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"cd $HOME/hm_home/my_exp\r\nPATH_TO_HARMONIE/config-sh/Harmonie co scr/Harmonie_domains.pm\r\n#\r\n# add domain information for new domain called MYNEWDOM in this file\r\n#\r\nvi scr/Harmonie_domains.pm\r\n#\r\n# set DOMAIN=MYNEWDOM in the experiment config file\r\n#\r\nvi ecf/config_exp.h ","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"You can now start a new experiment with a newly defined domain called MYNEWDOM.","category":"page"},{"location":"ModelDomain/#Create-a-test-domain-with-gl-1","page":"Model Domain","title":"Create a test domain with gl","text":"","category":"section"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"Before you go through the full climate generation process you can generate a test domain using gl. Define your domain in the namelist like:","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"&NAMINTERP\r\nOUTGEO%NLON = 300 ,\r\nOUTGEO%NLAT = 300,\r\nOUTGEO%PROJECTION = 3,\r\nOUTGEO%WEST = 17.0,\r\nOUTGEO%SOUTH = 58.0,\r\nOUTGEO%DLON = 2500.0\r\nOUTGEO%DLAT = 2500.0\r\nOUTGEO%PROJLAT = 60.0\r\nOUTGEO%PROJLAT2 = 60.0\r\nOUTGEO%PROJLON = 0.0,\r\n/","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"Running gl using this namelist by","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"gl -n namelist_file","category":"page"},{"location":"ModelDomain/#","page":"Model Domain","title":"Model Domain","text":"will create an GRIB file with a constant orography which you can use for plotting.  Back to the main page of the HARMONIE System Documentation ––","category":"page"},{"location":"#Harmonie-system-documentation-1","page":"Home","title":"Harmonie system documentation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"If there are any issues with the documentation please create a Github issue or edit the page by clicking the \"Edit on Github\" button at the top of each markdown page.  This will take you to the hirlam.org trac wiki","category":"page"},{"location":"#Community-1","page":"Home","title":"Community","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"HIRLAM Forum: discussion and help within the HIRLAM community.\nHIRLAM Meetings: Working weeks and other HARMONIE-related meetings\nHIRLAM Training: Training courses for new users of HARMONIE.\nHIRLAM NWP: Information on operational implementation of HIRLAM and HARMONIE\nHIRLAM Data Portal: Monitoring and Inter-comparison of Operational and Real time Harmonie/HIRLAM/GLAMEPS\nHIRLAM mailing lists: subscribe to receive common interest e-mails \nHIRLAM staff: contact information on HIRLAM web site\nSurface physics and assimilation: HIRLAM activities related to development in surface physics and assimilation\nUpper air physics, dynamics and high resolution: HIRLAM activities related to development in upper air physics, dynamics and high resolution modeling\nHarmonie Climate: status, development and documentation of HARMONIE Climate (HCLIM), the climate version of HARMONIE\nHirlam Chemical Branch: HIRLAM Chemical branch & Enviro-HIRLAM online integrated NWP-ACTM model","category":"page"},{"location":"#Rolling-Workplan-1","page":"Home","title":"Rolling Workplan","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"link here","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/DrHook?action=edit\"","category":"page"},{"location":"DrHook/#Profiling-and-traceback-tool-Dr.Hook-1","page":"Profiling and Traceback","title":"Profiling & traceback tool Dr.Hook","text":"","category":"section"},{"location":"DrHook/#Background-1","page":"Profiling and Traceback","title":"Background","text":"","category":"section"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"Dr.Hook (& the Medicine Head :-) was developed at ECMWF in 2003 to overcome problems in catching runtime errors. Their IBM system at the time was quite impotent to produce meaningful traceback upon crash. It was decided that something need to be done urgently.","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"Dr.Hook gets its name from Fujitsu VPP's hook-functionality in their Fortran compiler,  which enabled to call user functions upon enter and exit of a routine. Dr.Hook is of course a former US rock-band from 70's, which probably did not survive to this millenium due to heavy drug use!  ","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"In about week or so late 2003 the first version of Dr.Hook saw daylight. It turned out nearly immediately that we could try to gather information for profiling purposes, too, like wall & CPU clock times, possibly MFlop/s and memory consumption information.","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"One drawback with Dr.Hook was that (initially just) Fortran code needed to be instrumented by subroutine calls, which was a bother. However, for IFS code and automatique insertion  script was developed greatly simplifiying the task.","category":"page"},{"location":"DrHook/#Activating-Dr.Hook-1","page":"Profiling and Traceback","title":"Activating Dr.Hook","text":"","category":"section"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"Two things have to be in place in order to use Dr.Hook:","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"Fortran (or C) codes must contain explicit Dr.Hook calls to enable instrumentation, starting from the main program\nCertain environment variable(s) need to be set","category":"page"},{"location":"DrHook/#An-example-of-Fortran-instrumentation-1","page":"Profiling and Traceback","title":"An example of Fortran instrumentation","text":"","category":"section"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"SUBROUTINE HOP(KDLEN,KDBDY,KSET,KHORIZ)\r\n!**** *HOP* - Operator routine for all types of observations.\r\n!     E. ANDERSSON            ECMWF          01/04/99\r\n...\r\nUSE PARKIND1  ,ONLY : JPIM     ,JPRB\r\nUSE YOMHOOK   ,ONLY : LHOOK,   DR_HOOK\r\n...\r\nIMPLICIT NONE\r\n...\r\nREAL(KIND=JPRB) :: ZHOOK_HANDLE ! Stack variable i.e. do not use SAVE\r\n...\r\n! Before the very first statement\r\nIF (LHOOK) CALL DR_HOOK('HOP',0,ZHOOK_HANDLE)\r\n...\r\n! Before any RETURN-clause\r\nIF (LLcondition) THEN\r\n  IF (LHOOK) CALL DR_HOOK('HOP',1,ZHOOK_HANDLE)\r\n  RETURN\r\nENDIF\r\n...\r\n! Before the very last statement\r\nIF (LHOOK) CALL DR_HOOK('HOP',1,ZHOOK_HANDLE)\r\nEND SUBROUTINE HOP\r\n","category":"page"},{"location":"DrHook/#Some-environment-variables-1","page":"Profiling and Traceback","title":"Some environment variables","text":"","category":"section"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"To activate Dr.Hook and to enable tracebacks upon failure:","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"#!sh\r\nexport DR_HOOK=1","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"This sets the Fortran-variable LHOOK to .TRUE..","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"By default all usual Unix-signals are caught (like SIGFPE=8, SIGSEGV=11, etc.). Occasionally, during development, some of them can be turned off, e.g. SIGFPE:","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"#!sh\r\nexport DR_HOOK_IGNORE_SIGNALS=8","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"To enable low-overhead wall clock time profiling, set also:","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"#!sh\r\nexport DR_HOOK_OPT=prof","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"Also recommended options are:","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"#!sh\r\nexport DR_HOOK_SHOW_PROCESS_OPTIONS=0\r\nmkdir -p /some/path/hook\r\nexport DR_HOOK_PROFILE=/some/path/hook/drhook.prof.%d","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"The former one reduces Dr.Hook informative output upon initialization. This can be messy as so many processors are printing the same, often useless, output to the stderr.","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"The latter defines the profile files' location. The %d will be replaced with MPL-task id (= MPI-task plus 1).","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"Sometimes it is necessary to turn Dr.Hook off and also make sure no signals are caught by Dr.Hook – as this the (unfortunate?) default due to function call to CDRHOOKINIT_SIGNALS in arp/setup/sumpini.F. Now there is a new environment variable DRHOOKINIT_SIGNALS to prevent this. So, to make sure Dr.Hook does not interfere your run at all, give:","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"#!sh\r\nexport DR_HOOK=0\r\nexport DR_HOOK_INIT_SIGNALS=0","category":"page"},{"location":"DrHook/#Timeline-memory-profiling-1","page":"Profiling and Traceback","title":"Timeline memory profiling","text":"","category":"section"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"It is possible to activate timeline profiling to see jumps in memory usage. Output is written to stdout. Controlling variables are:","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"#!sh\r\nexport DR_HOOK=1\r\nexport DR_HOOK_TIMELINE=1\r\n#-- Optional:\r\nexport DR_HOOK_TIMELINE_FREQ=1 # the default = 1000000\r\nexport DR_HOOK_TIMELINE_MB=1 # th default jump 1 MByte","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"Upon each DRHOOKTIMELINE_FREQ-call to DR_HOOK this will check for one MByte (or DRHOOKTIMELINE_MB) jumps in resident memory usage, and will print a line containing cumulutive wall clock time since start, resident memory size right now, high water mark so far, routine name (instrumented to Dr.Hook). ––","category":"page"},{"location":"DrHook/#Implicit-MPL-library-(and-MPI)-initialization-1","page":"Profiling and Traceback","title":"Implicit MPL-library (and MPI) initialization","text":"","category":"section"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"Be aware that the very first call to DR_HOOK also attempts to initialize MPL-library for you. Sometimes this is not desired or causes some hard to understand failures, especially with programs where MPI is not involved, but Dr.Hook calls are present. To turn this initialization off, set","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"#!sh\r\nexport DR_HOOK_NOT_MPI=1","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"For example, asyncronous I/O module SAMIO does that – from within its Fortran. It calls before first Dr.Hook call function","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"CALL C_DRHOOK_NOT_MPI()","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"Thus, this can be used elsewhere, too (like in util/gl tools):","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"PROGRAM SOME_UTILGL_TOOL\r\n...\r\nCALL C_DRHOOK_NOT_MPI()\r\n!-- The following now does NOT initialize MPL nor MPI for you\r\nIF (LHOOK) CALL DR_HOOK('SOME_UTILGL_TOOL',0,ZHOOK_HANDLE)\r\n...\r\nIF (LHOOK) CALL DR_HOOK('SOME_UTILGL_TOOL',1,ZHOOK_HANDLE)","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"","category":"page"},{"location":"DrHook/#Overheads-1","page":"Profiling and Traceback","title":"Overheads","text":"","category":"section"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"The DR_HOOK=1 has practically no overhead on a scalar machine. Profiling with DRHOOKOPT=prof causes some 5% overhead.","category":"page"},{"location":"DrHook/#","page":"Profiling and Traceback","title":"Profiling and Traceback","text":"On a vector machine overhead are so big that Dr.Hook should not be used there, unfortunately.","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/UseofObservation?action=edit\"","category":"page"},{"location":"UseofObservation/#Use-of-Observation-1","page":"Use of Observation","title":"Use of Observation","text":"","category":"section"},{"location":"UseofObservation/#Background-Information-1","page":"Use of Observation","title":"Background Information","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"ODBusage2.pdf Anne Fouilloux's (ECMWF) review presentation about ODB\nhttp://apps.ecmwf.int/odbgov ECMWF's ODB governance pages - useful for looking up ODB and BUFR definintions\nhttp://www.ecmwf.int/research/ifsdocs/CY28r1/pdf_files/odb.pdf The ODB bible - Sami Saarinen's ODB user guide (2004)\nhttp://www.rclace.eu/File/DataAssimilation/2007/laceobspp.pdf Sandor's document about observation dataflow in ALADIN ","category":"page"},{"location":"UseofObservation/#Observation-types-1","page":"Use of Observation","title":"Observation types","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"The observation types used by Harmonie (upper-air) data assimilation are defined in scr/include.ass.","category":"page"},{"location":"UseofObservation/#SYNOP-1","page":"Use of Observation","title":"SYNOP","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"By default all SYNOP observation types (including SHIP) are used. ","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"export SYNOP_OBS=1             # All synop","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"To blacklist SYNOP observations add blacklisted \"ODB observation type/ASCII type/ODB code type/ODB variable number/station identifier/date to blacklist from\" to nam/LISTENOIREDIAP. For example to blacklist 10m winds from Valentia Automatic SYNOP (03953) from the 10th of November 2012 enter the following line to LISTENOIREDIAP:","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":" 1 SYNOP       14  41 03953    10112012","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"(Note: please don't add Valentia to your blacklist - the observations from there are pretty good!)","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"For further information on ODB observation types, code types, variable numbers etc see the ECMWF ODB governance page here: http://apps.ecmwf.int/odbgov/obstype/","category":"page"},{"location":"UseofObservation/#SHIP-1","page":"Use of Observation","title":"SHIP","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"See information provided above on SYNOP observations.","category":"page"},{"location":"UseofObservation/#BUOY-1","page":"Use of Observation","title":"BUOY","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"By default all BUOY observation types are used. ","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"export BUOY_OBS=1              # Buoy","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"To blacklist BUOY observations add blacklisted \"ODB observation type/ASCII type/ODB code type/ODB variable number/station identifier/date to blacklist from\" to nam/LISTENOIREDIAP. For example to blacklist surface temperatures from BUOY M5 (62094) from the 10th of November 2012 enter the following line to LISTENOIREDIAP:","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":" 4 BUOY        165  11 62094    10112012","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"(Note: please don't add M4 to your blacklist - the observations from there are pretty good too!)","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"For further information on ODB observation types, code types, variable numbers etc see the ECMWF ODB governance page here: http://apps.ecmwf.int/odbgov/obstype/","category":"page"},{"location":"UseofObservation/#AIRCRAFT-1","page":"Use of Observation","title":"AIRCRAFT","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"By default all AIRCRAFT observation types (including AMDAR, AIREP, ACARS) are used. ","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"export AIRCRAFT_OBS=1          # AMDAR, AIREP, ACARS","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"Below are lines added by Xiaohua to the  DMI dka37 LISTENOIREDIAP file to exclude problematic aircraft observations:","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"2 AMDAR 144 2 EU0028 08292013\r\n2 AMDAR 144 2 EU0092 01042013\r\n2 AMDAR 144 2 EU0079 01052013\r\n2 AMDAR 144 2 EU0097 01052013\r\n2 AMDAR 144 2 EU0107 01052013\r\n2 AMDAR 144 2 EU0033 01062013\r\n2 AMDAR 144 2 EU0118 01062013\r\n2 AMDAR 144 2 EU0112 07052013\r\n2 AMDAR 144 2 EU1110 08122013\r\n2 AMDAR 144 2 EU0074 08122013","category":"page"},{"location":"UseofObservation/#TEMP-1","page":"Use of Observation","title":"TEMP","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"By default all TEMP observation types are used. ","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"export TEMP_OBS=1              # TEMP, TEMPSHIP","category":"page"},{"location":"UseofObservation/#PILOT-1","page":"Use of Observation","title":"PILOT","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"By default all PILOT observation types are used. ","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"export PILOT_OBS=1             # Pilot, Europrofiler","category":"page"},{"location":"UseofObservation/#AMSUA-1","page":"Use of Observation","title":"AMSUA","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"By default all AMSUA observation types are not used. ","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"export AMSUA_OBS=0             # AMSU-A","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"To use locally received AMSUA data provided by EUMETCast set ATOVS_SOURCE to local in scr/include.ass:","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"export ATOVS_SOURCE=mars       # local: EUMETCast; \r\n                               # mars: data from MARS\r\n                               # hirlam: hirlam radiance template ","category":"page"},{"location":"UseofObservation/#AMV-(aka-SATOB,-GEOWIND)-1","page":"Use of Observation","title":"AMV (aka SATOB, GEOWIND)","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"For AMVs there is a HOW-TO page.","category":"page"},{"location":"UseofObservation/#Other-observation-types-...-1","page":"Use of Observation","title":"Other observation types ...","text":"","category":"section"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"More documentation to follow ...","category":"page"},{"location":"UseofObservation/#","page":"Use of Observation","title":"Use of Observation","text":"export AMSUB_OBS=0             # AMSU-B, MHS\r\nexport IASI_OBS=0              # IASI  \r\nexport PAOB_OBS=0              # PAOB not defined everywhere\r\nexport SCATT_OBS=0             # Scatterometer data not defined everywhere\r\nexport LIMB_OBS=0              # LIMB observations, GPS Radio Occultations\r\nexport RADAR_OBS=0             # Radar ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/How_to_use_hires_topography?action=edit\"","category":"page"},{"location":"How_to_use_hires_topography/#Harmonie-System-Documentation-1","page":"Hires topography","title":"Harmonie System Documentation","text":"","category":"section"},{"location":"How_to_use_hires_topography/#How-to-Introduce-New-High-Resolution-Topography-into-Harmonie-1","page":"Hires topography","title":"How to Introduce New High-Resolution Topography into Harmonie","text":"","category":"section"},{"location":"How_to_use_hires_topography/#Introduction-1","page":"Hires topography","title":"Introduction","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"This page describes how to set up and use an ultra-high resolution topographic data set for your Harmonie domain, instead of the current standard GTOPO30 data set.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The data replacing GTOPO30 is likely to be much denser (by a factor of 100 or more), so it probably doesn’t make much sense for each centre to store a complete quasi-global set.  It is much more practical for each centre to generate and store a local sub-set of the high-resolution topography to encompass just their own computational domains. First the principal process is described and in [#DoitallinsideHARMONIE here] the streamlined implementation, with the coarser GMTED2010 data, in the system is summarized.","category":"page"},{"location":"How_to_use_hires_topography/#Background-1","page":"Hires topography","title":"Background","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The standard topographic data set currently used by Harmonie is the global “GTOP030” set from NASA (http://gcmd.nasa.gov/records/GCMDNCARDS758.0.html ).   This is a “Digital Elevation Model”  (DEM) with a horizontal resolution of 30 arc seconds (approx. 1km).   As Harmonie model configurations start to use grid-sizes of 1km or smaller, the computational grid can have finer resolution than the topographic grid, and so topography becomes a new limiting factor in the full model resolution.  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"It is possible now to overcome this limitation of the relatively coarse GTOPO30 topography by replacing it with a much finer-scale DEM.  One such DEM representation of the earth’s surface has been available since Oct. 2011.  This is version 2 of the DEM derived from the Aster instrument on board the Terra satellite, as part of the collaboration between Japan’s Ministry of Economy, Trade and Industry (METI), and NASA in the U.S.  In the Aster dataset, surface elevations are reported at a horizontal resolution of approx. 30m. Thus the Aster data is about 900 times denser than GTOPO30, i.e., has about 30 times higher resolution in each horizontal dimension.  The average error in the vertical elevation estimates is approx. 6-10m (I think of this as the typical height of a tree or a house – the kind of things that can confuse the satellite radiometer into reporting a false surface elevation).  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"More information about the Aster DEM is available at http://asterweb.jpl.nasa.gov/gdem.asp .  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"Even for “relatively” coarse Harmonie grids (perhaps even 2.5km meshes), the “slope”, “roughness”, “silhouette” and other physical attributes of the topography used by Harmonie can be provided much more accurately by Aster data than by GTOPO30.","category":"page"},{"location":"How_to_use_hires_topography/#Obtaining-ASTER-high-resolution-DEM-data-1","page":"Hires topography","title":"Obtaining ASTER high-resolution DEM data","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The data are publicly and freely available from NASA’s “reverb” web-site (http://reverb.echo.nasa.gov/reverb/).   Since the resolution is so fine, the complete dataset is quite voluminous: the compressed file for each 1^o^ x 1^o^ (longitude-latitude) tile or “granule” at 50^o^ N is about 15MB if totally land-covered.  To obtain the data you want:","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"Draw a bounding rectangle around your domain of interest (even all of Europe!) at that “reverb” web-site;\nSelect“ASTER Global Digital Elevation Model V0002” from the list of data sets further down the same web-page;\nClick the “Search for Granules” box at the bottom of the page.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"From here you will be brought through a standard registration process familiar to anyone who has ever bought a train ticket online – the main difference being that the Aster data are free.   Once registration is complete, you should receive an email after 1-2 days telling you that your data is ready, and how you can ftp it to your own computer.  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"I obtained 97 “granules” of such data (i.e., DEM files for an area approximately 1^o^ square), covering the islands of Ireland and the UK (14^o^ longitude x 11^o^ latitude).  The 57 “missing” granules are simply ocean regions that encompass no land at all.  No granules are provided for any 1-degree tile that is completely over the open ocean, since sea-level elevation is assumed to be zero.   Each granule is a separate zip file, varying in size up to about 15MB, depending on the fraction of land area in each 1-degree tile and the complexity of the topography itself.  Granules are identified by the latitude and longitude of the southwest (lower-left) corner (or more precisely, of the geometric centre of the southwest corner pixel), which is given in the file-name.  ","category":"page"},{"location":"How_to_use_hires_topography/#Processing-the-Raw-Aster-Data-1","page":"Hires topography","title":"Processing the Raw Aster Data","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"Each “granule” of data is a zip file that unzips to 2 “tiff” files (ASTGM2_*_dem.tif, containing the actual data, and ASTGM2_*_num.tif, containing “quality assessment”), along with a generic README.pdf.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The Quality Assessment files (*num.tif) contains the number of “stereo scene pairs” used to determine elevation at each pixel (if positive) or the source of non-ASTER elevation data used to  replace bad ASTER DEM (if negative).  Values less than 5 are associated with relatively larger errors in the elevation measurement.  Larger values are associated with more accurate final estimates of surface elevation.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"This information can help to identify those regions where the Aster values may need to be merged or replaced with elevation data from some other source.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"For the purposes of formatting the DEM data for Harmonie, the first step is to extract the (longitude, latitude, elevation) triplet for each “pixel” (or  “grid-point”) from the ASTGM2_*_dem.tif  files.  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"This can be done using software such as the Geospatial Data Abstraction Library (GDAL) open-source tools, available from http://www.gdal.org.  Once installed, these can be used to read, merge, and otherwise manipulate geoTIFF files.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The command I used to generate a simple text file containing longitude, latitude and elevation from an ASTGM2_*_dem.tif file is, e.g.,","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"gdal_translate –of XYZ ASTGM2_N59W006_dem.tif ASTGM2_N59W006_xyz.txt","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"This fills the ascii output file  ASTGTM2_N59W006_xyz.txt with rows of (longitude, latitude, elevation) values, starting from the northwest (top-left) corner (-6, 60), and proceeding eastwards to (-5,60), then moving south to the next row, ending up at the southeast (bottom-right) corner (-5,59).  Each output text file contains 3601 x 3601 data-points, i.e., 12,967,201 rows, and uses over 550 MB of storage.  Note that the various granules overlap each other at the boundaries (the line of boundary data is included in each bounding file).  Elevation is in units of metres.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"This is relatively straightforward and only needs to be done once for each file,  even if there may be more efficient ways to do it.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The command above can easily be scripted to process the full collection of *dem.tif files:","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"for i in $( ls ASTGTM2_*_dem.tif ); do\r\n  gdal_translate -of XYZ $i $i.xyz\r\ndone","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"To obtain some information about any particular tif file, use the gdalinfo command.  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"Next, the data from each separate 1^o^ x 1^o^ text file were combined into a single flat unformatted little-endian binary file consisting of surface elevation every 30m or so encompassing the entire Harmonie domain.  For an Ireland/UK domain, bounded between latitudes 49 and 60 deg. N, and between longitudes 11 deg. W and 3 deg. E, this contains approx. 40,000 (latitude) x 50,000 (longitude) data points – or about 2 billion points altogether.  (2 billion points stored in 2-byte integer format use about 4GB of storage).  A domain like this can easily be extended to the west and north, where there is no land and where sea-level elevation is simply zero.  In order to extend it to the south or east, however, where there is land, extra Aster granules would be required.  See the attached standalone program (or [wiki:hirestopoggather_tiles.f]) for the details of what I did (crude but effective; nothing fancy and probably not the best way, but simple and it works).  The file is written with the first element at the northwest corner, progressing eastwards, then south, with the last element at the southeast corner.","category":"page"},{"location":"How_to_use_hires_topography/#Errors-and-Data-Gaps-1","page":"Hires topography","title":"Errors and Data Gaps","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"I did not notice any gaps or \"bad data\" in the Aster topography over Ireland and the UK, but there do seem to be some gaps, negative pixels or positive \"spikes\" elsewhere, esp. over Scandanavia and other high latitudes.  The \"quality assessment\" numbers in the ASTGM2_*_num.tiffiles mentioned above can help to identify bad or dubious elevation values.  Nicolas Bauer (FMI) has a procedure for detecting and correcting these.  ","category":"page"},{"location":"How_to_use_hires_topography/#Formatting-topographic-data-for-use-by-Harmonie-1","page":"Hires topography","title":"Formatting topographic data for use by Harmonie","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The main topographic data files used by Harmonie are in $HM_CLDATA/PGD, and are called gtopo30.hdr and gtopo30.dir .  In principle, all that is required now is to replace these 2 files (containing GTOPO30 data) with equivalent files containing Aster data.  There is no need to change the file names or to edit any Harmonie source code – just create new files with the old names, and containing Aster instead of GTOPO30 data.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The gtopo30.hdr file is the “header” file, containing meta-data about the main data file (gtopo30.dir).   The header file contains all the information needed by the MASTERODB executable to read in the real data from the gtopo30.dir file, and to use it appropriately within the rest of Harmonie.   The original gtopo30.hdr file contains:","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"GTOPO30 orography model, rewritten by V. Masson, CNRM, Meteo-France, 16/07/98\r\nnodata: -9999\r\nnorth: 90.\r\nsouth: -90.\r\nwest: -180.\r\neast: 180.\r\nrows: 21600\r\ncols: 43200\r\nrecordtype: integer 16 bytes","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"Note that this file specifies a global domain.  To use Aster data for the Ireland/UK domain, this content ended up being replaced with:","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"ASTER orography model, starting UL\r\nnodata: -9999\r\nnorth: 60\r\nsouth: 49\r\nwest: -11\r\neast: 3\r\nrows: 39601\r\ncols: 50401\r\nrecordtype: integer 16 bits","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"While the number of rows and columns is about the same as before, the topographic domain is much smaller.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"In the Harmonie source, the key files that are involved in reading and parsing the gtopo30.hdr and gtopo30.dir files are surfex/pgd/zoom_pgd_orography.F90 and surfex/aux/read_direct.F90.  Parsing these files reveals  what is needed to write gtopo30.hdr and gtopo30.dir files containing Aster data.  I wrote another simple program to do this, based largely on programs already written by Nicolas Bauer and Imanol Guerrero, and provided by Laura Rontu.   This program is available as attachement, or at:  [wiki:hires_convert.f] .","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The part of this file that writes the header data is:","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"!    Header file for harmonie:\r\n       open(unit=23,file=\"hires_irluk_hm.hdr\",form='formatted',\r\n     &      status='new',IOSTAT=ios)\r\n            write(23,FMT='(A)') \"GTOPO30 orography model, starting UL\"\r\n            write(23,FMT='(A)') \"nodata: -9999\"\r\n                  write(caux,*) north\r\n            write(23,FMT='(A)') \"north: \"//adjustl(trim(caux))\r\n                  write(caux,*) south\r\n            write(23,FMT='(A)') \"south: \"//adjustl(trim(caux))\r\n                  write(caux,*) west\r\n            write(23,FMT='(A)') \"west: \"//adjustl(trim(caux))\r\n                  write(caux,*) east\r\n            write(23,FMT='(A)') \"east: \"//adjustl(trim(caux))\r\n                  write(caux,*) npts_ns\r\n            write(23,FMT='(A)') \"rows: \"//adjustl(trim(caux))\r\n                  write(caux,*) npts_ew\r\n            write(23,FMT='(A)') \"cols: \"//adjustl(trim(caux))\r\n            write(23,FMT='(A)') \"recordtype: integer 16 bits\"","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The character variable “caux” is used here as an “internal” file to hold the various domain parameters corresponding to the Aster data.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The main DEM data file is written in integer*2 format to the new gtopo30.dir file, as in:","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"      integer*2, allocatable :: elev_hm(:,:)\r\n      integer*2                   ::  idata\r\n      character*2                :: cdata, ctmp\r\n      equivalence (idata,cdata)\r\n...   \r\n      allocate (elev_hm(npts_ew,npts_ns))\r\n!  Start of main (outer) loop:\r\n       do j=1,npts_ns\r\n          read(21) elevation\r\n          elev_hm(:,j) = elevation(:)\r\n       enddo\r\n          close(21)\r\n          deallocate(elevation)\r\n\r\n!  So now elev_hm should be filled.\r\n\r\n!  Byte-swap from little to big-endian (for sake of Harmonie build...):\r\n       do j=1,npts_ns\r\n          do i=1,npts_ew\r\n              idata = elev_hm(i,j)\r\n              ctmp(1:1) = cdata(1:1)\r\n              cdata(1:1) = cdata(2:2)\r\n              cdata(2:2) = ctmp(1:1)\r\n              elev_hm(i,j) = idata\r\n          enddo\r\n       enddo\r\n\r\n       open(unit=24,file=\"gtopo30.dir\",form=\"unformatted\",\r\n     &      access=\"direct\",recl=npts_ns*npts_ew*2,status=\"new\",err=999)\r\n\r\n!  Write starting from NW corner, working east, then south one row:\r\n        write(24,rec=1) ((elev_hm(i,j),i=1,npts_ew), j=1,npts_ns)","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"Note the explicit conversion to big-endian (so no “-convert big-endian” compiler flag should be used with this).   ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"Note too that when using Intel compilers, the “-assume byterecl” option must be used so that record lengths are in bytes instead of (4-byte) words.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"Once those simple programs are run to perform straightforward file-format conversions, the resulting gtopo30.hdr and gtopo30.dir files (containing Aster data) can be used directly in CLDATA/PGD in place of the original “real” ones (containing GTOPO30 data).  Those files are read by Harmonie during the “Climate” phase, and generate reference “climate” files PGD.lfi and PGD.fa.  These remain constant and are not generated again for each Harmonie installation.  They are read in by the surfex module during each Forecast phase, and used wherever surface topographic data is needed.","category":"page"},{"location":"How_to_use_hires_topography/#Do-it-all-inside-HARMONIE-1","page":"Hires topography","title":"Do it all inside HARMONIE","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"We discovered that there are a lot of \"holes\" in the ASTER data over Scandinavia, so instead we focused on the GMTED2010 data set (http://topotools.cr.usgs.gov/gmtedviewer/). This almost global dataset is compiled of different high resolution DEM sources and the highest available resolution is 7.5 arc seconds (~250 meters). It is used by Meteo-France for their 1.3 km domain. This data also comes in tiles of big tif-files like the ASTER data so a similar method described above can be used on this dataset. The different tiles cover an area that is 30 by 20 degrees longitude/latitude. There are no valid data north of 84 degrees north and south of 56 degrees south. The two steps described above have been streamlined in harmonie-40h1 and the main tasks have been gathered in Preparegmted which is called from Preparepgd. What's required from the user is to download (http://topotools.cr.usgs.gov/gmtedviewer/viewer.htm) the GMTED2010 data and locate them in the appropriate location and point the following variable in Env_system to the location:","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"   export GMTED2010_INPUT_PATH=/project/hirlam/harmonie/climate/GMTED2010","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"To use the GMTED2010 data and not GTOPO30 we have to define the input source, once again in ecf/config_exp.h .","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"   TOPO_SOURCE=gmted2010","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The Prepare_gmted script checks for the chosen domain size and selects the necessary tiles and then combines them together into one geotiff file under CLIMDIR. Small python script tif2bin.py then converts the new geotiff to the binary (dir/hdr) format needed for PGD generation.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"On cca (ECMWF) the following input files are available under /project/hirlam/harmonie/climate/GMTED2010:","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":" 10N030W_20101117_gmted_mea075.tif\r\n 30N030E_20101117_gmted_mea075.tif\r\n 30N000E_20101117_gmted_mea075.tif\r\n 30N030W_20101117_gmted_mea075.tif\r\n 30N060W_20101117_gmted_mea075.tif\r\n 30N090W_20101117_gmted_mea075.tif\r\n 50N030E_20101117_gmted_mea075.tif\r\n 50N000E_20101117_gmted_mea075.tif\r\n 50N030W_20101117_gmted_mea075.tif\r\n 50N060W_20101117_gmted_mea075.tif\r\n 50N090W_20101117_gmted_mea075.tif\r\n 70N030E_20101117_gmted_mea075.tif\r\n 70N000E_20101117_gmted_mea075.tif\r\n 70N030W_20101117_gmted_mea075.tif\r\n 70N060W_20101117_gmted_mea075.tif\r\n 70N090W_20101117_gmted_mea075.tif","category":"page"},{"location":"How_to_use_hires_topography/#Tests-of-Aster-vs.-GTOPO30-Topography-1","page":"Hires topography","title":"Tests of Aster vs. GTOPO30 Topography","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The images below shows the topography of the Burren, a hilly region in the west of Ireland, approx. 30km square, as represented by GTOPO30 (top) and Aster (bottom).  The extra detail provided by Aster is apparent.  The segments of straight line represent the coastline as plotted by the GrADS \"hires\" map.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The difference fields of surface winds and sea-level pressure between a Harmonie run using GTOPO30 PGD files and another Harmonie run using PGD files from the Aster topography are shown in the image below.  Both runs were at 0.5km resolution over a West of Ireland domain, and the difference fields were taken after a 24hr forecast.  The only difference between these two runs was the PGD.lfi and PGD.fa topographic files used as input – or more precisely, between the topographic datasets used to generate those 2 PGD files.  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The first point to emphasize about this chart is that the differences are very small: the scale on the right is in units of 0.02hPa, and maximum sea-level pressure difference is only about 0.1hPa in magnitude (though it can be of either sign), and surface wind-speed differences are no larger than 0.4m s^-1^.  So refining the PGD topography has a relatively small impact on the overall forecast.  The main feature of the sea-level pressure difference field is the wave-train originating in the mountains of Connemara and propagating downstream eastwards.  The slight difference in representation of those mountains between GTOPO30 and Aster is enough to generate that weak but surprisingly coherent wave-train.  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The topographic input used by the “Aladin” part of Harmonie (from OroMean, NbPeaks, and other files) were unchanged for these runs.  ","category":"page"},{"location":"How_to_use_hires_topography/#What-about-the-Aladin-Topography-Files-(Oro_Mean,-etc.)?-1","page":"Hires topography","title":"What about the Aladin Topography Files (Oro_Mean, etc.)?","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The directory HM_CLDATA/GTOPT030 contains 9 files, 7 of which are derived in some way from the full GTOPO30 topography data set:","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"=  File \t\t\t= =\t\tField \t\t\t\t\t= =\t  Unit = =  Nb bits =\nOro_Mean Mean orography (mean of Hmean) m 16\nSigma Sub-grid std dev of Hmean m 16\nNb_Peaks Number of sub-grid peaks  8\nHmax-HxH-Hmin_ov4 mean of (Hmax-Hmean)(Hmean-Hmin)/4 m^2^ 32\nDhoverDxDhover_Dy mean of dHmean/dx x dHmean/dy m^2^ km^-2^ 32\nDhoverDx_square mean of (dHmean/dx)^2^ m^2^ km^-2^ 32\nDhoverDy_square mean of (dHmean/dy)^2^ m^2^ km^-2^ 32\nWater_Percentage Land/Sea mask % water 8\nUrbanisation Fraction of urbanisation % city 8","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"2 of the files (Urbanisation, Water_Percentage) are from a NOAA/Navy Global95 dataset and are not related to GTOPO30 at all.  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The other 7 files each contain information derived from 5x5 sub-grid boxes of the main gtopo30.dir.  (So each is 25 times smaller than gtopo30.dir, accounting for data-type).","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"The word \"mean\" in the table above means \"averaged over the GTOPO30 pixels contained in one 2'30\" box (usually 5x5 GTOPO30 pixels)\".   ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"All these files are read in by ald/c9xx/eincli1.F90 .  At run-time, the files are only read during the \"Climate\" phase of each run, and the information in them ultimately written out to the m01, m02, etc. monthly files.","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"After that, however, these files have no effect whatsoever on Forecast output.  ","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"If the 7 secondary GTOPO30 files above are replaced with equivalent ones generated from Aster data, they are read during the \"Climate\" phase and embedded into m01, m02, etc., but then forecast runs that use these generate output that is bit-wise identical to that produced by a \"control\" executable (and \"control\" m01, etc.) based on GTOPO30.  (Originally, I found some very small differences in output between my \"Aster\" and \"GTOPO30\" runs, but that must have been due to me changing something too much in my \"Aster\" executable, which necessarily uses modified eincli1.F90 and einter1.F90 input files, or not using a totally \"clean slate\" of input files to start with).","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"So those 9 derived files in HM_CLDATA/GTOPT030 are ultimately redundant, and there is no point replacing them with equivalent ones based on high-resolution Aster topography.","category":"page"},{"location":"How_to_use_hires_topography/#Comment-Laura-Rontu-21-July-2013-1","page":"Hires topography","title":"Comment Laura Rontu 21 July 2013","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"In my understanding, the 7 secondary files are used to derive the following three fields in m01 etc. (example from gl listing of some m01):","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":" SURFET.GEOPOTENT> 001:220-00000-105@   10115_00:00+0000 000 Standard deviation of orograph   0.000E+000  195.020E+000    4.812E+003  326.546E+000\r\n SURFVAR.GEOP.ANI> 001:221-00000-105@   10115_00:00+0000 000 Anisotropy coeff of topography   0.000E+000  542.720E-003    1.000E+000  313.600E-003\r\n SURFVAR.GEOP.DIR> 001:222-00000-105@   10115_00:00+0000 000 Direction of main axis of topo  -1.571E+000   96.202E-003    1.939E+000  661.270E-003","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"These are used by the ALADIN/ALARO buoyancy wave parametrization for generation and dissipation of subgrid-scale waves due to orography. Such a parametrization is not applied in AROME, thus these fields are not used there and do not have any influence on AROME results. However, these or similar variables can be found also in the PGD file, among other orography-related variables derived from GTOPO30 (another example of gl listing of some PGD.lfi):","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":" ZS              > 001:008-00000-105@20051219_00:00+0000 000 Oro hgt.     0.000E+000  137.923E+000    1.354E+003  152.975E+000\r\n AVG_ZS          > 001:001-00600-105@20051219_00:00+0000 000 Average oro     0.000E+000  137.923E+000    1.436E+003  154.681E+000\r\n SIL_ZS          > 001:002-00600-105@20051219_00:00+0000 000 Silhouette oro     0.000E+000  150.633E+000    1.575E+003  168.821E+000\r\n SSO_STDEV       > 001:005-00600-105@20051219_00:00+0000 000 Stdv SSO    -0.000E+000   16.335E+000  435.020E+000   24.560E+000\r\n MIN_ZS          > 001:003-00600-105@20051219_00:00+0000 000 Min subgrid oro     0.000E+000  119.170E+000    1.250E+003  136.836E+000\r\n MAX_ZS          > 001:004-00600-105@20051219_00:00+0000 000 Max subgrid oro     0.000E+000  162.376E+000    1.776E+003  181.778E+000\r\n SSO_ANIS        > 001:006-00600-105@20051219_00:00+0000 000 Aniso SSO     0.000E+000  543.880E-003    1.000E+000  194.160E-003\r\n SSO_DIR         > 001:007-00600-105@20051219_00:00+0000 000 Direction SSO   -90.000E+000   29.056E+000   90.000E+000   40.999E+000\r\n SSO_SLOPE       > 001:008-00600-105@20051219_00:00+0000 000 Slop SSO     0.000E+000   28.708E-003  718.360E-003   41.450E-003\r\n HO2IP           > 001:009-00600-105@20051219_00:00+0000 000 h/2 i+     0.000E+000    6.905E+000  274.755E+000   11.246E+000\r\n HO2JP           > 001:010-00600-105@20051219_00:00+0000 000 h/2 j+     0.000E+000    7.030E+000  290.501E+000   11.472E+000\r\n HO2IM           > 001:011-00600-105@20051219_00:00+0000 000 h/2 i-     0.000E+000    6.964E+000  256.012E+000   11.534E+000\r\n HO2JM           > 001:012-00600-105@20051219_00:00+0000 000 h/2 j-     0.000E+000    7.190E+000  352.647E+000   11.734E+000\r\n AOSIP           > 001:013-00600-105@20051219_00:00+0000 000 A/S i+     0.000E+000    8.055E-003  548.990E-003   14.087E-003\r\n AOSJP           > 001:014-00600-105@20051219_00:00+0000 000 A/S j+     0.000E+000    8.297E-003  461.020E-003   14.306E-003\r\n AOSIM           > 001:015-00600-105@20051219_00:00+0000 000 A/S i-     0.000E+000    8.280E-003  521.020E-003   14.863E-003\r\n AOSJM           > 001:016-00600-105@20051219_00:00+0000 000 A/S i-     0.000E+000    8.454E-003  471.930E-003   15.079E-003","category":"page"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"Presently, derivations are done automatically, so there is nothing to worry for the user from the point of view of technical implementation. However, eventually there are needs for further development and improvements when the high-resolution source data on topography will be used.","category":"page"},{"location":"How_to_use_hires_topography/#Conclusion-1","page":"Hires topography","title":"Conclusion","text":"","category":"section"},{"location":"How_to_use_hires_topography/#","page":"Hires topography","title":"Hires topography","text":"In order to replace the (relatively) coarse-resolution GTOPO30 topography with higher-resolution data (e.g., from Aster), it is enough to generate replacements for the gtopo30.hdr and gtopo30.dir files in the $HM_CLDATA/PGD directory, as described in the upper part of this page.","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ConfigureYourExperiment?action=edit\"","category":"page"},{"location":"ConfigureYourExperiment/#Experiment-configuration-1","page":"Experiment","title":"Experiment configuration","text":"","category":"section"},{"location":"ConfigureYourExperiment/#Introduction-1","page":"Experiment","title":"Introduction","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"There are several levels on configuration available in HARMONIE. The highest level of configuration is done in config_exp.h. It includes the environment variables, which are used to control the experimentation. In the following we describe the meaning of the different variables and are described in the order they appear in config_exp.h.","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Host specific paths and environment variables for your system are defined in Env_system. Read more here.","category":"page"},{"location":"ConfigureYourExperiment/#Build-options-1","page":"Experiment","title":"Build options","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Build and bin paths ****\r\n# Definitions about Build, should fit with hm_rev\r\nBUILD=${BUILD-yes}                     # Turn on or off the compilation and binary build (yes|no)","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"BUILD is a switch for compiling HARMONIE code (yes|no).","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"BINDIR=${BINDIR-$HM_DATA/bin}                 # Binary directory","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"BINDIR is the location of where your HARMONIE binaries will be installed. You can use this to point to binaries outside of your experiment. A few other options for non default configurations exists as well:","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"COMPILE_ENKF=${COMPILE_ENKF-\"no\"}             # Compile LETKF code (yes|no)\r\nCOMPILE_DABYFA=${COMPILE_DABYFA-\"no\"}         # Compile FA/VC code (yes|no)\r\nSURFEX_OFFLINE_BINARIES=\"no\"                  # Switch to compile and use offline SURFEX binaries","category":"page"},{"location":"ConfigureYourExperiment/#General-settings-1","page":"Experiment","title":"General settings","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Misc, defined first because it's used later ****\r\n\r\nCNMEXP=HARM                             # Four character experiment identifier\r\nWRK=$HM_DATA/$CYCLEDIR                  # Work directory","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"CNMEXP: experiment identifier used by MASTERODB\nWRK is the work directory. The suggested path on cca is SCRATCHhm_home{EXP}/CYCLEDIR","category":"page"},{"location":"ConfigureYourExperiment/#Archive-settings-(ECMWF)-1","page":"Experiment","title":"Archive settings (ECMWF)","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Since SCRATCH is cleaned regularly on cca and ecgb some files are transferred to ECFS for a more permanent storage by the scripts Archive_host1 and Archive_ecgb. ","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Paths to archive ****\r\n# We need to define ARCHIVE early since it might be used further down\r\n\r\nARCHIVE_ROOT=$HM_DATA/archive           # Archive root directory\r\nECFSLOC=ectmp                           # Archiving site at ECMWF-ECFS: \"ec\" or ECFS-TMP \"ectmp\"\r\nECFSGROUP=hirald                        # Group in which to chgrp the ECMWF archive, \"default\" or \"hirald\"\r\nEXTRARCH=$ARCHIVE_ROOT/extract          # Archive for fld/obs-extractions","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"ARCHIVE_ROOT is the path to forecast file archive. Note that at ECMWF this directory is not a permanent storage\nEXTRARCH is the path to field extraction archive. Note that at ECMWF this directory is not a permanent storage\nECFSLOC Archiving site at ECMWF-ECFS  (ectmp|ec) Note that files archived on ectmp will be lost after 90 days. If you wish your files to stay longer you should set ECFSLOC=ec. \nECFSGROUP Group in which to chgrp the ECMWF archive, (hirald|default)","category":"page"},{"location":"ConfigureYourExperiment/#Running-Mode-1","page":"Experiment","title":"Running Mode","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Running mode ****\r\nRUNNING_MODE=research                   # Research or operational mode (research|operational)\r\n                                        # operational implies that the suite will continue even if e.g.\r\n                                        # observations are missing or assimilation fails\r\n\r\nSIMULATION_TYPE=nwp                     # Type of simulation (nwp|climate)","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"RUNNING_MODE can be research or operational. Operational is more forgiving in the error handling and e.g. the assimilation will be skipped if Bator doesn't find any observations. Exceptions handled by the operational mode are written to $HM_DATA/severe_warnings.txt\nSIMULATION_TYPE Switch between nwp and climate type of simulation. The climate simulations are still in an experimental stage. See HARMONIE-Climate for cy43h2 for more information","category":"page"},{"location":"ConfigureYourExperiment/#Model-domain-settings-1","page":"Experiment","title":"Model domain settings","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Horizontal domain settings. Further information is available here: HarmonieSystemDocumentation/ModelDomain","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Model geometry ****\r\nDOMAIN=DKCOEXP                          # See definitions in scr/Harmonie_domains.pm\r\nTOPO_SOURCE=gmted2010                   # Input source for orography. Available are (gmted2010|gtopo30)\r\nGRID_TYPE=LINEAR                        # Type of grid (LINEAR|QUADRATIC|CUBIC)","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"DOMAIN defines your domain according to the settings in scr/Harmonie_domains.pm (DKCOEXP). The spectral truncation for your domain is determined from NLON and NLAT by scr/Harmonie_domains.pm. Further information on model domains are available in HarmonieSystemDocumentation/ModelDomain\nTOPO_SOURCE: Defines input source for model orography (gmted2010|gtopo30). Further information available here: hi-res topography\nGRID_TYPE: This variable is used to define the spectral truncation used (LINEAR|QUADRATIC|CUBIC). GRID_TYPE is used in scr/Climate and scr/Forecast","category":"page"},{"location":"ConfigureYourExperiment/#Vertical-levels-1","page":"Experiment","title":"Vertical levels","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Set the number vertical levels to use. Further information is available here: HarmonieSystemDocumentation/VerticalGrid","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"VLEV=65                                 # Vertical level definition name\r\n                                        # HIRLAM_60, MF_60,HIRLAM_40, or\r\n                                        # BOUNDARIES = same number of levs as on boundary file.\r\n                                        # See the other choices from scr/Vertical_levels.pl","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"VLEV is the name of the vertical levels defined in Vertical_levels.pl (65). Further information is available here: Vertical Grid. If you intend to run upper air assimilation you must select the same domain and level definition for which you have derived structure functions. Read more here: Structure Functions","category":"page"},{"location":"ConfigureYourExperiment/#Forecast-model-1","page":"Experiment","title":"Forecast model","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Higher level forecast model settings.","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** High level forecast options ****\r\nNAMELIST_BASE=\"harmonie\"                # Input for namelist generation (harmonie|alaro1)\r\n                                        #   harmonie : The default HARMONIE namelist base nam/harmonie_namelists.pm\r\n                                        #   alaro1   : For ALARO-1 baseline with only a few configurations available\r\n                                        #              nam/alaro1_namelists.pm\r\nDYNAMICS=\"nh\"                           # Hydrostatic or non-hydrostatic dynamics (h|nh)\r\nVERT_DISC=vfd                           # Discretization in the vertical (vfd,vfe)\r\n                                        # Note that vfe does not yet work in non-hydrostatic mode\r\nPHYSICS=\"arome\"                         # Main model physics flag (arome|alaro)\r\nSURFACE=\"surfex\"                        # Surface flag (old_surface|surfex)\r\nDFI=\"none\"                              # Digital filter initialization (idfi|fdfi|none)\r\n                                        # idfi : Incremental dfi\r\n                                        # fdfi : Full dfi\r\n                                        # none : No initialization (AROME case)\r\nLSPBDC=no                               # Spectral boundary contions option off(no) | on(yes)\r\nLGRADSP=yes                             # Apply Wedi/Hortal vorticity dealiasing\r\nLUNBC=yes                               # Apply upper nested boundary condition","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"NAMELIST_BASE: Two different namelist sets are available (harmonie|alaro).\nDYNAMICS: Hydrostatic or non-hydrostatic dynamics (h|nh)\nVERT_DISC: Vertical discretization (vfd,vfe)\nPHYSICS: HARMONIE uses either AROME or ALARO for its forecast model physics (arome|alaro)\nSURFACE: Surface physics flag to use either the SURFEX or the ALADIN surface scheme(surfex|old_surface)\nDFI: Digital filter initialization switch (idfi|fdfi|none). idfi - incremental dfi, fdfi - full dfi, none - no initialization. See Digital filter for more information\nLSPBDC: Specify whether the boundary conditions are spectral or not (yes|no)\nLGRADSP: Switch to apply vorticity dealiasing (yes|no)\nLUNBC: Switch to apply upper boundary conditions (yes|no)","category":"page"},{"location":"ConfigureYourExperiment/#Physics-1","page":"Experiment","title":"Physics","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Physics options.","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# Highlighted physics switches\r\nCISBA=\"3-L\"                             # Type of ISBA scheme in SURFEX. Options: \"3-L\" and \"2-L\".\r\nCROUGH=\"NONE\"                           # SSO scheme used in SURFEX \"NONE\"|\"'Z01D'\"|\"'BE04'\"\r\nSURFEX_SEA_ICE=\"none\"                   # Treatment of sea ice in surfex (none|sice)\r\nMASS_FLUX_SCHEME=edmfm                  # Version of EDMF scheme (edkf|edmfm)\r\n                                        # Only applicable if PHYSICS=arome\r\n                                        # edkf is the AROME-MF version\r\n                                        # edmfm is the KNMI implementation of Eddy Diffusivity Mass Flux scheme for Meso-scale\r\nHARATU=\"yes\"                            # Switch for HARATU turbulence scheme (no|yes)\r\nALARO_VERSION=0                         # Alaro version (1|0)","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"CISBA: If SURFACE is set to surfex this selects the type of ISBA scheme to use in SURFEX. (3-L|2-L). See surfex_namelists.pm for more info.\nCROUGH: If SURFACE is set to surfex this selects the sub-grid scale orography scheme used in SURFEX. (NONE|Z01D|BE04). See surfex_namelists.pm for more info.\nSURFEXSEAICE: Treatment of sea ice in surfex (none|sice). See surfex_namelists.pm for more info.\nMASSFLUXSCHEME: If PHYSICS is set to arome choose the mass flux scheme to be used by AROME; edkf to use the AROME-MF scheme or edmfm to use the KNMI developed scheme\nHARATU: Switch to use the HARATU turbulence scheme\nALARO_VERSION: If PHYSICS is set to alaro select version of ALARO to use (0|1)","category":"page"},{"location":"ConfigureYourExperiment/#Assimilation-1","page":"Experiment","title":"Assimilation","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Data assimilation settings. More assimilation related settings, in particular what observations to assimilate, can be found in include.ass","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Assimilation ****\r\nANAATMO=3DVAR                           # Atmospheric analysis (3DVAR|4DVAR|blending|none)\r\nANASURF=CANARI_OI_MAIN                  # Surface analysis (CANARI|CANARI_OI_MAIN|CANARI_EKF_SURFEX|none)\r\n                                        # CANARI            : Old style CANARI\r\n                                        # CANARI_OI_MAIN    : CANARI + SURFEX OI\r\n                                        # CANARI_EKF_SURFEX : CANARI + SURFEX EKF ( experimental )\r\n                                        # none              : No surface assimilation\r\nANASURF_MODE=\"before\"                   # When ANASURF should be done\r\n                                        # before            : Before ANAATMO\r\n                                        # after             : After ANAATMO\r\n                                        # both              : Before and after ANAATMO (Only for ANAATMO=4DVAR)\r\nINCV=\"1,1,1,1\"                          # Active EKF control variables. 1=WG2 2=WG1 3=TG2 4=TG1\r\nINCO=\"1,1,0\"                            # Active EKF observation types (Element 1=T2m, element 2=RH2m and element 3=Soil moisture) \r\n\r\nMAKEODB2=no                             # Conversion of ODB-1 to ODB-2 using odb_migrator\r\n\r\nSST=BOUNDARY                            # Which SST fields to be used in surface analysis\r\n                                        # BOUNDARY          : SST interpolated from the boundary file. ECMWF boundaries utilize a special method.\r\n                                        #                     HIRLAM and HARMONIE boundaries applies T0M which should be SST over sea.\r\nLSMIXBC=no                              # Spectral mixing of LBC0 file before assimilation\r\n[ \"$ANAATMO\" = 3DVAR] && LSMIXBC=yes\r\nJB_INTERPOL=no                          # Interpolation of structure functions from a pre-defined domain to your domain\r\n","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"ANAATMO: Atmospheric analysis (3DVAR|4DVAR|blending|none)\nANASURF: Surface analysis (CANARI|CANARIOIMAIN|CANARIEKFSURFEX|none). See surfex_namelists.pm for more info.\nANASURF_MODE:When the surface should be called (before|after|both)\nINCV: Active EKF control variables. 1=WG2 2=WG1 3=TG2 4=TG1 (0|1)\nINCO: Active EKF observation types (Element 1=T2m, element 2=RH2m and element 3=Soil moisture) (0|1)\nMAKEODB2: Option to convert ODB-1 databases to ODB-2 files for DA monitoring\nSST: which sea surface temperature field to use in the surface analysis\nLSMIXBC Spectral mixing of LBC0 file before assimilation (no|yes)\nJB_INTERPOL Interpolation of structure functions from a pre-defined domain to your domain (no|yes). Note that this has to be used with some caution.","category":"page"},{"location":"ConfigureYourExperiment/#Observations-1","page":"Experiment","title":"Observations","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Observations ****\r\nOBDIR=$HM_DATA/observations             # Observation file directory\r\nRADARDIR=$HM_DATA/radardata             # Radar observation file directory\r\nSINGLEOBS=no                            # Run single obs experiment with observation created by scr/Create_single_obs (no|yes)\r\n\r\nUSE_MSG=no                              # Use MSG data for adjustment of inital profiles, EXPERIMENTAL! (no|yes)\r\nMSG_PATH=$SCRATCH/CLOUDS/               # Location of input MSG FA file, expected name is MSGcloudYYYYMMDDHH","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"OBDIR: Defines the directory that your (BUFR) observation files (obYYYYMMDDHH) are to read from\nRADARDIR: Defines the directory that your (OPERA HDF5) radar observation files are to be read from. BALTRAD OPERA HDF5, MF BUFR and LOCAL files are treated in scr/Prepradar\nSINGLEOBS Run single obs experiment with synthetic observation created by [source:Harmonie/scr/Createsingleobs scr/Createsingleobs) (no|yes)\nUSE_MSG: Use MSG data for adjustment of inital profiles, EXPERIMENTAL! (no|yes)\nMSG_PATH:  Location of input MSG FA file, expected name is MSGcloudYYYYMMDDHH. Note that the pre-processing software to generate input files is not yet included in HARMONIE","category":"page"},{"location":"ConfigureYourExperiment/#DVAR-settings-1","page":"Experiment","title":"4DVAR settings","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"4DVAR settings (experimental)","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** 4DVAR ****\r\nNOUTERLOOP=1                            # 4DVAR outer loops, need to be 1 at present\r\nILRES=2,2                               # Resolution (in parts of full) of outer loops\r\nTSTEP4D=360,360                         # Timestep length (seconds) of outer loops TL+AD\r\nTL_TEST=yes                             # Only active for playfile tlad_tests\r\nAD_TEST=yes                             # Only active for playfile tlad_tests","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"NOUTERLOOP: Number of outer loops, need to be 1 at present\nILRES:  Resolution (in parts of full) of outer loops\nTSTEP4D: Timestep length (seconds) of outer loops TL+AD\nTL_TEST: Only active for playfile tlad_tests (yes|no)\nAD_TEST: Only active for playfile tlad_tests (yes|no)","category":"page"},{"location":"ConfigureYourExperiment/#Digital-filter-settings-1","page":"Experiment","title":"Digital filter settings","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Digital filter initialization settings if DFI is not equal to \"none\"","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** DFI setting ****\r\nTAUS=5400                               # cut-off frequency in second\r\nTSPAN=5400                              # 7200s or 5400s","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"TAUS cut-off frequency in seconds \nTSPAN length of DFI run in seconds","category":"page"},{"location":"ConfigureYourExperiment/#Boundaries-and-initial-conditions-1","page":"Experiment","title":"Boundaries and initial conditions","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Settings for generation of lateral boundaries conditions for HARMONIE. Further information is available here: HarmonieSystemDocumentation/BoundaryFilePreparation","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Lateral boundary conditions ****\r\nHOST_MODEL=\"ifs\"                        # Host model (ifs|hir|ald|ala|aro)\r\n                                        # ifs : ecmwf data\r\n                                        # hir : hirlam data\r\n                                        # ald : Output from aladin physics\r\n                                        # ala : Output from alaro physics\r\n                                        # aro : Output from arome physics\r\n\r\nHOST_SURFEX=\"no\"                        # yes if the host model is run with SURFEX\r\nSURFEX_INPUT_FORMAT=lfi                 # Input format for host model run with surfex (lfi|fa)\r\n\r\nNBDMAX=12                               # Number of parallel interpolation tasks\r\nBDLIB=ECMWF                             # Boundary experiment, set:\r\n                                        # ECMWF to use MARS data\r\n                                        # RCRa  to use RCRa data from ECFS\r\n                                        # Other HARMONIE/HIRLAM experiment\r\n\r\nBDDIR=$HM_DATA/${BDLIB}/archive/@YYYY@/@MM@/@DD@/@HH@   # Boundary file directory,\r\n                                                        # For more information, read in scr/Boundary_strategy.pl\r\nINT_BDFILE=$WRK/ELSCF${CNMEXP}ALBC@NNN@                 # Interpolated boundary file name and location\r\n\r\nBDSTRATEGY=simulate_operational # Which boundary strategy to follow\r\n                                # as defined in scr/Boundary_strategy.pl\r\n                                #\r\n                                # available            : Search for available files in BDDIR, try to keep forecast consistency\r\n                                #                        This is ment to be used operationally\r\n                                # simulate_operational : Mimic the behaviour of the operational runs using ECMWF LBC,\r\n                                #                        i.e. 6 hour old boundaries\r\n                                # same_forecast        : Use all boundaries from the same forecast, start from analysis\r\n                                # analysis_only        : Use only analysises as boundaries\r\n                                # era                  : As for analysis_only but using ERA interim data\r\n                                # latest               : Use the latest possible boundary with the shortest forecast length\r\n                                # RCR_operational      : Mimic the behaviour of the RCR runs, ie\r\n                                #                        12h old boundaries at 00 and 12 and\r\n                                #                        06h old boundaries at 06 and 18\r\n                                # enda                 : use ECMWF ENDA data for running ensemble data assimilation\r\n                                #                        or generation of background statistic.\r\n                                #                        Note that only LL up to 9h is supported\r\n                                #                        with this you should set your ENSMSEL members\r\n                                # eps_ec               : ECMWF EPS members (on reduced gaussian grid)\r\n                                #                      : Only meaningful with ENSMSEL non-empty, i.e., ENSSIZE > 0\r\n\r\nBDINT=1                         # Boundary interval in hours\r\n\r\nSURFEX_PREP=\"yes\"                # Use offline surfex prep facility (Alt. gl + Fullpos + prep )","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"HOST_MODEL defines the host model that provides the lateral boundaries conditions for your experiment\nhir for HIRLAM.\nald for ALADIN \nala for ALARO\naro for AROME\nifs for ECMWF-IFS. \nHOST_SURFEX Set to yes if host model runs with SURFEX. (no|yes)\nSURFEXINPUTFORMAT Input format for host model run with surfex (lfi|fa)","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"BDLIB is the experiment to be used as boundaries. Possible values, ECMWF for IFS from MARS (default), RCRa for HIRLAM-RCR from ECFS or other HARMONIE experiment. \nBDDIR is the boundary file directory. The possible date information in the path must be given by using UPPER CASE letters (@YYYY@=year,@MM@=month,@DD@=day,@HH@=hour,@FFF@=forecast length).  \nBDSTRATEGY Which boundary strategy to follow i.e. How to find the right boundaries with the right age and location. Read more\nBDINT is boundary interval in hours.\nBDCLIM is the path to climate files corresponding the boundary files, when nesting HARMONIE to HARMONIE.\nINT_BDFILE is the name and location of the interpolated boundary files. These files are removed every cycle, but if you wish to save them you can specify a more permanent location here. By setting INT_BDFILE=ARCHIVE the interpolated files will be stored in your archive directory.\nNBDMAX Number of parallel boundary interpolation tasks in mSMS. The current default value is 12.\nSURFEX_PREP Use SURFEX tool PREP instead of gl+FULLPOS to prepare SURFEX initial conditions. This is now the default. The gl+FULLPOS version is still working but will not be maintained in the future (no|yes)","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Read more about the boundary file preparation here.","category":"page"},{"location":"ConfigureYourExperiment/#Ensemble-mode-settings-1","page":"Experiment","title":"Ensemble mode settings","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# *** Ensemble mode general settings. ***\r\n# *** For member specific settings use msms/harmonie.pm ***\r\nENSMSEL=                                # Ensemble member selection, comma separated list, and/or range(s):\r\n                                        # m1,m2,m3-m4,m5-m6:step    mb-me == mb-me:1 == mb,mb+1,mb+2,...,me\r\n                                        # 0=control. ENSMFIRST, ENSMLAST, ENSSIZE derived automatically from ENSMSEL.\r\nENSINIPERT=                             # Ensemble perturbation method (bnd). Not yet implemented: etkf, hmsv.\r\nENSCTL=                                 # Which member is my control member? Needed for ENSINIPERT=bnd. See harmonie.pm.\r\nENSBDMBR=                               # Which host member is used for my boundaries? Use harmonie.pm to set.\r\nENSMFAIL=0                              # Failure tolerance for all members.\r\nENSMDAFAIL=0                            # Failure tolerance for members doing own DA. Not implemented.\r\nSLAFK=1.0                               # best set in harmonie.pm\r\nSLAFLAG=0                               # --- \" ---\r\nSLAFDIFF=0                              # --- \" ---\r\n\r\n# *** This part is for EDA with observations perturbation\r\nPERTATMO=none                           # ECMAIN  : In-line observation perturbation using the default IFS way.\r\n                            \t\t\t# CCMA    : Perturbation of the active observations only (CCMA content)\r\n\t                            \t\t#           before the Minimization, using the PERTCMA executable.\r\n                            \t\t\t# none    : no perturbation of upper-air observations\r\n\r\nPERTSURF=none                           # ECMA    : perturb also the surface observation before Canari (recommended\r\n                            \t\t\t#         : for EDA to have full perturbation of the initial state).\r\n                                        # model   : perturb surface fields in grid-point space (recursive filter)\r\n\t\t\t                            # none    : no perturbation for surface observations.\r\n\r\nFESTAT=no                               # Extract differences and do Jb calculations (no|yes)\r\n","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"ENSMSEL  Ensemble member selection, comma separated list, and/or range(s):\nm1,m2,m3-m4,m5-m6:step    mb-me == mb-me:1 == mb,mb+1,mb+2,...,me\n0=control. ENSMFIRST, ENSMLAST, ENSSIZE derived automatically from ENSMSEL.\nENSINIPERT Ensemble perturbation method (bnd). Not yet implemented: etkf, hmsv, slaf.\nENSMFAIL Failure tolerance for all members. Not yet implemented.\nENSMDAFAIL Failure tolerance for members doing own DA. Not yet implemented.\nENSCTL Which member is my control member? Needed for ENSINIPERT=bnd. See harmonie.pm.\nENSBDMBR Which host member is used for my boundaries? Use harmonie.pm to set.\nSLAFK Perturbation coefficients for SLAF, experimental\nSLAFLAG Time lag for boundaries in SLAG, experimental","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"For member dependent settings see msms/harmonie.pm.","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"PERTATMO Observation perturbation with three options \nECMA: In-line observation perturbation using the default IFS way.\nCCMA    : Perturbation of the active observations only (CCMA content) before the Minimization, using the PERTCMA executable.\nnone    : no perturbation of upper-air observations","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"PERTSURF Perturbation of surface observations before Canari (recommended for EDA to have full perturbation of the initial state) (no|yes).","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"FESTAT Extract differences and do Jb calculations (no|yes). Read more about the procedure here.","category":"page"},{"location":"ConfigureYourExperiment/#Climate-file-settings-1","page":"Experiment","title":"Climate file settings","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Climate file generation settings. Further information is available here: HarmonieSystemDocumentation/ClimateGeneration","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Climate files ****\r\nCREATE_CLIMATE=${CREATE_CLIMATE-yes}    # Run climate generation (yes|no)\r\nCLIMDIR=$HM_DATA/climate                # Climate files directory\r\nBDCLIM=$HM_DATA/${BDLIB}/climate        # Boundary climate files (ald2ald,ald2aro)\r\n                                        # This should point to intermediate aladin \r\n                                        # climate file in case of hir2aro,ifs2aro processes.\r\n\r\n# Physiography input for SURFEX\r\nECOCLIMAP_VERSION=2.2                   # Version of ECOCLIMAP for surfex (1,2)\r\n                                        # Available versions are 1.1-1.5,2.0-2.2\r\nSOIL_TEXTURE_VERSION=FAO                # Soil texture input data FAO|HWSD_v2","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"CREATE_CLIMATE: Run climate generation (yes|no). If you already have a full set of climate files generated in CLIMDIR you can set this flag to no for a faster run.\nCLIMDIR: path to the generated climate files for your specific domain. The input data for the climate generation is defined by HMCLDATA defined in Envsystem -> config-sh/config.YOURHOST\nBDCLIM: path to intermediate climate files\nECOCLIMAP_VERSION is the version of ECOCLIMAP to be used with SURFEX. Available versions are 1.1-1.5,2.0,2.1,2.2. See surfex_namelists.pm for more info.\nSOILTEXTUREVERSION Soil texture input data (FAO|HWSDv2). [See surfexnamelists.pm for more info.](../HarmonieSystemDocumentation/Namelists.md#surfex_namelists.pm)","category":"page"},{"location":"ConfigureYourExperiment/#Archiving-settings-1","page":"Experiment","title":"Archiving settings","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Archiving settings ****\r\nARCHIVE_ECMWF=yes                       # Archive to $ECFSLOC at ECMWF (yes|no)\r\n# Archiving selection syntax, settings done below\r\n#\r\n# [fc|an|pp]_[fa|gr|nc] : Output from\r\n#  an : All steps from upper air and surface analysis\r\n#  fc : Forecast model state files from upper air and surfex\r\n#  pp : Output from FULLPOS and SURFEX_LSELECT=yes (ICMSHSELE+NNNN.sfx)\r\n# in any of the formats if applicable\r\n#  fa : FA files\r\n#  gr : GRIB[1|2] files\r\n#  nc : NetCDF files\r\n# sqlite|odb|VARBC|bdstrategy : odb and sqlite files stored in odb_stuff.tar\r\n# fldver|ddh|vobs|vfld : fldver/ddh/vobs/vfld files\r\n# climate : Climate files from PGD and E923\r\n# Some macros\r\n# odb_stuff=odb:VARBC:bdstrategy:sqlite\r\n# verif=vobs:vfld\r\n# fg : Required files to run the next cycle","category":"page"},{"location":"ConfigureYourExperiment/#Forecast-output-1","page":"Experiment","title":"Forecast output","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Cycles to run, and their forecast length ****\r\n\r\nTFLAG=\"h\"                               # Time flag for model output. (h|min)\r\n                                        # h   = hour based output\r\n                                        # min = minute based output\r\n\r\n\r\n# The unit of HWRITUPTIMES, FULLFATIMES, ..., SFXFWFTIMES should be:\r\n#   - hours   if TFLAG=\"h\"\r\n#   - minutes if TFLAG=\"min\"\r\n\r\n# Writeup times of # history,surfex and fullpos files\r\n# Comma separated list, and/or range(s) like:\r\n# t1,t2,t3-t4,t5-t6:step    tb-te == tb-te:1 == tb,tb+1,tb+2,...,te\r\n\r\nif [ -z \"$ENSMSEL\"] ; then\r\n  # Standard deterministic run\r\n  HH_LIST=\"00-21:3\"                       # Which cycles to run, replaces FCINT\r\n  LL_LIST=\"12,3\"                          # Forecast lengths for the cycles [h], replaces LL, LLMAIN\r\n                                          # The LL_LIST list is wrapped around if necessary, to fit HH_LIST\r\n  HWRITUPTIMES=\"00-21:3,24-60:6\"          # History file output times\r\n  FULLFAFTIMES=$HWRITUPTIMES              # History FA file IO server gather times\r\n  PWRITUPTIMES=\"00-60:3\"                  # Postprocessing times\r\n  PFFULLWFTIMES=-1                        # Postprocessing FA file IO server gathering times\r\n  VERITIMES=\"00-60:1\"                     # Verification output times, may change PWRITUPTIMES\r\n  SFXSELTIMES=$HWRITUPTIMES               # Surfex select file output times\r\n                                          # Only meaningful if SURFEX_LSELECT=yes\r\n  SFXSWFTIMES=-1                          # SURFEX select FA file IO server gathering times\r\n  SWRITUPTIMES=\"00-06:3\"                  # Surfex model state output times\r\n  SFXWFTIMES=$SWRITUPTIMES                # SURFEX history FA file IO server gathering times\r\n  if [ \"$SIMULATION_TYPE\" == climate]; then  #Specific settings for climate simulations\r\n    HWRITUPTIMES=\"00-760:6\"                 # History file output times\r\n    FULLFAFTIMES=\"00-760:24\"                # History FA file IO server gather times\r\n    PWRITUPTIMES=$HWRITUPTIMES              # Postprocessing times\r\n    VERITIMES=$HWRITUPTIMES                 # Verification output times, may change PWRITUPTIMES\r\n    SFXSELTIMES=$HWRITUPTIMES               # Surfex select file output times - Only meaningful if SURFEX_LSELECT=yes\r\n    SWRITUPTIMES=\"00-760:12\"                # Surfex model state output times\r\n    SFXWFTIMES=$SWRITUPTIMES                # SURFEX history FA file IO server gathering times\r\n  fi\r\n\r\n  ARSTRATEGY=\"climate:fg:verif:odb_stuff: \\\r\n              [an|fc]_fa:pp_grb\"          # Files to archive on ECFS, see above for syntax\r\n\r\nelse\r\n  # EPS settings\r\n  HH_LIST=\"00-21:3\"                       # Which cycles to run, replaces FCINT\r\n  LL_LIST=\"36,3,3,3\"                      # Forecast lengths for the cycles [h], replaces LL, LLMAIN\r\n  HWRITUPTIMES=\"00-06:3\"                  # History file output times\r\n  FULLFAFTIMES=$HWRITUPTIMES              # History FA file IO server gather times\r\n  PWRITUPTIMES=\"00-48:1\"                  # Postprocessing times\r\n  PFFULLWFTIMES=-1                        # Postprocessing FA file IO server gathering times\r\n  VERITIMES=\"00-60:3\"                     # Verification output times, may change PWRITUPTIMES\r\n  SFXSELTIMES=$HWRITUPTIMES               # Surfex select file output times\r\n                                          # Only meaningful if SURFEX_LSELECT=yes\r\n  SFXSWFTIMES=-1                          # SURFEX select FA file IO server gathering times\r\n  SWRITUPTIMES=\"00-06:3\"                  # Surfex model state output times\r\n  SFXWFTIMES=$SWRITUPTIMES                # SURFEX history FA file IO server gathering times\r\n\r\n  ARSTRATEGY=\"climate:fg:verif:odb_stuff: \\\r\n              an_fa:pp_grb\"               # Files to archive on ECFS, see above for syntax\r\n\r\nfi\r\n","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"The writeup times of model output can be defined as a space separated list or as a fixed frequency for model history files, surfex files and postprocessed files respectively. The unit of the steps of WRITUPTIMES, SWRITUPTIMES, PWRITUPTIMES and OUTINT should be in hours or minutes depending on the TFLAG Regular output interval can be switched on by setting OUTINT>0. Consequently, OUTINT will override the WRITUPTIMES lists!","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"TFLAG: Time flag for model output. Hourly or minute-based output (h|min)\nHWRITUPTIMES:  Output list for history files. Default is \"00-21:3,24-60:6\" which will output files every 3 hours for 00-21 and every 6 hours for 24-60.\nVERITIMES:  Output list for verification files. Default is \"00-60:1\" which will produce file every 1 hour for 00-60\nSWRITUPTIMES  Output list for surfex files. Default is \"00-06:3\" which output a  SURFEX file every 3 hours for 00-06.\nPWRITUPTIMES  Output list for fullpos (post-processed) files. Default is \"00-21:3,24-60:6\" which will output files every 3 hours for 00-21 and every 6 hours for 24-60.","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"SURFEX_LSELECT=\"yes\"                    # Only write selected fields in surfex outpute files. (yes|no)\r\n                                        # Check nam/surfex_selected_output.pm for details.\r\n                                        # Not tested with lfi files.\r\nINT_SINI_FILE=$WRK/SURFXINI.fa          # Surfex initial file name and location\r\n\r\n# **** Postprocessing/output ****\r\nIO_SERVER=yes                           # Use IO server (yes|no). Set the number of cores to be used\r\n                                        # in your Env_submit\r\nIO_SERVER_BD=yes                        # Use IO server for reading of boundary data\r\nPOSTP=\"inline\"                          # Postprocessing by Fullpos (inline|offline|none).\r\n                                        # See Setup_postp.pl for selection of fields.\r\n                                        # inline: this is run inside of the forecast\r\n                                        # offline: this is run in parallel to the forecast in a separate task\r\n\r\nFREQ_RESET_TEMP=3                       # Reset frequency of max/min temperature values in hours, controls NRAZTS\r\nFREQ_RESET_GUST=1                       # Reset frequency of max/min gust values in hours, controls NXGSTPERIOD\r\n                                        # Set to -1 to get the same frequency _AND_ reset behaviour as for min/max temperature\r\n                                        # See yomxfu.F90 for further information.\r\n","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"SURFEX_LSELECT: Switch to write a selection of fields in SURFEX output files (yes|no). See surfexselectedoutput.pm for more info.","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"INTSINIFILE: name and location of the initial SURFEX file\nARCHIVE_ECMWF: archive files to ECFSLOC at ECMWF (yes|no)\nIO_SERVER: Use IO server (yes|no). If set to \"yes\" changes may be required in Env_submit -> config-sh/submit.YOURHOUST\nPOSTP: Postprocessing by Fullpos (inline|offline|none).\nFREQRESET[TEMP|GUST]: Reset frequency of max/min values in hours, controls NRAZTS. Default is every 3/1 hours","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** GRIB ****\r\nCONVERTFA=yes                           # Conversion of FA file to GRIB/nc (yes|no)\r\nARCHIVE_FORMAT=GRIB1                    # Format of archive files (GRIB1|GRIB2|nc). nc format yet only available in climate mode\r\nNCNAMES=nwp                             # Nameing of NetCDF files follows (climate|nwp) convention.\r\nRCR_POSTP=no                            # Produce a subset of fields from the history file for RCR monitoring\r\n                                        # Only applicable if ARCHIVE_FORMAT=GRIB\r\nMAKEGRIB_LISTENERS=1                    # Number of parallel listeners for Makegrib\r\n                                        # Only applicable if ARCHIVE_FORMAT=GRIB\r\n","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"More options on fullpos postprocessing can be found in [browser:trunk/harmonie/scr/Selectposp.pl Selectpostp.pl]","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"CONVERTFA: Conversion of FA files to GRIB or NetCDF (yes|no)\nARCHIVE_FORMAT: Format of archive files (GRIB1|nc). NetCDF format yet only available in climate mode\nRCR_POSTP Produce a subset of fields from the history file for RCR monitoring (yes|no). This is only applicable if ARCHIVE_FORMAT=GRIB1|GRIB2\nMAKEGRIB_LISTENERS: Number of parallel listeners for Makegrib. Only applicable if ARCHIVE_FORMAT=GRIB1|GRIB2","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"More options on file conversion can be found in [browser:trunk/harmonie/scr/Makegrib scr/Makegrib]","category":"page"},{"location":"ConfigureYourExperiment/#Verification-and-monitoring-1","page":"Experiment","title":"Verification and monitoring","text":"","category":"section"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# **** Verification extraction ****\r\nOBSEXTR=yes                             # Extract observations from BUFR (yes|no)\r\nFLDEXTR=yes                             # Extract model data for verification from model files (yes|no)\r\nFLDEXTR_TASKS=1                         # Number of parallel tasks for field extraction\r\nVFLDEXP=$EXP                            # Experiment name on vfld files","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"OBSEXTR: Extract observations for verification from BUFR (yes|no)\nFLDEXTR Extract model data for verification from model files (yes|no)\nFLDEXTR_TASKS: Number of parallel tasks for field extraction\nVFLDEXP:","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Read more about the verification package here","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"=== Field verification ===","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# *** Field verification ***\r\nFLDVER=no                               # Main switch for field verification (yes|no)\r\nFLDVER_HOURS=\"06 12 18 24 30 36 42 48\"  # Hours for field verification\r\n","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"FLDVER Main switch for field verification (yes|no). The field verification extracts some selected variables for calculation of bias, rmse, stdv and averages on the model grid.\nFLDVER_HOURS Hours for field verification","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"More options on field verification can be found in [browser:trunk/harmonie/scr/Fldver Fldver] and [browser:trunk/harmonie/scr/AccuFldver AccuFldver]","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"=== Observation monitoring and general diagnostics ===","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"# *** Observation monitoring ***\r\nOBSMONITOR=obstat                       # Create Observation statistics plots\r\n                                        # Format: OBSMONITOR=Option1:Option2:...:OptionN\r\n                                        # obstat: Daily usage maps and departures\r\n                                        # no: Nothing at all\r\n                                        #\r\n                                        # obstat is # only active if ANAATMO != none\r\nOBSMON_SYNC=no                          # Sync obsmn sqlite tables to ecgate (yes|no)","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"OBSMONITOR Selection for observation statistics plots     * obstat Observations usage. Read more here.     * no No monitoring","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Note that this is only active if ANAATMO != none","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"=== Field monitoring ( experimental ) ===","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"Make various charts for daily monitoring","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"#  *** Monitoring maps for hirlam.org. ***\r\n#      Note that at ECMWF this is run on ecgb (grads is only there)\r\n#      In  this version You must check out manually contrib/mapbin to the \r\n#      directory referred as MAPBIN \r\nFIELDMONITOR=no\r\nMAPBIN=$HM_DATA/lib/util/mapbin\r\n","category":"page"},{"location":"ConfigureYourExperiment/#","page":"Experiment","title":"Experiment","text":"FIELDMONITOR Main switch (no|yes)\nMAPBIN Path to plotting settings. Read more in [source:Harmonie/scr/Monitoring_maps]","category":"page"},{"location":"ConfigureYourExperiment/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Experiment","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"DigitialFilterInitialization/#","page":"DFI","title":"DFI","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/DigitialFilterInitialization?action=edit\"","category":"page"},{"location":"DigitialFilterInitialization/#Harmonie-system-Documentation-1","page":"DFI","title":"Harmonie system Documentation","text":"","category":"section"},{"location":"DigitialFilterInitialization/#Digital-Filter-Initialization-1","page":"DFI","title":"Digital Filter Initialization","text":"","category":"section"},{"location":"DigitialFilterInitialization/#","page":"DFI","title":"DFI","text":"== Introduction Digital Filter Initialization (DFI) is documented by Météo France here: http://www.cnrm.meteo.fr/gmapdoc//spip.php?article158&lang=en. This wiki page is based on the \"Version cycle 40t1\" document available on the gmapdoc web page. By default HARMONIE does not use DFI. ","category":"page"},{"location":"DigitialFilterInitialization/#DFI-1","page":"DFI","title":"DFI","text":"","category":"section"},{"location":"DigitialFilterInitialization/#","page":"DFI","title":"DFI","text":"The use (or not) of DFI is controlled by the variable DFI in ecf/config_exp.h. By default it is set to \"none\". ","category":"page"},{"location":"DigitialFilterInitialization/#","page":"DFI","title":"DFI","text":"\"idfi\", incremental DFI\n\"fdfi\", full DFI \n\"none\" - no initialization (default)","category":"page"},{"location":"DigitialFilterInitialization/#","page":"DFI","title":"DFI","text":"scr/Dfi is the script which calls the model in order to carry out DFI.","category":"page"},{"location":"DigitialFilterInitialization/#References-1","page":"DFI","title":"References","text":"","category":"section"},{"location":"DigitialFilterInitialization/#","page":"DFI","title":"DFI","text":"YESSAD K. (METEO-FRANCE/CNRM/GMAP/ALGO) July 7, 2015: DIGITAL FILTERING INITIALISATION IN THE CYCLE 42 OF ARPEGE/IFS\nYESSAD K. (METEO-FRANCE/CNRM/GMAP/ALGO) March 17, 2015: DIGITAL FILTERING INITIALISATION IN THE CYCLE 41T1 OF ARPEGE/IFS\nYESSAD K. (METEO-FRANCE/CNRM/GMAP/ALGO) August 6, 2014: DIGITAL FILTERING INITIALISATION IN THE CYCLE 41 OF ARPEGE/IFS\nYESSAD K. (METEO-FRANCE/CNRM/GMAP/ALGO) March 12, 2014: DIGITAL FILTERING INITIALISATION IN THE CYCLE 40T1 OF ARPEGE/IFS\nYESSAD K. (METEO-FRANCE/CNRM/GMAP/ALGO) July 3, 2013: DIGITAL FILTERING INITIALISATION IN THE CYCLE 40 OF ARPEGE/IFS","category":"page"},{"location":"DigitialFilterInitialization/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"DFI","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/scripts/mSMS?action=edit\"","category":"page"},{"location":"scripts/mSMS/#mini-SMS-and-mini-XCdp-1","page":"mSMS","title":"mini-SMS and mini-XCdp","text":"","category":"section"},{"location":"scripts/mSMS/#Overview-1","page":"mSMS","title":"Overview","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"What is mini-SMS?\nWhat is mini-XCdp?\nHow does mini-SMS fit into the Harmonie script system?\nBasic mini-SMS:\nDefinition file(s)\nTasks and containers, execution\nControl structures (if, repeat, loop, trigger, complete)\nInteraction with mini-SMS through mini-XCdp (demo)","category":"page"},{"location":"scripts/mSMS/#What-is-mini-SMS?-1","page":"mSMS","title":"What is mini-SMS?","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"Mini-SMS is a simple [[Color(blue, job scheduler)]], the source code is contained in the perl script mSMS.pl. It was written around year 2000 by Gerard Cats, former Hirlam system manager, in order to make the Hirlam runs at ECMWF (and locally) run more efficiently. It was inspired by, and is a subset of SMS, the Supervisor and Monitoring System, developed at ECMWF. The main advantage of mini-SMS compared to full SMS is that it is easy to port to a new system, e.g., your laptop. Having a home-made system also makes it easier for the system managers to implement new features when this is required.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"Mini-SMS basically works as follows: the user provides a description of the suite of programs that (s)he wants to run, possibly distributed over several computers. This description is in the [[Color(blue, (template) suite definition file)]]. In that file, the user should also specify in what order the modules must be executed, by using certain [[Color(blue, control structures)]].","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"In Harmonie, things related to mini-SMS are located in subdirectory msms. The main template definition file is harmonie.tdf, but there are also others.","category":"page"},{"location":"scripts/mSMS/#What-is-mini-XCdp?-1","page":"mSMS","title":"What is mini-XCdp?","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"Mini-XCdp is a graphical user interface (GUI) to the mini-SMS scheduler. The source code is contained in the perl script mXCdp.pl. It communicates with mini-SMS by sending HTTP requests. For this to work, a small extension WebServer.pl is included by mSMS.pl on demand. More information on the client/server interaction can be found here, and also in this blog post.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"The name mini-XCdp is perhaps a bit unfortunate, it is not as closely mimicking ECMWF's XCdp (X Control and display program) as mini-SMS follows full SMS. But it gives the user some possibilities to interact with the scheduler, e.g.:","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"If a task aborts, it can be restarted from the GUI, without rerunning the whole suite.\nLog files (and job container scripts) can be viewed.\nJob status can be overridden, e.g. forced to \"complete\".\nTasks or families can be suspended (and resumed).\n(Active) jobs can be killed (if implemented for the local system)","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"The GUI can be started also if the scheduler is currently not running. In that case it is possible to see in what state the scheduler was when it terminated. It should generally also be possible to restart the scheduler from exactly where it left off and continue the run, possibly with some manual intervention. ","category":"page"},{"location":"scripts/mSMS/#How-does-mini-SMS-fit-into-the-Harmonie-script-system?-1","page":"mSMS","title":"How does mini-SMS fit into the Harmonie script system?","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"The master script Harmonie is the user's main interface to the system. Harmonie is a perl script, which will again usually invoke the old interface (sh) script Main. Harmonie recognizes a set of \"actions\" (as implemented in the scripts Actions and Actions.pl). The most important actions will invoke the script Start. Finally, Start will invoke the mini-SMS script mSMS.pl with the correct arguments, and with the proper environment variables set. The user should normally never invoke the scripts mSMS.pl or mXCdp.pl herself.","category":"page"},{"location":"scripts/mSMS/#Script-call-sequence:-1","page":"mSMS","title":"= Script call sequence:=","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"[Color(blue, Harmonie)]\n[Color(blue, Main)]\n* [[Color(blue, Start)]] (reads [config_exp.h](https://hirlam.org/trac/browser/trunk/harmonie/sms/config_exp.h))\n[Color(blue, mSMS.pl)]\nprepare [Color(green, harmonie.def)]\nplay      * [Color(blue, mXCdp.pl)]","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"Note that mini-SMS goes through two steps, the preparation step and the execution (play) step. In the first step, the template definition file is converted into a plain definition file. This preparation step is something unique to mini-SMS, it is not a part of full SMS. In full SMS, the definition file is \"played\" directly. However, full SMS accepts several things in the .def file that mini-SMS does not, e.g., if- and loop-statements. These are only understood in the preparation step of mini-SMS, making these constructs less dynamic than in full SMS. It is e.g. not possible to test on variables that change during the run. ","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"Note also that Harmonie start DTG=... will usually automatically invoke also mXCdp.pl in addition to mSMS.pl. But if the user decides to close the GUI, a new GUI can be opened later by the command","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":" Harmonie mon","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"It is possible to have more than one GUI open for the same experiment, e.g., one at work and another one at home.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"At ecgb, mSMS is now submitted as a batch job in a special queue minisms, with no guarantee of immediate execution (although this is what usually happens). Thus, since mXCdp still starts immediately, it can sometimes report that there is no running scheduler (since mSMS has not started execution yet). This behaviour is likely to confuse users, if they don't realize that mSMS and mXCdp are two separate processes.","category":"page"},{"location":"scripts/mSMS/#(mini-)SMS-basics-1","page":"mSMS","title":"(mini-)SMS basics","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"The definition file(s) (e.g., harmonie.tdf) describes the system to be run in terms of [[Color(blue, suites, families, tasks)]] and [[Color(blue, control structures)]].\nA family is just a group of tasks and/or other families. A suite is a top-level family.\nAll tasks need a [[Color(green, \"task\".sms)]] [Color(blue, container)]. In Harmonie, many containers are simply symbolic links to default.sms, which invokes a script named [[Color(green, \"task\")]].\nAll containers should include the files sms.h and hosts.h at the top, and end.h at the bottom.\nBy default all tasks start as soon as possible. We must include [[Color(blue, triggers)]] to specify dependencies between tasks, e.g. that one task must wait for another task to complete before it can start execution.","category":"page"},{"location":"scripts/mSMS/#(mini-)SMS-variables-1","page":"mSMS","title":"= (mini-)SMS variables=","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"In the definition file, variables may be defined and set by [[Color(green, edit)]] statements, e.g.:","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":" edit SMSTRIES 1\r\n edit SMSCMD \"perl -S Submit.pl -o %SMSJOBOUT% %SMSJOB% >> mSMS.log 2>&1\"","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"Variables are referred to by [[Color(blue, %VAR%)]]. Variables that start with SMS might have a special meaning to mSMS. Avoid such names if you need to create your own variable.","category":"page"},{"location":"scripts/mSMS/#mini-SMS-task-execution-1","page":"mSMS","title":"= mini-SMS task execution=","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"When mini-SMS decides it is time to execute a particular task (i.e., it is triggered) it first converts the [[Color(green, \"task\".sms)]] container script into a (sh) script [[Color(green, \"task\".job%SMSTRYNO%)]], where [[Color(blue, %SMSTRYNO%)]] is the attempt number of the task. %SMSTRYNO% runs from 1 to [Color(blue, %SMSTRIES%)] for automatically submitted tasks, but %SMSTRIES% is ignored for tasks that are rerun through the GUI.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"Since jobs might have different requirements for memory, number of CPUs, host to run on, whether to run as a background job or be submitted to a batch queuing system etc., in Harmonie all jobs go through a second step, the so-called \"Universal Job Submission Filter\" (script Submit.pl). This filter reads the [[Color(green, \"task\".job%SMSTRYNO%)]] file and the [[Color(green, Env_submit)]] file for this (sms)host, and then creates the final (sh) job file [[Color(green, \"task\".job%SMSTRYNO%-q)]]. In this file, headers (for the queueing system) and footers might have been added.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"All tasks emit [[Color(blue, signals)]] at certain stages of their execution, namely when [[Color(green, active)]] and [[Color(orange, complete)]] or [[Color(red, aborted)]].","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"The various colors that the boxes get in the GUI correspond to the current state of the actual family or task. The codes are as follows:","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"| [[Color2(blue, white, queued)]] | [[Color2(cyan, black, submitted)]] | [[Color2(green, black, active)]] | [[Color2(yellow, black, complete)]] | [[Color2(red, white, aborted)]] | [[Color2(orange, black, suspended)]] | [[Color2(brown, white, unknown)]] | [[Color2(magenta, black, halted)]] | [[Color2(black, white, shutdown)]] | | –- | –- | –- | –- | –- | –- | –- | –- | –- |","category":"page"},{"location":"scripts/mSMS/#mini-SMS-client/server-communication-1","page":"mSMS","title":"= mini-SMS client/server communication=","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"Before changeset [13288] this signalling was always via files created in SMSFLAGDIR (often HM_DATA). The scheduler would remove these files as soon as the signals were registered. After [13288], it is also possible to configure the system so that signals are sent over http instead of using files. One possible drawback with http signals is that if the mSMS scheduler terminates while tasks are still submitted or active, signals can be lost. With files these signals would be picked up if the scheduler was restarted through the mXCdp interface, but this will not happen with http signals. Therefore, more user interaction might be necessary on systems with http signals. If you see errors like","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"msms_client error for request\r\n'http://ecgb06:27965/_ctrl/set?t=/letkf_harmonEPS_38h11_v6_e1/Date/Hour/Cycle/Mbr000/PostAnalysis/Makegrib_an&s=1':\r\n500 Can't connect to ecgb06:27965 (Connection refused)\r\n#################################################################\r\n# Failed to send signal 'complete' to mini-SMS!\r\n# If mini-SMS is dead and you restart it from mXCdp, you should\r\n# manually set this task to 'complete' to resume your run!\r\n#################################################################","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"the mSMS server has died before the task completed. To sort this out you have to restart your server ( using Harmonie mon ) and check all the tasks that are still running ( i.e. are green ). If the have completed you can just change startus to complete and accordingly for aborted tasks. ","category":"page"},{"location":"scripts/mSMS/#Template-definition-file-control-structures-1","page":"mSMS","title":"Template definition file control structures","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"Below is a brief list of the various control structures that a template definition file (.tdf) may contain. Those in blue are common with full SMS, and will also appear in the generated (.def) definition file. Those in green will be processed during the preparation step and might be transformed into something else in the definition file. ","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"The typical condition is:  ( some/family/task == complete )\nIf queued, the task will be submitted when the condition is fulfilled.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"mini-SMS sets the task or family complete without executing it if the condition is fulfilled.\nNote that complete statements are checked before triggers, therefore, if a task has both a trigger and a complete statement it may get the status complete before the trigger is fulfilled. This might be surprising if you have another task triggered on this particular task being complete.  NOTE added later: After changeset 10876, this has been changed; a task is not set complete before it is also triggered.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"This generates an iterative loop in the scheduler, the variable [[Color(blue, var)]] is cycled between its start and stop values.\nThe execution is sequential, i.e., one iteration must complete before the next is queued.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"This construct may only appear in a tdf file, the preprocessing step will \"duplicate\" the loop body the specified number of times in the definition file.\nIn the loop body, use of [[Color(green, @var@)]] will be replaced by the actual loop iterate.\nNote that the execution is normally parallel, unless the loop body contains triggers to make each \"iterate\" wait for the previous one.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"These constructs may also only appear in tdf files, the preprocessing step will include or ignore lines depending on the outcome of the tests. The first two variants are there for historic reasons. The third form (general if) can easily replace the two varieties above.\nNote that full SMS also has if-tests, but these are evaluated at playtime (which is more general).","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"For many examples of the use of these constructs, take a look at harmonie.tdf. Since changeset [10930], this tdf also covers ensemble mode, there is no separate harmeps.tdf anymore.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"The indentation style used in these tdf files may look confusing, but there is a separation of prepare-time constructs (ifs and loops), which are indented independently of the other standard definition file constructs.","category":"page"},{"location":"scripts/mSMS/#More-documentation-1","page":"mSMS","title":"More documentation","text":"","category":"section"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"On mini-SMS. Old and slightly outdated, but extensive.\nOn mini-XCdp. A bit more detailed than in this page. An even older document (from before the split into two separate programs) can be found here.","category":"page"},{"location":"scripts/mSMS/#","page":"mSMS","title":"mSMS","text":"","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Evaluation/Mitraillette?action=edit\"","category":"page"},{"location":"Evaluation/Mitraillette/#Mitraillette-the-ALADIN-dynamical-core-testbed-1","page":"Mitraillette","title":"Mitraillette - the ALADIN dynamical core testbed","text":"","category":"section"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Mitraillette is a script designed to validate ALADIN configurations and is particularly useful to test a new cycle. This script uses a chain of jobs: when a job is finished it launches the following job, in a predetermined order. There are several documents describing the system on the  gmapdoc site","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"The latest version of mitraillette can be found on:","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"https://svn.hirlam.org/trunk/contrib/mitraille","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"or","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"beaufix:/home/gmap/mrpm/yessadk/SAVE/mitraille","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Due to current access limitations to tori, this version will not necessarily be up to date. It is, however, possible to check out the svn version from lxgmap workstations:","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"svn co https://svn.hirlam.org/trunk/contrib/mitraille","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Before your start using mitraillette please read the general instructions in here","category":"page"},{"location":"Evaluation/Mitraillette/#Configure-the-system-for-your-host.-1","page":"Mitraillette","title":"Configure the system for your host.","text":"","category":"section"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Under protojobs you find subdirectories for different hosts. Currently there are definitions for yuki and c1a. In each host directory there are four files.","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"config           # Configuration of main directories and local environment variables\r\njobtrailer       # End of job specification\r\nmemtable         # Definition of memory requirements for different configurations\r\nmonoheader       # Header for a 1 PE job on the local batch system\r\nmultiheader      # Header for a N PE job on the local batch system\r\ntimetable        # Definition of wall time requirements for different configurations","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"The main change is that the headers and trailers in the job*-files are separated. And that mitraillette.x has been updated to build the chain-files using these files. The config file is source in the beginning of the main script mitraillette.x.","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"The tori config file looks like","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"\r\n#\r\n# Mitraillette configuration file for tori\r\n#\r\n\r\n# Where to find prototype jobs and namelists\r\nREFDIR=/cnrm/gp/mrpm/mrpm624/mitraille\r\n\r\n# where the prototype job_* files are\r\nREF_JOBSDIR=$REFDIR/protojobs\r\n# where the namelists are\r\nREF_NAMDIR=$REFDIR/namelist\r\n\r\n\r\n# Where to store the output files\r\nWORKDIR=/work/$USER\r\n\r\n# Where to put your modified job* files, i.e. the chain-files\r\n# MITRA_HOME is defined in mitraiellette.x as your pwd\r\nJOB_LOC=$MITRA_HOME\r\nTMP_LOC=$TMP_LOC\r\n\r\n# Location of input data\r\nFILE_PATH=/cnrm/gp/mrpm/mrpm603/anal_a_mitraille\r\n\r\n# Definition of cp/ecp for files and namelists\r\nCP=\"/bin/cp -b 32768\"\r\nECP=\"/bin/cp -b 32768\"\r\n\r\n# Batch and MPI launch definitions\r\nSUBMIT=/usr/bin/nqsII/qsub\r\nMPILAUNCH=\"mpirun -nn 1 -nnp nb_proc\"\r\nLOPT_SCALAR=F\r\nMBX_SIZE=0\r\n\r\n# NEC specific envifonment variables\r\nexport F_UFMTENDIAN=31\r\nexport F_SYSLEN=1000\r\nexport F_FMTBUF=131072\r\nexport F_PROGINF=DETAIL\r\nexport F_FTRACE=FMT2\r\nexport F_RECLUNIT=BYTE\r\nexport MPIPROGINF=ALL_DETAIL\r\nexport MPISEPSELECT=0\r\nexport MPISUSPEND=ON\r\nexport MPIEXPORT=\"MPISUSPEND,F_FTRACE,F_FMTBUF,F_RECLUNIT,MPIPROGINF,PATH,DR_HOOK,DR_HOOK_IGNORE_SIGNALS\"\r\n","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Modify to fit your needs or add your own host with the current definitions as a template.","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"NPROMA","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"None of the NPROMA settings are changed in the namelists. The current values are suitable for tori (NEC vector) but probably not for other machines. There is a small script, mitraille/util/Parse_nproma.pl, that changes all different values to one in the namelists.","category":"page"},{"location":"Evaluation/Mitraillette/#c2a-instructions-based-on-cy40-1","page":"Mitraillette","title":"c2a instructions based on cy40","text":"","category":"section"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"The following instructions will instruct the user on how to build the code to be evaluated by mitraillette using the Harmonie build system and how to use mitraillette.","category":"page"},{"location":"Evaluation/Mitraillette/#Build-executables-1","page":"Mitraillette","title":"Build executables","text":"","category":"section"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"On ecgb get the phasing code","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"cd\r\nmkdir -p harmonie_release/branches/phasing\r\ncd harmonie_release/branches/phasing\r\nsvn co https://svn.hirlam.org/branches/phasing/cy40","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"On ecgb build cy40","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"cd\r\ncd hm_home\r\nmkdir cy40_main_makeup_c2a\r\ncd cy40_main_makeup_c2a\r\n~hlam/Harmonie setup -r $HOME/harmonie_release/branches/phasing/cy40\r\nvi Env_system # set PRECOMPILED= to empty in Env_system - this ensures you will compile a nice fresh clean build\r\n~hlam/Harmonie install","category":"page"},{"location":"Evaluation/Mitraillette/#Run-mitraillette-1","page":"Mitraillette","title":"Run mitraillette","text":"","category":"section"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"On ecgb get mitraillette code and copy to c2a:","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"cd\r\nmkdir mitraille_releases\r\ncd mitraille_releases\r\nsvn co https://svn.hirlam.org/trunk/contrib/mitraille\r\nrsync -tvaz --exclude=.svn mitraille /cca/perm/ms/ie/dui # please insert correct PATH to your PERM directory","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"The next few instructions are a bit messy - I am waiting for access to MF mitraille before I update trunk/contrib/mitraille properly. In the meantime ...Make a copy of the Harmonie executables in PERM on c2a:","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"mkdir -p $PERM/HarmBin/cy40ald/\r\ncp $TEMP/hm_home/cy40_main_makeup_c2a/bin/MASTERODB $PERM/HarmBin/cy40ald/\r\ncp $TEMP/hm_home/cy40_main_makeup_c2a/bin/PGD $PERM/HarmBin/cy40ald/","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Log in to c2a and configure and run your mitraillette evaluation as follows:","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"cd $PERM/mitraille\r\n./mitraillette_v012014.x AL40T1 PRO_FILE.al40t1_hirlam_mono mono\r\n./test.xNNNN","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"This PRO_FILE points to  /perm/ms/ie/dui/HarmBin/cy40ald/MASTERODB copied above. The mitraillette.x script will have created a test script called test.xNNNN where NNNN is an integer. Let's run the test script:","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"./test.xNNNN","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Now have a look at the output produced. Still on c2a:","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"cd $TEMP/mitraillette/al40t1/mitraillette_NNNN\r\nls -ltr\r\ncd $TEMP/OUTPUT_FILES/AL40T1\r\nls -ltr","category":"page"},{"location":"Evaluation/Mitraillette/#MORE-TO-FOLLOW-1","page":"Mitraillette","title":"MORE TO FOLLOW","text":"","category":"section"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Please note: I have yet to merge the cycle 40 mitraillette updates into trunk/contrib. I want to get these updates from MF myself I have to see if my tests have succeeded! ","category":"page"},{"location":"Evaluation/Mitraillette/#Quick-start-on-c1a-1","page":"Mitraillette","title":"Quick start on c1a","text":"","category":"section"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Check out the script and put i under HOME/mitraille on c1a. \nModify PRO_FILE.al37.c1a to point to your binary\nCreate directory al37\nCreate a multi job chain by","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"./mitraillette.x AL37 PRO_FILE.al37.c1a multi ","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Run the created test.xNNNN script\nResults can be found under TEMP","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Utilities","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"A set of exmple scripts used to compare different runs are gathered under util. Read more in the util/README. Please fill with your own tools!","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"","category":"page"},{"location":"Evaluation/Mitraillette/#","page":"Mitraillette","title":"Mitraillette","text":"Last modified [[LastModified]]","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PostPP/Diagnostics?action=edit\"","category":"page"},{"location":"PostPP/Diagnostics/#Diagnostics-1","page":"Diagnostics","title":"Diagnostics","text":"","category":"section"},{"location":"PostPP/Diagnostics/#Xtool-1","page":"Diagnostics","title":"Xtool","text":"","category":"section"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"xtool","category":"page"},{"location":"PostPP/Diagnostics/#SAL-1","page":"Diagnostics","title":"SAL","text":"","category":"section"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"SAL","category":"page"},{"location":"PostPP/Diagnostics/#DDH-1","page":"Diagnostics","title":"DDH","text":"","category":"section"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"Diagnostics par Domaines Horizontaux (Diagnostics by Horizontal Domains) is a tool to create budgets of different processes in the model. Please read on in the gmap documentation: http://www.cnrm.meteo.fr/gmapdoc/spip.php?page=recherche&recherche=DDH","category":"page"},{"location":"PostPP/Diagnostics/#EZDIAG-1","page":"Diagnostics","title":"EZDIAG","text":"","category":"section"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"From Lisa: Note, this is for printing out full 3D fields from the model physics to the FA-file. ","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"In the routine that you would like to print out your fields add args:","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"     & PDIAG, KNDIAG,&","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"and declare them","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"INTEGER(KIND=JPIM),INTENT(IN) :: KNDIAG\r\nREAL(KIND=JPRB)   ,INTENT(OUT)   :: PDIAG(KLON,KLEV,KNDIAG)","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"Put values in the array if its dimension allows it, e.g.","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"IF (KNDIAG.GE.1) THEN\r\n    PDIAG(KIDIA:KFDIA,KTDIA:KLEV,1)= YOURVAL(KIDIA:KFDIA,KTDIA:KLEV)\r\nENDIF","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"or anything you wish. Note that the variable YOURVAL is now stored in NGFL_EZDIAG=1.","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"You can store this way up to 25 diagnostic 3D fields in the historic files.","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"If you want to store 2D fields, you can put them at different levels in the same 3D array.","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"Remake the interfaces if running AROME (not needed if running ALARO), before recompiling.","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"In the NAMGFL namelist:","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"! ADDITIONAL FIELDS FOR DIAGNOSTIC\r\n   NGFL_EZDIAG=1,          ! <=25\r\n   YEZDIAG_NL(1)%CNAME='YOURVAL',\r\n   YEZDIAG_NL(1)%LADV=.F.,","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"If you add more fields (e.g. you set NGFL_EZDIAG=4), I think you will also need to set the grib parameter, e.g.   (the default is 999, that you can leave for the first one).","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"   YEZDIAG_NL(2)%IGRBCODE=998,\r\n   YEZDIAG_NL(3)%IGRBCODE=997,\r\n   YEZDIAG_NL(4)%IGRBCODE=996,","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"Note that the two first places are already defined in harmonie_namelist.pm.","category":"page"},{"location":"PostPP/Diagnostics/#","page":"Diagnostics","title":"Diagnostics","text":"In order to have your variable converted from FA to grib, add the new variable in util/gl/inc/trans_tab.h","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Centos6Install?action=edit\"","category":"page"},{"location":"Centos6Install/#Centos-6-instructions-1","page":"Centos6","title":"Centos 6 instructions","text":"","category":"section"},{"location":"Centos6Install/#INFORMATION-1","page":"Centos6","title":"INFORMATION","text":"","category":"section"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Please note: the version of gcc/gfortran available on CentOS/Redhat 6 platforms ((GCC) 4.4.7 !20120313 (Red Hat 4.4.7-16)) is not recent enough to compile harminie-40h1 code. gcc/gfortran, netCDF and HDF5 must be installed locally (from source).","category":"page"},{"location":"Centos6Install/#Requirements-1","page":"Centos6","title":"Requirements","text":"","category":"section"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"This is a HOWTO for building and running Harmonie on a CentOS 6 PC with GNU compilers. This should probably work on a Redhat 6 PCs too. harmonie-38h1 code was used to develop this documentation.","category":"page"},{"location":"Centos6Install/#bit-OS-1","page":"Centos6","title":"64-bit OS","text":"","category":"section"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Enter the following command in a terminal to check you actually have a 64-bit Linux PC:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"uname  -m -i -p","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"This should return:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"x86_64 x86_64 x86_64","category":"page"},{"location":"Centos6Install/#OS-software-1","page":"Centos6","title":"OS software","text":"","category":"section"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"This list of required software is a guess at the moment. Your system may require the installation of other libraries. The following instructions require root access to your PC.","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"The compilers","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"yum install gcc.x86_64\r\nyum install gcc-c++.x86_64\r\nyum install gcc-gfortran.x86_64\r\nyum install libgcc.x86_64\r\nyum install openmpi.x86_64\r\nyum install openmpi-devel.x86_64","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Get yacc/bison","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"yum install byacc.x86_64 bison.x86_64 bison-devel.x86_64","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Get BLAS/LAPACK","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"yum install blas.x86_64 blas-devel.x86_64\r\nyum install lapack.x86_64 lapack-devel.x86_64","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"I installed NetCDF from the EPEL (Extra Packages for Enterprise Linux) repository. Here is how to enable access to this repository by your CentOS 6 PC:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm\r\nrpm -Uvh epel-release-6*.rpm\r\nls -1 /etc/yum.repos.d/epel*","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"now install netCDF","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"yum install netcdf.x86_64\r\nyum install netcdf-devel.x86_64\r\nyum install netcdf-static.x86_64","category":"page"},{"location":"Centos6Install/#Get-the-code-1","page":"Centos6","title":"Get the code","text":"","category":"section"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"For the 38h1.2.beta.2 tag:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"mkdir -p $HOME/harmonie_releases/tags\r\ncd $HOME/harmonie_releases/tags\r\nsvn co https://svn.hirlam.org/tags/harmonie-38h1.2.beta.2","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"For trunk:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"mkdir -p $HOME/harmonie_releases\r\ncd $HOME/harmonie_releases\r\nvn co https://svn.hirlam.org/trunk/harmonie \r\nln -s harmonie trunk","category":"page"},{"location":"Centos6Install/#Compile-Harmonie-1","page":"Centos6","title":"Compile Harmonie","text":"","category":"section"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Now let's create our first Harmonie experiment (METIE.LinuxPC setup is designed for standard CentOS 6 Linux PCs):","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"cd $HOME\r\nmkdir -p hm_home/trunkexp\r\ncd $HOME/hm_home/trunkexp\r\n$HOME/harmonie_releases/trunk/config-sh/Harmonie setup -r $HOME/harmonie_releases/trunk -h METIE.LinuxPC","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Local changes that may be required ... in the Env_system:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":":\r\n:\r\nmodule load metlib/odbapi/0.9.31-gnu\r\n:\r\n:\r\n# Climate data location\r\nexport HM_CLDATA=/home/ewhelan/harmonie_climate/38h1.1\r\nexport HM_SAT_CONST=/home/ewhelan/harmonie_sat_const\r\n:\r\n:\r\n# Jb data location\r\nexport JBDIR=/opt/metdata/harmonie_jbdata\r\n:\r\nexport SMSTASKMAX=4","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Local changes that may be required ... in the Env_submit:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"  $nprocy=2; # instead of 8 if you only have a dual-/quad-core PC","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Now use the Harmonie system to build the software:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"cd $HOME/hm_home/trunkexp\r\n$HOME/harmonie_releases/trunk/config-sh/Harmonie Install","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"This uses the Harmonie MAKEUP utility to compile the code and create libraries and executables required. Further details on MAKEUP are available here: wiki:HarmonieSystemDocumentation/Buildwithmakeup","category":"page"},{"location":"Centos6Install/#Run-an-experiment-1","page":"Centos6","title":"Run an experiment","text":"","category":"section"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Instructions for testbed and/or local experiment are detailed here:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Your first experiment will require changes to be made to the default settings in HOME/hmhome/trunkexp/ecf/configexp.h :","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"DOMAIN=IRELAND150       ## choose a small domain to run on your limited PC.\r\n                        ## See $HOME/harmonie_releases/trunk/scr/Harmonie_domains.pm for existing definitions\r\nVLEV=HIRLAM_60          ## I only have (easy access) to HIRLAM model level files on my PC \r\nANASURF_INLINE=\"no\"     ## I have experienced some issues with my setup calling SODA from inside CANARI\r\nHOST_MODEL=\"hir\"        ## tell boundary processing that you are using HIRLAM model boundary files\r\nOBDIR=$HOME/scratch/obs ## tell Harmonie where your BUFR observation files are\r\nBDDIR=$HOME/scratch/bnd ## tell Harmonie where your input boundary files are (HIRLAM or IFS files normally)\r\nBDSTRATEGY=available    ## I use a more forgiving boundary file strategy\r\nBDINT=3                 ## I only have (HIRLAM) boundary files every 3 hours","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Once you think you have all your ducks in a row you can try to run your first experiment:","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"cd $HOME/hm_home/trunkexp\r\n$HOME/harmonie_releases/trunk/config-sh/Harmonie start DTG=2014040100 DTGEND=2014040112 LL=03 BUILD=no","category":"page"},{"location":"Centos6Install/#","page":"Centos6","title":"Centos6","text":"Further details on how to use the Harmonie mini-SMS script system are available here: wiki:HarmonieSystemDocumentation/Harmonie-mSMS","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/QuickStartLocal?action=edit\"","category":"page"},{"location":"QuickStartLocal/#Running-Harmonie-on-your-local-platform-1","page":"Quick start local","title":"Running Harmonie on your local platform","text":"","category":"section"},{"location":"QuickStartLocal/#Introduction-1","page":"Quick start local","title":"Introduction","text":"","category":"section"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"These \"quick start instructions\" assumes that someone has already put in place a valid configuration for your local platform, CONFIG=linux.local for example.","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"The Harmonie system runs through a number of steps to help you complete your experiment. The chain can be summarized like:","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Configure and start the experiment: This is where you define your domain, choose your settings and specify the period for your experiment.","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Once you have done this you can start the system and let it create the basic infrastructure","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Setup the necessary directories and copy the system files needed (!InitRun, Prepare_cycle)\nCompile the binaries you need to run your experiment (Build)\nCreate the constant climate files specifying your domain (Climate)","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"With the basic setup and files in place we can proceed to the integration part where we have three loops taking care of ","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Prepare boundaries and observations (!MakeCycleInput)\nRun assimilation and forecasts (Date)\nPost process and archive the result (Postprocessing)","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"The three different task are allowed to run ahead/after each other to get a good throughput.","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"The configuration, the full suite and the relation between different tasks is controlled by the scheduler mini-SMS. This documentation describes how to get started with your first experiment. The description is general for a single host. (The reference Harmonie system on ECMWF platform assumes a dual-hosts setup with the front-end ecgb used to configure and launch experiments and cca is used for all computations except those for operations related to observation verification and monitoring. ","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Following example shows the steps to launch an Harmonie experiment my_exp.","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"If this is the first time to install HARMONIE on your local platform please take a look at the basic install instructions here: HarmonieSystemDocumentation/PlatformConfiguration. ","category":"page"},{"location":"QuickStartLocal/#Configure-your-experiment-1","page":"Quick start local","title":"Configure your experiment","text":"","category":"section"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Create an experiment directory under HOME/hm_home and use the master script Harmonie to set up a minimum environment for your experiment.","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"   mkdir -p $HOME/hm_home/my_exp\r\n   cd $HOME/hm_home/my_exp\r\n   PATH_TO_HARMONIE/config-sh/Harmonie setup -r PATH_TO_HARMONIE -h YOURHOST","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"where","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"-r is the path to your downloaded version of HARMONIE\n-h tells which configuration files to use. At ECMWF config.ecgb is the default one. List PATHTOHARMONIE/config-sh/config.* for available HOST configurations\nThis setup command  provides the default setup which currently is AROME physics with CANARI+OI_MAIN surface assimilation and 3DVAR upper air assimilations with 3h cycling on a domain covering Denmark using 2.5km horizontal resolution and 65 levels in the vertical.\nNow you can edit the basic configuration file ecf/config_exp.h to configure your experiment scenarios. Modify specifications for model domain, physics (AROME, ALARO), data locations, settings for dynamics, physics, domain, coupling host model etc. Read more about the options in here. You can also use some of the predefined configurations by calling Harmonie with the -c option:","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"mkdir $HOME/hm_home/my_exp\r\ncd $HOME/hm_home/my_exp\r\nPATH_TO_HARMONIE/config-sh/Harmonie setup -r PATH_TO_HARMONIE -h YOURHOST -c CONFIG ","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"where CONFIG is one of the setups defined in Harmonie_configurations.pm. If you give -c with out an argument or a non existing configuration a list of configurations will be printed.","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"In some cases you might have to edit the general system configuration file, Env_system. See here for further information: HarmonieSystemDocumentation/PlatformConfiguration\nThe rules for how to submit jobs are defined in Env_submit]. See here for further information: HarmonieSystemDocumentation/PlatformConfiguration\nIf you experiment in data assimilation you might also want to change scr/include.ass.","category":"page"},{"location":"QuickStartLocal/#Start-your-experiment-1","page":"Quick start local","title":"Start your experiment","text":"","category":"section"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Launch the experiment by giving start time, DTG, end time, DTGEND, and forecast length, LL","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"cd $HOME/hm_home/my_exp\r\nPATH_TO_HARMONIE/config-sh/Harmonie start DTG=YYYYMMDDHH DTGEND=YYYYMMDDHH LL=12\r\n# e.g., PATH_TO_HARMONIE/Harmonie start DTG=2012122400 DTGEND=2012122406 LL=12","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"If you would like to only run long forecasts at 00/12 UTC and short (3h) at 03/06/09/15/18/21, you specify the longer forecast length as LLMAIN. ","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"cd $HOME/hm_home/my_exp\r\nPATH_TO_HARMONIE/config-sh/Harmonie start DTG=2012122400 LLMAIN=24","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"If successful, mini-SMS will identify your experiment name and start building your binaries and run your forecast. If not, you need to examine the mSMS log file HM_DATAmSMSlog HM_DATA is defined in your Env_system file At ECMWF HMDATA=SCRATCH/hmhome/EXP where EXP` is your experiment name. Read more about where things happen further down.","category":"page"},{"location":"QuickStartLocal/#Continue-your-experiment-1","page":"Quick start local","title":"Continue your experiment","text":"","category":"section"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"If your experiment have successfully completed and you would like to continue for another period you should write","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"cd $HOME/hm_home/my_exp\r\nPATH_TO_HARMONIE/config-sh/Harmonie prod DTGEND=YYYYMMDDHH LL=12 ","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"By using prod you tell the system that you are continuing the experiment and using the first guess from the previous cycle. The start date is take from a file progress.log created in your HOME/hmhome/myexp directory. If you would have used start the initial data would have been interpolated from the boundaries, a cold start in other words.","category":"page"},{"location":"QuickStartLocal/#!Start/Restart-of-mXCdp-1","page":"Quick start local","title":"!Start/Restart of mXCdp","text":"","category":"section"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"To start the graphical window for mSMS on ecgb type","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"cd $HOME/hm_home/my_exp\r\nPATH_TO_HARMONIE/config-sh/Harmonie mon","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"The graphical window, mXCdp runs independently of the mSMS job and can be closed and restarted again with the same command. With the graphical interface you can control and view logfiles of each task. ","category":"page"},{"location":"QuickStartLocal/#Making-local-changes-1","page":"Quick start local","title":"Making local changes","text":"","category":"section"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Very soon you will find that you need to do changes in a script or in the source code. Once you have identified which file to edit you put it into the current HOME/hmhome/myexp directory, with exactly the same subdirectory structure as in the reference. e.g, if you want to modify a namelist setting ","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"cd $HOME/hm_home/my_exp\r\nPATH_TO_HARMONIE/config-sh/Harmonie co nam/harmonie_namelists.pm         # retrieve default namelist harmonie_namelists.pm\r\nvi nam/harmonie_namelists.pm                        # modify the namelist","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Next time you run your experiment the changed file will be used. You can also make changes in a running experiment. Make the change you wish and rerun the InitRun task in the mXCdp window. The !InitRun task copies all files from your local experiment directory to your working directory $HM_DATA. Once your InitRun task is complete your can rerun the task you are interested in. If you wish to recompile something you will also have to rerun the Build tasks. Read more about how to control and rerun tasks in mini-SMS from mXCdp here.","category":"page"},{"location":"QuickStartLocal/#Directory-structure-1","page":"Quick start local","title":"Directory structure","text":"","category":"section"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"On most platforms HARMONIE compiles and produces all its output data under HM_DATA (defined in ~/hmhome/myexp/Env_system)","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"= Description                            = = Location                                                                                  =\nBinaries BINDIR (set in ecf/configexp.h ), default is HMDATA/bin\nlibraries, object files & source code HM_DATA/lib/src if MAKEUP=yes, HMDATA/gmkpack_build if MAKEUP=no\nScripts HM_DATA/lib/scr\nconfig files (Envsystem & Envsystem HM_DATA/lib linked to files in HM_DATA/config-sh\nsms HM_DATA/lib/sms\nmsms definitions HM_DATA/lib/msms\nUtilities such as gmkpack, gl & monitor HM_DATA/lib/util\nClimate files HM_DATA/climate\nWorking directory for the current cycle HM_DATA/YYYYMMDD_HH\nArchived files HM_DATA/archive\nArchived cycle output HM_DATA/archive/YYYY/MM/DD/HH\nArchived log files HM_DATA/archive/log/HMTaskFamilyYYYYMMDDHH.html where !TaskFamily=!MakeCycleInput,Date,Postprocessing\nTask log files JOBOUTDIR (set in Envsystem) usually HMDATA/sms_logfiles\nVerification data (vfld/vobs/logmonitor) HM_DATA/archive/extract\nVerification (monitor) results HM_DATA/archive/extract/WebgraF\n\"Fail\" directory HM_DATA/YYYYMMDDHH/FailedFamilyTask (look at ifs.stat, NODE.00101, fort.4","category":"page"},{"location":"QuickStartLocal/#Archive-contents-1","page":"Quick start local","title":"Archive contents","text":"","category":"section"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"HM_DATA","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"/archive/YYYY/MM/DD/HH is used to store \"archived\" output from HARMONIE cycles. The level of archiving depends on ARSTRATEGY in ecf/config_exp.h . The default setting is medium which will keep the following cycle data:","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Surface analysis: ICMSHANAL+0000\nAtmospheric analysis result: MXMIN1999+0000\nBlending between surface/atmospheric analysis and cloud variable from the first guess: ANAB1999+0000\nICMSHHARM+NNNN and ICMSHHARM+NNNN.sfx are atmospheric and surfex forecast output files\nPFHARM* files produced by the inline postprocessing \nGRIB files produced by the conversion of FA output files to GRIB if MAKEGRIB=yes in ecf/config_exp.h \nODB databases and feedback information in odb_stuff.tar","category":"page"},{"location":"QuickStartLocal/#Cleanup-of-old-experiments-1","page":"Quick start local","title":"Cleanup of old experiments","text":"","category":"section"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Once you have complete your experiment you may wish to remove code, scripts and data from the disks. Harmonie provides some simple tools to do this. First check the content of the different disks by","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":" Harmonie CleanUp -ALL","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"Once you have convinced yourself that this is OK you can proceed with the removal.","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":" Harmonie CleanUp -ALL -go ","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"If you would like to exclude the data stored  HMDATA ( as defined in Envsystem ) you run ","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":" Harmonie CleanUp -d","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"to list the directories intended for cleaning. Again, convince yourself that this is OK and proceed with the cleaning by","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":" Harmonie CleanUp -d -go","category":"page"},{"location":"QuickStartLocal/#","page":"Quick start local","title":"Quick start local","text":"NOTE that these commands may not work properly in all versions. Do not run the removal before you're sure it's OK","category":"page"},{"location":"QuickStartLocal/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Quick start local","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"Binaries/#","page":"Binaries","title":"Binaries","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Binaries?action=edit\"","category":"page"},{"location":"Binaries/#HARMONIE-binaries-1","page":"Binaries","title":"HARMONIE binaries","text":"","category":"section"},{"location":"Binaries/#","page":"Binaries","title":"Binaries","text":"An installation of HARMONIE produces the following binaries:","category":"page"},{"location":"Binaries/#","page":"Binaries","title":"Binaries","text":"ACADFA1D : Tool to generate initial and boundary data for MUSC\nADDPERT : Create initial perturbations\nADDSURF : Allows you to mix different files and add different fields\nALTO : Also known as PINUTS. Contains several diagnostic tools.\nBATOR : Generate ODB from observations in various formats\nbl95.x : Blacklist compiler, help program to generate object files from the blacklist\nBLEND : Mixes to files\nBLENDSUR : Mixes to files\ncluster : Cluster ensemble members\nCONVERTECOCLIMAPPARAM : Generate binary files from ECOCLIMAP ascii files\ndcagen : ODB handling tool\ndomain_prop : Helper program to return various model domain properties\nFESTAT : Background error covariance calculations.\nfldextr : Extracts data for verification from model history files. Reads FA from HARMONIE and GRIB from ECMWF/HIRLAM.\ngl : Converts/interpolates between different file formats and projections. Used for boundary interpolation.\nIOASSIGN/ioassign : ODB IO setup\nLSMIX : Scale dependent mixing of two model states.\njbconv : Interpolates/extrapolates background error statistics files. For technical experimentation\nlfitools : FA/LFI file manipulation tool\nMASTERODB : The main binary for the forecast model, surface assimilation, climate generation, 3DVAR, fullpos and much more.\nMTEN : Computation of moist tendencies\nobsextr : Extract data for verification from BUFR files. \nobsmon : Extract data for observation monitoring\nodb98.x : ODB manipulation program\nOFFLINE : The SURFEX offline model. Also called SURFEX\noulan : Converts observations in BUFR to OBSOUL format used by BATOR\nPERTCMA : Perturbation of observations in ODB\nPERTSFC : Surface perturbation scheme\nPGD : Generates physiography files for SURFEX.\nPREGPSSOL : Processing of GNSS data\nPREP : Generate SURFEX initial files. Interpolates/translates between two SURFEX domains.\nSFXTOOLS : Converts SURFEX output between FA and LFI format.\nshuffle : Manipulation of ODB. Also called ODBTOOLS\n!ShuffleBufr : Split bufr data according to observation type, used in the observation preprocessing.\nSODA : Surfex offline data assimilation\nSPG : Stochastic pattern generator, https://github.com/gayfulin/SPG\nSURFEX : The SURFEX offline model. Also called OFFLINE\ntot_energy : Calculates the total energy of a model state. Is used for boundary perturbation scaling.\nxtool : Compares two FA/LFI/GRIB files.","category":"page"},{"location":"Binaries/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Binaries","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"PostPP/gl_grib_api/#","page":"glgribapi","title":"glgribapi","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PostPP/gl_grib_api?action=edit\"","category":"page"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PostPP/gl/Interpolation?action=edit\"","category":"page"},{"location":"PostPP/gl/Interpolation/#Interpolations-with-gl-1","page":"GL interpolation","title":"Interpolations with gl","text":"","category":"section"},{"location":"PostPP/gl/Interpolation/#Introduction-1","page":"GL interpolation","title":"Introduction","text":"","category":"section"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"In the following we describe the geometrical routines in gl. gl can handle the following projections","category":"page"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"lat/lon\nRotated lat/lon\nLambert\nPolar stereographic\nRotated Mercator","category":"page"},{"location":"PostPP/gl/Interpolation/#Interpolation-1","page":"GL interpolation","title":"Interpolation","text":"","category":"section"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"All interpolations are handled within the module module_interpol.f90. The module contains ","category":"page"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"clear_interpol to clear the interpolation setup\nsetup_interpol where the position of the output gridpoints in the input grid are calculated\nsetup_weights where we calculate the interpolation weights. Interpolation can be nearest gridpoint or bilinear. The interpolation can be masked with a field that tells which gridpoints from the input fields that can be used. ","category":"page"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"The setup routines are only called once.","category":"page"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"interpolate runs the interpolation\nresample works like the interpolation if the input grid is coarser than the output grid. If reversed it takes the averages of the input gridpoints belonging to each output gridpoit.","category":"page"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"Interpolation can be done between different projections as wall as to geographical points. The most general exmple on the usage of the interpolatin can be found in  any2any.F90.","category":"page"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"For practical usage see the section about postprocessing","category":"page"},{"location":"PostPP/gl/Interpolation/#Rotations-1","page":"GL interpolation","title":"Rotations","text":"","category":"section"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"All rotations are handled within the module module_rotations.f90. The module contains ","category":"page"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"clear_rotation to clear the rotation setup\nprepare_rotation prepare rotations from input geometry to output geometry via north south components.\nrotate_winds runs the actual rotation.","category":"page"},{"location":"PostPP/gl/Interpolation/#Staggering-1","page":"GL interpolation","title":"Staggering","text":"","category":"section"},{"location":"PostPP/gl/Interpolation/#","page":"GL interpolation","title":"GL interpolation","text":"The staggering of an input file is based on the knowledge about the model and is set here.   The restaggering is done in restag.f90 as a simple average between gridpoints. The staggering of the output geomtery  is defined by OUTGEO@ARKAWA, where A and C are available options.","category":"page"},{"location":"PostPP/gl/Interpolation/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../../../HarmonieSystemDocumentation.md)-1","page":"GL interpolation","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PostPP/FileConversions?action=edit\"","category":"page"},{"location":"PostPP/FileConversions/#File-conversions-this-page-under-construction-1","page":"FileConversion","title":"File conversions - this page under construction","text":"","category":"section"},{"location":"PostPP/FileConversions/#FA-–-GRIB-1","page":"FileConversion","title":"FA –> GRIB","text":"","category":"section"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"The default HARMONIE output is in FA format. HIRLAM/HARMONIE users are more used to dealing with data encoded according to GRIB, a WMO code for the representation of gridded data. Users have the option to convert HARMONIE FA format files to GRIB1 (short for GRIB edition 1), GRIB2 (short for GRIB edition 2) or NETCDF. Note that the NETCDF conversion is still experimental. References about different WMO GRIB editions (1, 2 and 3) can be found [[#GRIBeds | here]].","category":"page"},{"location":"PostPP/FileConversions/#ecf/config_exp.h-1","page":"FileConversion","title":"ecf/config_exp.h","text":"","category":"section"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"The option to convert model output can be selected in the [source:Harmonie/ecf/config_exp.h] experiment configuration file:","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"\r\n# **** GRIB ****\r\nCONVERTFA=yes                    # Conversion of FA file to grib/nc (yes|no)\r\nARCHIVE_FORMAT=GRIB1|2           # Format of archive files (GRIB1|GRIB2|nc). Currently nc format is only available in climate mode","category":"page"},{"location":"PostPP/FileConversions/#Details-1","page":"FileConversion","title":"Details","text":"","category":"section"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"From the perspective of harmonie suite, the conversion FA to GRIB is carried out in the following tasks:","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"Makegrib_an - for fields produced in the analysis. This task is part of the !/Expe/Date/Hour/Cycle/PostAnalysis family.\nListen2file - for fields produced in the forecast. This task is part of the !/Expe/Date/Hour/Cycle/Forecast family, possibly through a set of intermediate families Process-i (depending on the values of variables MULTITASK and MAKEGRIBLISTENERS as set in the [source:Harmonie/ecf/configexp.h] experiment configuration file).","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"If ARCHIVE_FORMAT is set to GRIB1 or GRIB2, the Makegrib bash script will be run from the tasks mentioned above (possibly through intermediate scripts). Finally, from the Makegrib script the gl tool will be called to convert HARMONIE output from FA to GRIB. Notice that if a more verbose job output is needed, e.g. for debugging, variable PRINTLEV can be set, at the beginning of Makegrib, to something else than 0.","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"Conversion of FA/lfi files to GRIB by gl:","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"    gl [-c] [-p] FILE [ -o OUTPUT_FILE] [ -n NAMELIST_FILE]\r\n\r\n    gl -c FA/LFI-FILE -- converts the full field (including extension zone)\r\n    gl -p FAFILE      -- excludes the extension zone ( \"p\" as in physical domain only) ","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"By default, Makegrib removes the biperiodic zone from FA files and creates GRIB files. HARMONIE data is produced on a Lambert projection. GRIB data can be interpolated onto different projections using gl. Further information is available in the gl documentation.","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"Forecast output is converted from FA to GRIB in Makegrib using the following command:","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"  $MPPGL $BINDIR/gl -p $1 -o $2 -n namelist_makegrib${MG} || exit","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"where ","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"1 is the input HARMONIE FA-file (ICSMH\n{HARM}+{ffff}, HARM is the 4-char experiment identifier, ffff is the forecast step)\n2 is the output HARMONIE GRIB file (fc\n{DATE}HH+{FFF}grib)\nnamelist_makegrib{MG} is ","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"&naminterp\r\n outkey%yy=$YY,\r\n outkey%mm=$MM,\r\n outkey%dd=$DD,\r\n outkey%hh=$HH,\r\n outkey%mn=00,\r\n outkey%ff=$FF,\r\n time_unit=$time_unit\r\n pppkey(1:3)%ppp =   1, 61,184\r\n pppkey(1:3)%ttt = 103,105,105,\r\n pppkey(1:3)%lll =   0,  0,  0,\r\n pppkey(1:3)%tri =   0,  4,  4,\r\n skipsurfex = .TRUE.,\r\n fstart(15) = $fstart,\r\n fstart(16) = $fstart,\r\n fstart(162) = $fstart,\r\n fstart(163) = $fstart,\r\n/","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"In the namelist:","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"YY\nMM/DDHH  is the forecast initial time\ntime_unit\nis the units of time to be used min/h\npppkey: selection of requested post-processed products (See: Postprocessing with gl for more details)\nfstart\nis the start hour for time-range products such as maximum temperature.","category":"page"},{"location":"PostPP/FileConversions/#WMO-GRIB-editions-and-references-1","page":"FileConversion","title":"WMO GRIB editions and references","text":"","category":"section"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"[=#GRIBeds] Currently (Aug 2019) there are several editions of GRIB in use or in experimental phase.","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"GRIB edition 2 is currently the main GRIB edition. See WMO FM 92–XIV GRIB for details of the format.","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"GRIB edition 1 is nowadays considered a legacy code. However it is still used, not only for legacy gridded data, but also to encode currently generated data. See WMO FM 92-XI GRIB for details of the format.","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"There is an experimental WMO GRIB edition 3. See WMO FM 92-16 GRIB for details of the format.","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"Back to the main page of the HARMONIE System Documentation","category":"page"},{"location":"PostPP/FileConversions/#","page":"FileConversion","title":"FileConversion","text":"","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Analysis/SurfaceAnalysis?action=edit\"","category":"page"},{"location":"Analysis/SurfaceAnalysis/#Surface-Data-Assimilation-in-HARMONIE-1","page":"Surface Analysis","title":"Surface Data Assimilation in HARMONIE","text":"","category":"section"},{"location":"Analysis/SurfaceAnalysis/#Surface-related-variables-in-ecf/config_exp.h-:-1","page":"Surface Analysis","title":"Surface related variables in ecf/config_exp.h :","text":"","category":"section"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"Surface model: SURFACE = \"surfex\" / \"old_surface\"","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"surfex: SURFEX is used as surface model (default and used in all Harmonie configurations) The surface fields are in a separat AROMOUT_.LLLL.lfi file in LFI format. \nold_surface: surface physics modelled by routines integrated in code The surface fields are a part of the atmospheric file (ICMSHXXXX+LLLL) in FA format.","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"Surface analysis method: ANASURF = \"CANARIOIMAIN\" / \"CANARIEKFSURFEX\"","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"the horisontal interpolation of screen level parameters is performed by CANARI in both cases\nCANARIOIMAIN updates soil temperature, water and ice based on 2m analysis increments using coefficients that are derived empirically for ISBA2/3-layers scheme\nCANARIEKFSURFEX (experimental) updates soil parameters using the Extended Kalman Filter method.","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"ANASURF_MODE = \"before\" / \"after\"/ \"both\" - surface analysis performed before/after/both before and after 3DVAR","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"ANASURF_INLINE = \"yes\" /\"no\"","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"yes: call SODA for updating soil parameters inside CANARI (default and experimental)\nno: soil parameters are updated after CANARI","category":"page"},{"location":"Analysis/SurfaceAnalysis/#Some-details-1","page":"Surface Analysis","title":"Some details","text":"","category":"section"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"The default surface model is SURFEX and the default surface assimilation scheme is CANARIOIMAIN. CANARIEKFSURFEX was first implemented in cy37 and will be undergoing tests in experimental and research mode before it can be used in operational setups.","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"CANARI is used for Optimum Interpolation horizontally to find analysis increments in each grid point based on observations minus first guess. The SURFEX assimilation schemes use two different techniques to propagate this information into the ground. The two ways CANARI is used is separated by two namelist settings needed when running with SURFEX:","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"LAEICS=.FALSE.","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"No initialization of ground variables are done as they are in the SURFEX file","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"LDIRCLSMOD=.TRUE.","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"2 metre variables taken directly from input file because they without surfex are diagnosed from 0 metre and lowest model height with the model specific routine achmt.","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"CANARI was designed before SURFEX was introduced and some of the climate variables that normally exist in the input file for CANARI, do not exist when using SURFEX. This means the task Addsurf is run before CANARI, adding the needed fields from the FA climate file (mMM).","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"The screen level analyisis (eg. T2m) used in blending/3DVAR/4DVAR is the same as for CANARI in the old_surface case.","category":"page"},{"location":"Analysis/SurfaceAnalysis/#Variables-updated-in-CANARI-for-old_surface-and-SURFEX-1","page":"Surface Analysis","title":"Variables updated in CANARI for old_surface and SURFEX","text":"","category":"section"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"Module of namelist variables","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"HARMONIE namelist settings:","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"!  * LAET2M  : .T. 2 meter temperature analysis\r\n!  * LAEH2M  : .T. 2 meter humidity analysis\r\n!  * LAESNM  : .T. snow analysis\r\n!  * LAESST  : .F. SST analysis\r\n!  * LECSST  : .T. use ECMWF SST\r\n!  * LAEPDS  : .F. surface pressure analysis\r\n!  * LAEUVT  : .F. wind and temperature analysis\r\n!  * LAEHUM  : .F. humidity analysis\r\n!  * LAEV1M  : .F. 10 meter wind analysis","category":"page"},{"location":"Analysis/SurfaceAnalysis/#Blacklisting-of-surface-observation-1","page":"Surface Analysis","title":"Blacklisting of surface observation","text":"","category":"section"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"It is possible, in HARMONIE data assimilation, to blacklist data from specific sites. Following example illustrate blacklisting of one automatic (type 24) ship measurement with code name DBKR starting from a certain date March 6, 2012,","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"   cd ~/hm_home/$exp\r\n   Harmonie co LISTE_NOIRE_DIAP  # check out blacklist from the repository, e.g., source:Harmonie/nam/LISTE_NOIRE_DIAP\r\n   (edit then nam/LISTE_NOIRE_DIAP to insert, e.g. at the last line, following\r\n\r\n    1 SHIP        24  11 DBKR     03062012\r\n","category":"page"},{"location":"Analysis/SurfaceAnalysis/#","page":"Surface Analysis","title":"Surface Analysis","text":"Back to the main page of the HARMONIE System Documentation","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/PostPP/xtool?action=edit\"","category":"page"},{"location":"PostPP/xtool/#Post-processing-with-xtool-1","page":"xtool","title":"Post processing with xtool","text":"","category":"section"},{"location":"PostPP/xtool/#xtool-1","page":"xtool","title":"xtool","text":"","category":"section"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"Xtool, part of the gl package, provides a utility to calculate differences between GRIB/FA files and produce the result in a new GRIB file. See xtool part of gl-README. The main commands are:","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":" \r\n                          xtool                                 \r\n \r\n Simple usage:                                                  \r\n  xtool -f1 FILE1 [ -fN FILEN] -op OPERATOR [ -o OFILE]       \r\n  i.e. apply OPERATOR on FILEN and output to OFILE              \r\n  operator is one of SUM/DIFF/AVE/STDV/RMS/MS                      \r\n  1 file : SUM/AVE/SQR                                          \r\n  2 files: SUM/AVE/PROD/DIFF/RMSE/STDV/SAL                      \r\n  3 files: DIFF/SAL                                             \r\n \r\n Accumulated usage:                                             \r\n  xtool -sdtg1 YYYYMMDDHH -edtg1 YYYYMMDDHH -ll1 LLL -ll2 LLL \\ \r\n        -p1 PATH1 -p2 PATH2 -fcint HH -op OPERATOR              \r\n  i.e. accumulate OPERATOR on FILE1 and FILE2 during the period \r\n  sdtg1 to edtg1 with step of fcint.                            \r\n  sdtg2/edtg2=sdtg1/edtg2 - (LL1-LL2) unless given              \r\n \r\n Time information in the path should be given as                \r\n  -p1 /data/test/fc@YYYY@@MM@@DD@@HH@+@LLL@ or something like   \r\n  -p2 /data/@YYYY@/@MM@/@DD@/@HH@/fc@YYYY@@MM@@DD@_@HH@+@LLL@   \r\n \r\n Different parameters can be compared by using the xkey         \r\n variable in the namelist                                       \r\n \r\n Flag summary :                                                 \r\n  -h                : Print this help                           \r\n  -fN FILE          : Single file name                          \r\n  -pN PATH          : Path name                                 \r\n  -sdtgN YYYYMMDDHH : Start date/time                           \r\n  -edtgN YYYYMMDDHH : End date/time                             \r\n  -llN LLL          : Forecast length to use                    \r\n  -fcint HH         : Forecast cycle interval in hours          \r\n  -iN               : format of the input file GRIB/FA          \r\n  -s                : Run silent                                \r\n  -of               : Output format GRIB/FA/SCREEN              \r\n  -g                : Prints ksec/cadre/lfi info                \r\n  -p                : Use FA file without extension zone        \r\n  -f                : Global FA switch                          \r\n  -a FILE           : Accumulation file to be read              \r\n  -n namelist       : Use namelist to set additional options    \r\n  -igd              : Set lignore_duplicates=F                  \r\n  -r VALUE          : Rescale the output with a constant VALUE  \r\n ","category":"page"},{"location":"PostPP/xtool/#DIFF-1","page":"xtool","title":"DIFF","text":"","category":"section"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"One of the things xtool is useful for is to check if the result from two different experiments differ. This is done by applying the DIFF operator and writing the output to the screen like","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":" xtool [-f] -f1 FILE1 -f2 FILE2 -of SCREEN","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"The is heavily used in the Harmonie testbed to check the difference between versions of the system.","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"Below is a simple example of how to use xtool. You may also check the field extraction to find examples. ","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"What is the difference between +24h and +48h MSLP forecasts during August 2008?","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"Namelist for xtool, which lists the parameters (here mean sea level pressure) to be examined:","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"&NAMINTERP\r\n  PPPKEY%ppp = 001,\r\n  PPPKEY%lll = 000,\r\n  PPPKEY%ttt = 103,\r\n/","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"Run xtool.","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"xtool -sdtg1 2008080100 -edtg1 2008083000 -ll1 48 \\\r\n      -sdtg2 2008073100 -edtg2 2008082900 -ll2 24 \\\r\n      -p1 /your_model_data/YYYY/MM/HH/fcYYYYMMDD_HH+LLL \\\r\n      -p2 /your_model_data/YYYY/MM/HH/fcYYYYMMDD_HH+LLL \\\r\n      -fcint 6 -op DIFF -n your_namelist \\\r\n      -o output.grb","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"-sdtg1, -edtg1, -ll1: The cycles to look for the +48h forecast.\n-sdtg2, -edtg2, -ll2: The cycles to look for the +24h forecast.\n-p1, -p2: Naming rules for the files in cycle 1 and 2, respectively.\n-fcint: Interval between forecast cycles.\n-op: Operation to be applied. Possible choices DIFF, SUM, AVE, STDV or SAL\n-n: Namelist file.\n-o: Name of the output grib file.","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"Output file (output.grb) now contains one 2D-field with accumulated 48-24h difference of mean sea level pressure.  ","category":"page"},{"location":"PostPP/xtool/#SAL-1","page":"xtool","title":"SAL","text":"","category":"section"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"Structure Amplitude Location (SAL) is object based quality measure for the verification of QPFs (Wernli et al., 2008). SAL contains three independent components that focus on Structure, Amplitude and Location of the precipitation field in a specified domain. ","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"S: Measure of structure of the precipitation area (-2 - +2). Large S, if model predicts too large precipitation areas.\nA: Measure of strength of the precipitation (-2 - +2). Large A, if model predicts too intense precipitation.\nL: Measure of location of the precipitation object (0 - +2). Large L, if modelled precipitation objects are far from the observed conterparts. ","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"SAL can be activated in xtool by using -op SAL option. e.g.","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":" xtool -f1 model.grib -f2 observation.grib -op SAL -n namelist","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"Output of the SAL are 2 simple ascii-files:","category":"page"},{"location":"PostPP/xtool/#","page":"xtool","title":"xtool","text":"scatter_plot.dat containing date, S,A and L parameters.\nsal_output.dat containing more detailed statistics collected during the verification (location of center of mass, number of objects, measure of object size etc.).","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Evaluation/HarmonieTestbed?action=edit\"","category":"page"},{"location":"Evaluation/HarmonieTestbed/#The-HARMONIE-testbed-1","page":"Testbed","title":"The HARMONIE testbed","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The HARMONIE testbed provides a facility to run a number of well defined test cases using the existing script environment in HARMONIE. The ALADIN testbed, mitraillette runs test on the hart of the model, the dynamical core. The HARMONIE testbed tests the full script system as it is supposed to be used.","category":"page"},{"location":"Evaluation/HarmonieTestbed/#Defining-the-configurations-1","page":"Testbed","title":"Defining the configurations","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#General-1","page":"Testbed","title":"General","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The testbed is a suite that launches and follows new experiments one at a time in a controlled environment. The testbed experiment takes care of compilation and also hosts the climate files generated by the tested configurations. Source and scripts changes shall be done in the testbed experiment and will be synchronized to the child experiment using the hm_CMODS option in HARMONIE. ","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"A number of basic configurations have been defined in Harmonie_configurations.pm as the deviation from the default setup in  config_exp.h, include.ass and harmonie.pm. These configurations are controlled by the script  Harmonie_testbed.pl. The script also contains a number of extra configurations tested from time to time. With the current settings, a test of AROME without 3DVAR would look like.","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"\r\n    # AROME no 3D-VAR but default blending of upper air from boundaries\r\n    'AROME' => {\r\n      'description' => 'Standard AROME settings without upper air DA',\r\n      'PHYSICS'     => 'arome',\r\n      'SURFACE'     => 'surfex',\r\n      'DYNAMICS'    => 'nh',\r\n      'ANAATMO'     => 'blending',\r\n      'ANASURF'     => 'none',\r\n      'DFI'         => 'none',\r\n      'HOST_MODEL'  => 'ifs',\r\n      'DOMAIN'      => 'DKCOEXP',\r\n      'VLEV'        => '65',\r\n      'BDINT'       => '3',\r\n    },\r\n","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The resulting output, in this case from AROMEBDARO running at ECMWF would look like:","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"\r\n Using the configuration AROME_BD_ARO\r\n\r\n\r\n Input /gpfs/scratch/ms/spsehlam/hlam/test_harmonie/ecgb_c2a_testbed_trunk_mkp_12413/ecf/config_exp.h  \r\n Output ecf/config_exp.h  \r\n\r\n Change BUILD=${BUILD-yes}                     to BUILD=no \r\n Change       BUILD_ROOTPACK=no to BUILD_ROOTPACK=no \r\n Change BINDIR=${BINDIR-$HM_DATA/bin}                 to BINDIR=$HM_COMDAT/ecgb_c2a_testbed_trunk_mkp_12413/bin \r\n Change DOMAIN=DKCOEXP                          to DOMAIN=TEST_8 \r\n Change VLEV=65                                 to VLEV=HIRLAM_60 \r\n Change LL=${LL-06}                             to LL=6 \r\n Change DYNAMICS=\"nh\"                           to DYNAMICS=nh \r\n Change PHYSICS=\"arome\"                         to PHYSICS=arome \r\n Change SURFACE=\"surfex\"                        to SURFACE=surfex \r\n Change DFI=\"none\"                              to DFI=none \r\n Change ANAATMO=3DVAR                           to ANAATMO=none \r\n Change ANASURF=CANARI_OI_MAIN                  to ANASURF=none \r\n Change OBDIR=$HM_DATA/observations             to OBDIR=$HM_DATA/../ecgb_c2a_testbed_trunk_mkp_12413/observations/ \r\n Change HOST_MODEL=\"ifs\"                        to HOST_MODEL=aro \r\n Change HOST_SURFEX=\"no\"                        to HOST_SURFEX=yes \r\n Change SURFEX_INPUT_FORMAT=lfi                 to SURFEX_INPUT_FORMAT=fa \r\n Change BDLIB=ECMWF                             to BDLIB=AROME \r\n Change BDDIR=$HM_DATA/${BDLIB}/archive/@YYYY@/@MM@/@DD@/@HH@   to BDDIR=$HM_DATA/../ecgb_c2a_testbed_trunk_mkp_12413/archive_AROME/@YYYY@/@MM@/@DD@/@HH@/ \r\n Change INT_BDFILE=$WRK/ELSCF${CNMEXP}ALBC@NNN@                 to INT_BDFILE=$ARCHIVE_ROOT/$YY/$MM/$DD/$HH/ELSCF${CNMEXP}ALBC@NNN@ \r\n Change BDSTRATEGY=simulate_operational to BDSTRATEGY=same_forecast \r\n Change BDINT=1                         to BDINT=3 \r\n Change SURFEX_PREP=\"no\"                to SURFEX_PREP=yes \r\n Change CLIMDIR=$HM_DATA/climate                to CLIMDIR=$HM_DATA/../ecgb_c2a_testbed_trunk_mkp_12413/climate/$DOMAIN/$PHYSICS \r\n Change BDCLIM=$HM_DATA/${BDLIB}/climate        to BDCLIM=$HM_DATA/../ecgb_c2a_testbed_trunk_mkp_12413/climate/TEST_11/arome/ \r\n Change INT_SINI_FILE=$WRK/SURFXINI.$SURFEX_OUTPUT_FORMAT       to INT_SINI_FILE=$ARCHIVE_ROOT/$YY/$MM/$DD/$HH/SURFXINI.$SURFEX_OUTPUT_FORMAT \r\n Change ARCHIVE_ECMWF=yes                       to ARCHIVE_ECMWF=no \r\n Change POSTP=\"inline\"                          to POSTP=inline \r\n Change MAKEGRIB=no                             to MAKEGRIB=yes \r\n Add new settings JBDIR=$HM_REV/testbed_data/jb_data \r\n Add new settings LARGE_EC_BD=no \r\n Add new settings PLAYFILE=harmonie \r\n Add new settings config=AROME \r\n\r\n\r\n Input /gpfs/scratch/ms/spsehlam/hlam/test_harmonie/ecgb_c2a_testbed_trunk_mkp_12413/Env_submit \r\n Output Env_submit \r\n\r\n Change $nprocx=16; to $nprocx=2 \r\n Change $nprocy=16; to $nprocy=2 \r\n Change $nprocx=8; to $nprocx=2 \r\n Change $nprocy=16; to $nprocy=2 \r\n","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"As seen from the example above the script also changes the submission rules. These rules can be defined, per host, at the end of the script. Other host specific settings may also be defined to allow local changes of the test environment. In Harmonie_testbed.pl we find e.g. changes for ecgate:","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"\r\n 'ecgate' => {\r\n   'BINDIR'     => '$HM_COMDAT/'.$EXP.'/bin',\r\n   'BDDIR'      => '$HM_DATA/../'.$EXP.'/$BDLIB/$DOMAIN',\r\n   'OBDIR'      => '$HM_DATA/../'.$EXP.'/observations/$DOMAIN',\r\n   'LARGE_EC_BD' => 'no',\r\n   'CLIMDIR'    => '$HM_DATA/../'.$EXP.'/climate/$DOMAIN/$PHYSICS',\r\n  },\r\n","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The host dependent settings will be imposed on all configurations. If a setting in any configuration is in conflict with the host settings the configuration settings will be used.","category":"page"},{"location":"Evaluation/HarmonieTestbed/#Define-changes-in-harmonie.pm-1","page":"Testbed","title":"Define changes in harmonie.pm","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The changes to msms/harmonie.pm are controlled with a special syntax, like in the AROME_JB configuration.","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"   # AROME Structure function derivation\r\n   'AROME_JB' => {\r\n     'description' => 'Derive structure functions for AROME 3DVAR',\r\n      ...\r\n      'harmonie.pm' => ['ENSBDMBR','ENSCTL','SLAFLAG'],\r\n        'ENSBDMBR'    => '[1,2,3,4]',\r\n        'ENSCTL'      => '[\"001\",\"002\",\"003\",\"004\"]',\r\n        'SLAFLAG'     => '[0]',\r\n    },\r\n","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The harmonie.pm key determines which keyword to find and replace. The list guarantees that the same keywords are not changed in e.g. ecf/config_exp.h .","category":"page"},{"location":"Evaluation/HarmonieTestbed/#Testbed-members-1","page":"Testbed","title":"Testbed members","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"=Name                 = =DOMAIN       = =DTGs                  = =Dependencies = =Description                                 = =Active in =\nAROME TEST_11 !2017093018-!2017100100 None AROME with 2-D decomposition CY43\nAROME_1D TEST_11 !2017093018-!2017100100 None AROME with 1-D decomposition CY43\nAROME_2D TEST_11 !2017093018-!2017100100 None AROME with 2-D decomposition \nAROME_3DVAR IRELAND150 !2017093018-!2017100100 None AROME_3DVAR CY43\nAROME3DVARMARSOBS IRELAND150 !2017093018-!2017100100 None AROME_3DVAR including non-conventional observations from MARS CY43\nAROME3DVAR2P TEST_11 !2017093018-!2017100100 None AROME_3DVAR with two patches \nAROME_4DVAR SCANDINAVIA !2017093021-!2017100100 None AROME_4DVAR \nAROMEBDALA TEST_8 !2017093018-!2017100100 ALARO AROME with ALARO LBCs \nAROMEBDALA_ARO TEST_2.5 !2017093018-!2017100100 AROMEBDALA AROME with AROME LBCs \nAROMEBDARO TEST_8 !2017093018-!2017100100 AROME AROME with AROME LBCs, no IO-server CY43\nAROMEBDAROIOSERV TEST_8 !2017093018-!2017100100 AROME AROME with AROME LBCs, with IO-server CY43\nAROMEBDARO_2P TEST_8 !2017093018-!2017100100 AROME AROME two patches with AROME LBCs \nAROME_CLIMSIM TEST_11 !2012053100-!2012060200 None AROME climate simulation, netcdf output CY43\nAROME_EKF TEST_11 !2017093018-!2017100100 None AROME with CANARIEKFSURFEX \nAROMEEPSCOMP TEST_11 !2017093018-!2017100100 HarmonEPS AROME_3DVAR comparison of EPS control CY43\nAROME_MUSC TEST_11 !2017093018-!2017100100 AROME AROME MUSC CY43\nAROME_NONE TEST_11 !2017093018-!2017100100 None AROME no SFC/UA DA \nAROMENONE2D TEST_11 !2017093018-!2017100100 None AROME no SFC/UA DA \nAROMENONEBDALANONE TEST_8 !2017093018-!2017100100 ALARO_NONE AROME no SFC/UA DA with ALARO LBCs \nAROMENONEBDARONONE TEST_8 !2017093018-!2017100100 AROME_NONE AROME no SFC/UA DA with AROME LBCs \nARONE_JB TEST_11 !2017093018-!2017100100 None Generation of JB statistics CY43\nHarmonEPS TEST_11 !2017093018-!2017100100 AROMEEPSCOMP HarmonEPS CY43\nHarmonEPS_IFSENSBD TEST_11 !2019111021-!2019111103 AROMEEPSCOMP HarmonEPS with IFSENS boundaries CY43\nALARO13DVAROLD TEST_11 !2017093018-!2017100100 None ALARO1 with 3DVAR and old_surface \nALARO_1D TEST_11 !2017093018-!2017100100 None ALARO with 1-D decomposition \nALARO_2D TEST_11 !2017093018-!2017100100 None ALARO with 2-D decomposition \nALARO3DVAROLD TEST_11 !2017093018-!2017100100 None ALARO3DVAR with oldsurface \nALARO_EKF TEST_11 !2017093018-!2017100100 None ALARO with CANARIEKFSURFEX \nALAROEPSCOMP TEST_11 !2017093018-!2017100100 ??? ALARO EPS? \nALAROMF60 TEST_11 !2017093018-!2017100100 None ALARO with VLEV=MF_60 \nALARO_MUSC TEST_11 !2017093018-!2017100100 ALARO ALARO MUSC \nALARONH1D TEST_11 !2017093018-!2017100100 None ALARO with NH dynamics and 1-D decomposition \nALARONH2D TEST_11 !2017093018-!2017100100 None ALARO with NH dynamics and 2-D decomposition \nALARO_NONE TEST_11 !2017093018-!2017100100 None ALARO with no SFC/UA DA \nALARO_OLD TEST_11 !2017093018-!2017100100 None ALARO with old_surface \nALAROOLDMUSC TEST_11 !2017093018-!2017100100 ALARO ALARO MUSC with old_surface ","category":"page"},{"location":"Evaluation/HarmonieTestbed/#Testbed-domains-1","page":"Testbed","title":"Testbed domains","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#The-playfile-1","page":"Testbed","title":"The playfile","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The playfile used for the testbed is  testbed.tdf. Here each configuration is defined with a trigger, a task to create and one to follow the child experiments.  Configurations inluded are listed in the TESTBEDLIST environment variable in ecf/configexp.h ","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":" TESTBED_LIST=\"ALADIN ALADIN_3DVAR AROME\"","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"If the child experiment fails the Followexp task will also fail. When the child experiment problem has been corrected and the task restarted, the follow task should be restarted. When, finally, the child experiment is finished the test family will be completed and next test case will be triggered. We may choose to let the testbed launch a new experiment if the current child experiment fails. This is done by setting in ecf/configexp.h  ","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":" TESTBED_CONT_ON_FAILURE=1","category":"page"},{"location":"Evaluation/HarmonieTestbed/#Input-data-1","page":"Testbed","title":"Input data","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The standard testbed configuration is run over several. The domain and resolution is chosen to be computationally cheap and not to give meteorologically interesting and meaningful results. Input data for running the testbed is ECMWF boundaries, observations, background error statistics and climate files. The latest data may be found  on cca:/scratch/ms/spsehlam/hlam/hmhome/somerecenttestbedexperiment/testbed_data and the data included is the following:","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"ECMWF boundaries for the tested periods\nObservations\nBackground errors\nClimate files\nForcing data for nested experiments","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"Download the data to your machine and put it on the default location $HM_REV/testbed_data or define your location in Harmonie_testbed.pl. If you wish to test the climate generation you simple redefine the location of the climate files or remove the existing ones in the climate directory of the testbed. The testbed data typically includes the following:","category":"page"},{"location":"Evaluation/HarmonieTestbed/#Starting-the-testbed-1","page":"Testbed","title":"Starting the testbed","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The testbed experiment is setup as any normal experiment with","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"Harmonie setup -r REVISION -h HOST","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The testbed is launched by","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"Harmonie testbed ","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"Before you start the testbed you should define your reference experiment. The reference experiment is picked automatically as an experiment with the same name but with lower revision number. The reference experiment can also be defined by the by setting REFEXP in ecf/config_exp.h  as the full path to another testbed experiment:","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"\r\nexport REFEXP=/scratch/ms/spsehlam/hlam/hm_home/test_37h12\r\n","category":"page"},{"location":"Evaluation/HarmonieTestbed/#Evaluation-of-the-result-1","page":"Testbed","title":"Evaluation of the result","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"At the end of each testbed run the results are compared to a reference experiment using the script Testbed_comp[scource:scr/Testbedcomp Testbedcomp]. The script uses xtool to check the numerical difference for the following output:","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"ECMWF input data\nclimate files\nInterpolated boundary files\nOutput forecast files in FA format\nOutput forecast files in GRIB format\nvfld/vobs files","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"In addition the internal consistency is checked by comparing runs with ","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"1D vs 2D decomposition\nEPS control vs a deterministic run\nRun with and without IO-server","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"The choice of internal consistency tests reflects the history of problems and inconsistencies encountered.","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"\r\nHARMONIE testbed results from ecgb-vecf\r\nSat Nov 16 20:41:27 GMT 2019\r\n\r\nConfiguration: cca.gnu\r\n\r\nCompare experiment ecgb_cca_testbed_develop_gnu_6147 and ecgb_cca_testbed_develop_gnu_6146\r\n\r\nCheck:ecmwf_bd\r\n  Output grib file summary (differ/missing/total) 0/0/37\r\n   comparison took 164 seconds\r\n Configuration ecmwf_bd is equal\r\n\r\nCheck:climate\r\n  Output internal file summary (differ/missing/total) 0/0/52\r\n   comparison took 34 seconds\r\n Configuration climate is equal\r\n\r\nCheck:AROME_3DVAR\r\n  Output internal file summary (differ/missing/total) 0/0/36\r\n   comparison took 79 seconds\r\n  Output grib file summary (differ/missing/total) 0/0/96\r\n   comparison took 91 seconds\r\n  vfld/vobs file summary (differ/missing/total) 0/0/36\r\n   comparison took 4 seconds\r\n Configuration AROME_3DVAR is equal\r\n\r\n ...\r\n\r\nCompare AROME_BD_ARO and AROME_BD_ARO_IO_SERV\r\n No differences found\r\n   comparison took 423 seconds\r\n\r\nTestbed comparison complete\r\n\r\n[ Status: OK]\r\n\r\n For more details please check /scratch/ms/spsehlam/hlam/hm_home/ecgb_cca_testbed_develop_gnu_6147/testbed_comp_6147.log_details\r\n","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"All the logs from any testbed experiment are posted to the testbed mailing list [https://hirlam.org/pipermail/testbed]. The test returns three different status signals","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"OK means that all configurations reproduces the result of your reference experiment.\nOK, BUT NO COMPARISON means that the suit run through but that there was nothing to compare with\nFAILED means that the internal comparisons failed\nDIFFER means that one more configurations differ from your reference experiment\nFAILED and DIFFER is a combination of the last two","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"In addition to the summary information detailed information can be found in the archive about the art of the difference.","category":"page"},{"location":"Evaluation/HarmonieTestbed/#When-to-use-the-testbed-1","page":"Testbed","title":"When to use the testbed","text":"","category":"section"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"It is recommended to use the testbed when adding new options or make other changes in the configurations. If your new option is not activated the result compared with the reference experiment should be the same, if not you have to start debugging. When changing things for one configuration it's easy to break other ones. In such cases the testbed is a very good tool make sure you haven't destroyed anything.","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"","category":"page"},{"location":"Evaluation/HarmonieTestbed/#","page":"Testbed","title":"Testbed","text":"Last modified ","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/VerticalGrid?action=edit\"","category":"page"},{"location":"VerticalGrid/#HARMONIE-Vertical-Model-Level-Definitions-1","page":"Vertical Grid","title":"HARMONIE Vertical Model Level Definitions","text":"","category":"section"},{"location":"VerticalGrid/#**HARMONIE-vertical-coordinate**-1","page":"Vertical Grid","title":"HARMONIE vertical coordinate","text":"","category":"section"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"HARMONIE model, similar to that of HIRLAM, is constructed for a general pressure based and terrain following vertical coordinate n(p,p,,s,,), where","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"n(0,P,,s,,) = 0 and n(p,,s,,,p,,s,,) = 1","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"The formulation corresponds to the ECMWF hybrid system. The model is formulated for a spherical coordinate system (lamda, theta), but in the code two metric coefficients (h,,x,,,h,,y,,) have been introduced. This is done to prepare the model for any orthogonal coordinate system or map projection with axes (x,y). ","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"To represent the vertical variation of the dependent variables (U, V, T and Q), the atmosphere is divided into \"nlev\" layers. These layers are defined by the pressures at the interfaces between them (the `half-levels'). From the general expression","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"p,,k+1/2,, = A,,k+1/2,,(n) + B,,k+1/2,,(n) * p,,s,,(x,y)          for k=0,1,...,nlev","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"the vertical surfaces for half-levels are defined. Pure pressure surfaces are obtained for B=0 and pure sigma surfaces for A=0. `full-level' pressure associated with each model level (middle of two half layers) is then determined accordingly.","category":"page"},{"location":"VerticalGrid/#**Definition-of-model-levels-in-HARMONIE**-1","page":"Vertical Grid","title":"Definition of model levels in HARMONIE","text":"","category":"section"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"The script Vertical_levels.pl contains definition of vertical levels that have been used in the HIRLAM community for research and/or operational purposes. Currently the default model setup defines 65-level structure as derived by Per Unden, SMHI. Model level definitions for commonly used vertical structures in HARMONIE are listed below.","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"FourtyLevel: HIRLAM_40 model levels (same as Hirlam 6.2.1, Nov 2003 - HIRLAM 7.0, 2006 )\nSixtyLevel: HIRLAM-60 model levels (same as Hirlam 7.1, March 2007 - 2012 )\nMF_60: MF-60 model levels (same as Meteo France AROME since 2010 )\nSixtyfiveLevel: 65 model levels (same as Hirlam 7.4, March 2012 - )\nother levels: Prague87, MF70, 40 (ALADIN-40), ECMWF_60.","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"Note that VLEV is the name of the set of A/B coefficients defining your levels set in ecf/configexp.h . There are e.g. more than one definition for 60 levels. To print the levels just run  `scr/Verticallevels.pl `","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"Usage: scr/Vertical_levels.pl [VLEV PRINT_OPTION] where:","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"VLEV: name of your level definition\nPRINT_OPTION=AHALF: print A coefficients for VLEV\nPRINT_OPTION=BHALF: print B coefficients for VLEV\nPRINT_OPTION=NLEV: print number of levels for VLEV\nPRINT_OPTION=NRFP3S: print NRFP3S namelist values for VLEV","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"For reference, we provide links detailing structure of the ECMWF 62 level (ensemble and seasonal forecast),  91 level (deterministic forecast) and the 137-level deterministic forecast (starting June 25 2013, 38r2)]","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"When performing HARMONIE experiment, users can select vertical levels by changing VLEV in the script config_exp.h. If a non-standard level number is to be chosen, the script Vertical_levels.pl needs to be edited to add layer definition.","category":"page"},{"location":"VerticalGrid/#**Define-new-eta-levels**-1","page":"Vertical Grid","title":"Define new eta levels","text":"","category":"section"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"A brief description and some code on how to create new eta levels can be found here.","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"There is also an interactive tool that can help you in creating a new set of levels.","category":"page"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"The method is based on a program by Pierre Bénard, Meteo France, that is described in this gmapdoc article.","category":"page"},{"location":"VerticalGrid/#**Relevant-corresponding-data-set-for-different-vertical-structure**-1","page":"Vertical Grid","title":"Relevant corresponding data set for different vertical structure","text":"","category":"section"},{"location":"VerticalGrid/#","page":"Vertical Grid","title":"Vertical Grid","text":"HARMONIE 3D-VAR and 4DVAR upper air data assimilation needs background error structure function for each given vertical layer structure. It is noted that the structure function data included in the reference HARMONIE repository is only useful for reference configuration. Users that runs 3DVAR/4DVAR are strongly recommended to derive proper structure function data following instructions in the HIRLAM wiki using own data archive to avoid improper use of structure function.","category":"page"},{"location":"VerticalGrid/#[HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Vertical Grid","title":"HARMONIE System Documentation","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ObservationPreprocessing/Cope?action=edit\"","category":"page"},{"location":"ObservationPreprocessing/Cope/#ODB-creation-(COPE)-1","page":"Cope","title":"ODB creation (COPE)","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#General-Description-1","page":"Cope","title":"General Description","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"HIRLAM, ALADIN and Météo France are working together with ECMWF to develop COPE, Continuous Observation Pre-processing Environment, to replace !Oulan/Bator (and BUFR2ODB at ECMWF), to improve the pre-processing of observations for use in NWP. COPE developments are made in ECMWF's git repository. A COPE 40h1 HARMONIE branch has been created to test COPE in the HARMONIE framework.","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"Here are some links that may be of interest:","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"https://software.ecmwf.int/wiki/display/COPE/COPE: COPE wiki (restricted access)\nhttp://www.rclace.eu/File/DataAssimilation/2014/201406COPEReadingreport.pdf: Report on the COPE technical meeting, Alena Trojáková.  ECMWF, Reading 9-12, June 2014\nhttp://www.cnrm.meteo.fr/aladin/IMG/pdf/copeovervieweoinwhelan.pdf: Overview of COPE, Eoin Whelan. Joint 24th ALADIN Workshop & HIRLAM All Staff Meeting 2014, 7-11 April 2014, Romania.","category":"page"},{"location":"ObservationPreprocessing/Cope/#\"Support\"-software-packages-1","page":"Cope","title":"\"Support\" software packages","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"This section provides a step-by-step set of instruction on how to compile COPE and COPE related software.","category":"page"},{"location":"ObservationPreprocessing/Cope/#Preparation-1","page":"Cope","title":"Preparation","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"These instructions rely on the ODB API source code bundle odbapibundle-0.15.2-Source.tar.gz and emoslib libemos-4.4.2-Source.tar.gz. The default install location for software packages is in HOME/metapp/.","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"mkdir -p $HOME/test_ecmwf_releases\r\nmkdir -p $HOME/test_ecSource\r\ncp odb_api_bundle-0.15.2-Source.tar.gz $HOME/test_ecmwf_releases/\r\ncp libemos-4.4.2-Source.tar.gz $HOME/test_ecmwf_releases/\r\ncd $HOME/test_ecmwf_releases\r\ngunzip odb_api_bundle-0.15.2-Source.tar.gz\r\ntar -xvf odb_api_bundle-0.15.2-Source.tar\r\ngunzip libemos-4.4.2-Source.tar.gz\r\ntar -xvf libemos-4.4.2-Source.tar","category":"page"},{"location":"ObservationPreprocessing/Cope/#ecBuild-(2.4.0)-1","page":"Cope","title":"ecBuild (2.4.0)","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"ecBuild is a set of cmake macros used by other ECMWF software packages.","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"cd $HOME/test_ecmwf_releases/odb_api_bundle-0.15.2-Source/ecbuild\r\nmkdir build\r\ncd build/\r\ncmake .. -DCMAKE_INSTALL_PREFIX=$HOME/metapp/ecbuild/2.4.0/gnu/\r\nmake\r\nmake check\r\nmake install","category":"page"},{"location":"ObservationPreprocessing/Cope/#eckit-(0.14.0)-1","page":"Cope","title":"eckit (0.14.0)","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"cd $HOME/test_ecmwf_releases/odb_api_bundle-0.15.2-Source/eckit\r\nmkdir build\r\ncd build/\r\ncmake .. -DCMAKE_INSTALL_PREFIX=$HOME/metapp/eckit/0.14.0/gnu/ -DCMAKE_MODULE_PATH=$HOME/metapp/ecbuild/2.4.0/gnu/share/ecbuild/cmake\r\nmake -j 4\r\nmake check\r\nmake install","category":"page"},{"location":"ObservationPreprocessing/Cope/#metkit-(0.3.0)-1","page":"Cope","title":"metkit (0.3.0)","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"cd $HOME/test_ecmwf_releases/odb_api_bundle-0.15.2-Source/metkit\r\nmkdir build\r\ncd build/\r\ncmake .. -DCMAKE_INSTALL_PREFIX=$HOME/metapp/metkit/0.3.0/gnu/ -DCMAKE_MODULE_PATH=$HOME/metapp/ecbuild/2.4.0/gnu/share/ecbuild/cmake/ -DECKIT_PATH=$HOME/metapp/eckit/0.14.0/gnu/\r\nmake -j 4\r\nmake check\r\nmake install","category":"page"},{"location":"ObservationPreprocessing/Cope/#libemos-(4.4.2)-1","page":"Cope","title":"libemos (4.4.2)","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"cd $HOME/test_ecmwf_releases/libemos-4.4.2-Source\r\nmkdir build\r\ncd build/\r\ncmake .. -DCMAKE_INSTALL_PREFIX=$HOME/metapp/libemos/4.4.2/gnu -DGRIB_API_PATH=PATH_TO_GRIBAPI\r\nmake\r\nmake check\r\nmake install","category":"page"},{"location":"ObservationPreprocessing/Cope/#\"Main\"-software-packages-1","page":"Cope","title":"\"Main\" software packages","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"These instructions assume you have access to the ODB-API and COPE ECMWF git repositories. The default install location for software packages is in HOME/metapp/.","category":"page"},{"location":"ObservationPreprocessing/Cope/#odb-(40t1.01)-1","page":"Cope","title":"odb (40t1.01)","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"ECMWF maintain a \"standalone\" version of ODB software that is compiled with cmake. A 40t1 tag, 40t1.01, has been created to support the flavour of ODB used by harmonie-40h1.1.","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"cd $HOME/test_ecmwf_releases\r\ngit clone https://dui@software.ecmwf.int/stash/scm/odb/odb.git\r\ncd $HOME/test_ecmwf_releases/odb\r\ngit pull\r\ngit archive --format=tar -o $HOME/test_ecSource/odb-40t1.01-Source.tar --prefix=odb-40t1.01/ 40t1.01\r\ncd $HOME/test_ecSource\r\ntar -xvf odb-40t1.01-Source.tar\r\ncd odb-40t1.01/\r\nmkdir build\r\ncd build/\r\ncmake .. -DCMAKE_INSTALL_PREFIX=$HOME/metapp/odb/40t1.01/gnu/ -DCMAKE_MODULE_PATH=$HOME/metapp/ecbuild/2.4.0/gnu/share/ecbuild/cmake/ -DODB_SCHEMAS=\"ECMA;CCMA\"\r\nmake -j 8\r\nmake check\r\nmake install","category":"page"},{"location":"ObservationPreprocessing/Cope/#ODB-API-(0.15.4)-1","page":"Cope","title":"ODB API (0.15.4)","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"ODB API is a software developed at ECMWF for encoding and processing of observational data. It includes a SQL filtering and statistics engine, command line tools and APIs for C/C++, Fortran and Python. ODB API works with data format used in ECMWF observational feedback archive. Development of ODB API has been partially funded by the Met Office. More details here: https://software.ecmwf.int/wiki/display/ODBAPI/ODB+API+Home","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"ODB API provides is required by COPE as well as for ODB2 to ODB1 conversion. ","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"cd $HOME/test_ecmwf_releases\r\ngit clone https://dui@software.ecmwf.int/stash/scm/odb/odb_api.git\r\ncd $HOME/test_ecmwf_releases/odb_api\r\ngit pull\r\ngit archive --format=tar -o $HOME/test_ecSource/odb_api-0.15.4-Source.tar --prefix=odb_api-0.15.4/ 0.15.4\r\ncd $HOME/test_ecSource\r\ntar -xvf odb_api-0.15.4-Source.tar\r\ncd odb_api-0.15.4/\r\nmkdir build\r\ncd build/\r\ncmake .. -DCMAKE_INSTALL_PREFIX=$HOME/metapp/odb_api/0.15.4/gnu/ -DCMAKE_MODULE_PATH=$HOME/metapp/ecbuild/2.4.0/gnu/share/ecbuild/cmake/  -DECKIT_PATH=$HOME/metapp/eckit/0.14.0/gnu/ -DMETKIT_PATH=$HOME/metapp/metkit/0.3.0/gnu -DENABLE_MIGRATOR=ON -DODB_PATH=$HOME/metapp/odb/40t1.01/gnu -DENABLE_FORTRAN=ON -DENABLE_PYTHON=ON -DENABLE_NETCDF=ON\r\nmake -j 8\r\nmake check\r\nmake install","category":"page"},{"location":"ObservationPreprocessing/Cope/#b2o-(40t1.01)-1","page":"Cope","title":"b2o (40t1.01)","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"b2o is a library and command line tool to extract ODB data from BUFR files. A 40t1 tag, 40t1.01, has been created to support the flavour of ODB used by harmonie-40h1.1.","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"cd $HOME/test_ecmwf_releases\r\ngit clone https://dui@software.ecmwf.int/stash/scm/cope/b2o.git\r\ncd b2o\r\ngit pull\r\ngit archive --format=tar -o $HOME/test_ecSource/b2o-40t1.01-Source.tar --prefix=b2o-40t1.01/ 40t1.01\r\ncd $HOME/test_ecSource\r\ntar -xvf b2o-40t1.01-Source.tar\r\ncd b2o-40t1.01/\r\nmkdir build\r\ncd build/\r\ncmake .. -DCMAKE_INSTALL_PREFIX=$HOME/metapp/b2o/40t1.01/gnu/ -DCMAKE_MODULE_PATH=$HOME/metapp/ecbuild/2.4.0/gnu/share/ecbuild/cmake/ -DLIBEMOS_PATH=$HOME/metapp/libemos/4.4.2/gnu/ -DECKIT_PATH=$HOME/metapp/eckit/0.14.0/gnu/ -DODB_API_PATH=$HOME/metapp/odb_api/0.15.4/gnu\r\nmake -j 4\r\nmake check\r\nmake install","category":"page"},{"location":"ObservationPreprocessing/Cope/#COPE-1","page":"Cope","title":"COPE","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"These instructions are based on building the develop branch of COPE. If you wish to use a tagged version you must use version 0.5.3 or greater.","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"cd $HOME/test_ecmwf_releases\r\ngit clone https://dui@software.ecmwf.int/stash/scm/cope/cope.git\r\ncd $HOME/test_ecmwf_releases/cope\r\ngit pull\r\nmkdir build\r\ncd build/\r\ncmake .. -DCMAKE_INSTALL_PREFIX=$HOME/metapp/cope/develop/gnu -DCMAKE_MODULE_PATH=$HOME/metapp/ecbuild/2.4.0/gnu/share/ecbuild/cmake/ -DECKIT_PATH=$HOME/metapp/eckit/0.14.0/gnu/ -DODB_API_PATH=$HOME/metapp/odb_api/0.15.4/gnu -DB2O_PATH=$HOME/metapp/b2o/40t1.01/gnu -DCMAKE_PREFIX_PATH=$HOME/metapp/libemos/4.4.2/gnu/\r\nmake -j 4\r\n# make check ## BROKEN DUE TO CHANGES TO ODB SCHEMA IN THIS BRANCH\r\nmake install","category":"page"},{"location":"ObservationPreprocessing/Cope/#COPE-in-HARMONIE-system-1","page":"Cope","title":"COPE in HARMONIE system","text":"","category":"section"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"COPE is currently only available in branches/harmonie40h1cope and has only been tested on a local Linux server.","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"The use of COPE in HARMONIE relies on ODB-API, b2o and COPE itself. ","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"ODB-API tools must be included in PATH\nThe ECMA.sch used by COPE is maintained in the b2o version described above. \n\"mfvertcotype\" specific changes are included in the feature/mfvertcotype branch of COPE\nscr/Cope includes the setting of the following environment variables which rely on COPEDIR and B2ODIR. These can be set in your Env_system file.","category":"page"},{"location":"ObservationPreprocessing/Cope/#","page":"Cope","title":"Cope","text":"export COPE_DEFINITIONS_PATH=${COPE_DIR}/share/cope\r\nexport ODB_SCHEMA_FILE=${B2O_DIR}/share/b2o/ECMA.sch\r\nexport ODB_CODE_MAPPINGS=${B2O_DIR}/share/b2o/odb_code_mappings.dat\r\nexport ODBCODEMAPPINGS=${B2O_DIR}/share/b2o/odb_code_mappings.dat","category":"page"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/RadarData?action=edit\"","category":"page"},{"location":"RadarData/#Assimilation-of-Radar-Data-1","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"","category":"section"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"This documentation outlines how to retrieve, process and assimilate HDF5 radar data","category":"page"},{"location":"RadarData/#HARMONIE-compilation-1","page":"Assimilation of Radar Data","title":"HARMONIE compilation","text":"","category":"section"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"HIRLAM have made code changes to BATOR to allow the direct reading of HDF5 radar data and conversion to ODB suitable for use in the HARMONIE data assimilation system. If you wish to use these changes you must compile HARMONIE with support for HDF5. This requires the addition of -DUSE_HDF5 to the FDEFS in your makeup config file as well has adding hdf5 to EXTMODS. source:tags/harmonie-38h1.2/util/makeup/config.cca.gnu is an example of a makeup config file ","category":"page"},{"location":"RadarData/#Format-1","page":"Assimilation of Radar Data","title":"Format","text":"","category":"section"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"The BATOR code assumes the HDF5 radar data being read uses the OPERA Data Information Model (ODIM). See http://www.eumetnet.eu/sites/default/files/OPERA2014O4ODIM_H5-v2.2.pdf for further information.","category":"page"},{"location":"RadarData/#Data-retreival-1","page":"Assimilation of Radar Data","title":"Data retreival","text":"","category":"section"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"Local HDF5 ODIM radar data can be used or, alternatively, can be retrieved from a BALTRAD ftp site.","category":"page"},{"location":"RadarData/#Data-processing-1","page":"Assimilation of Radar Data","title":"Data processing","text":"","category":"section"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"The HARMONIE script system requires that the OPERA HDF5 data files be stored in RADARDIR (defined in ecf/configexp.h ) and have a file name using the format: {HDFID}qcvol_DATET{HH}00.h5 where: ","category":"page"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"HDFID is a 5 digit OPERA radar identifier\nDATE is the date\nHH is the hour","category":"page"},{"location":"RadarData/#Common-pitfalls-1","page":"Assimilation of Radar Data","title":"Common pitfalls","text":"","category":"section"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"Forgetting to add -DUSE_HDF5 correctly to your config file\nIncorrect RADARDIR\nIncorrect file names\nIncorrect format entered in refdata - BATOR is quite strict about how it reads the information in refdata:","category":"page"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"02918zh  HDF5     radarv           20100808 03 ","category":"page"},{"location":"RadarData/#Further-reading-1","page":"Assimilation of Radar Data","title":"Further reading","text":"","category":"section"},{"location":"RadarData/#","page":"Assimilation of Radar Data","title":"Assimilation of Radar Data","text":"Martin Ridal's radar data assimilation presentation: https://hirlam.org/trac/raw-attachment/wiki/HarmonieSystemTraining2014/Programme/MR_radarobservations.pdf","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Forecast?action=edit\"","category":"page"},{"location":"Forecast/#Harmonie-system-Documentation-1","page":"Forecast","title":"Harmonie system Documentation","text":"","category":"section"},{"location":"Forecast/#Forecast-1","page":"Forecast","title":"Forecast","text":"","category":"section"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"== Introduction","category":"page"},{"location":"Forecast/#Forecast-2","page":"Forecast","title":"Forecast","text":"","category":"section"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Forecast is the script, which initiates actual  forecast run (ALADIN/AROME/ALARO depending on FLAG and PHFLAG).","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Input parameters: none.\nData: Boundary files (ELSCF***-files). Initial file (fcstart**). If data assimilation is used, **fcstart** is the analysis file. In case of dynamical adaptation, fc_start is the first boundary file. In case of AROME, Surfex initial file (SURFXINI.lfi) is also needed (Prepinisurfex). \nNamelists: namelist templates nam/namelistfcst{FLAG}default are fetched based on FLAG and PHFLAG. The templates are completed in Forecast based on the choices of NPROCX, NPROCY (see submit.ecgb), TFLAG, OUTINT, BDINT and REDUCELFI. In case of AROME also the namelists to control SURFEX-scheme  (TEST.des and EXSEG1.nam) are needed.\nExecutables: as defined by MODEL.\nOutput: Forecast files (spectral files ICMSHALAD+***). In case of AROME, Surfex files containing the surface data (AROMOUT_*.lfi**). ","category":"page"},{"location":"Forecast/#Forecast-namelists-1","page":"Forecast","title":"Forecast namelists","text":"","category":"section"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"The current switches in the HARMONIE system (in config_exp.h) provide only very limited possibility to control the different aspects of the model. If the user wants to have more detailed control on the specific schemes etc., one has to modify the variety of the namelists options.","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"In general, the different namelist options are documented in the source code modules (e.g. src/arp/module/*.F90). Below is listed information on some of the choices.   ","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"NH-dynamics/advection/time stepping:","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"A detailed overview of the such options has been given by Vivoda (2008). ","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Upper air physics switches","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Switches related to different schemes of ALADIN/ALARO physics, yomphy.F90.\nSwitches related to physics schemes in AROME yomarphy.F90.\nSwitches to tune different aspects of physics, yomphy0.F90, yomphy1.F90, yomphy2.F90 and yomphy3.F90\nSwitches related to HIRLAM physics, yhloption.F90 and suhloption.F90.","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Initialization switch","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Initialization is controlled by namelist NAMINI/NEINI, yomini.F90.","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Horizontal diffusion switches","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Horizontal diffusion is controlled by namelist *NAMDYN/RDAMP**, yomdyn.F90. Larger the coefficient, less diffusion.","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"MPP switches","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"The number of processors in HARMONIE are given in submit.HOST. These values are transfered in to yomct0.F90 and yommp.F90.","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Surface SURFEX switches","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"The SURFEX scheme is controlled through namelist settings in surfex_namelists.pm. The different options are described here.","category":"page"},{"location":"Forecast/#Archiving-1","page":"Forecast","title":"Archiving","text":"","category":"section"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"Archiving has a two layer structure. Firstly, all the needed analysis forecast and field extract files   are stored in ARCHIVE directory by Archive_fc. This is the  place where the postprocessing step expects to find the files. ","category":"page"},{"location":"Forecast/#","page":"Forecast","title":"Forecast","text":"At ECMWF all the requested files are stored to ECFS into directory ECFSLOC by the script Archive_ECMWF","category":"page"},{"location":"Forecast/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Forecast","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Harmonie-mSMS?action=edit\"","category":"page"},{"location":"Harmonie-mSMS/#Running-Harmonie-at-ECMWF-1","page":"Running at ECMWF","title":"Running Harmonie at ECMWF","text":"","category":"section"},{"location":"Harmonie-mSMS/#Introduction-1","page":"Running at ECMWF","title":"Introduction","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"The Harmonie system runs through a number of steps to help you complete your experiment. The chain can be summarized like:","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Configure and start the experiment. This is where you define your domain, choose your settings and specify the period for your experiment.","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Once you have done this you can start the system and let it create the basic infrastructure","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Setup the necessary directories and copy the system files needed.\nCompile the binaries you need to run your experiment.\nCreate the constant climate files specifying your domain","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"With the basic setup and files in place we can proceed to the integration part where we have three loops taking care of ","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Prepare boundaries and observations\nRun assimilation and forecasts\nPost process and archive the result","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"The three different task are allowed to run ahead/after each other to get a good throughput.","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"The configuration, the full suite and the relation between different tasks is controlled by the scheduler ECFLOW which has a graphical interface ecflow_ui. This documentation describes how to get started with your first experiment. The description follows the setup at ECMWF, but your local system setup would be very similar but most likely simpler. The reference Harmonie system on ECMWF platform assumes a dual-hosts setup using ECFLOW. By default, Harmonie uses the front-end ecgb to configure and launch experiments, whereas cca is used for all computations except those for operations related to observation verification and monitoring.","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Following example shows the steps to launch an Harmonie experiment my_exp from ecgb.","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"If this is the first time to install HARMONIE on your local platform please take a look at the basic install instructions here: HarmonieSystemDocumentation/PlatformConfiguration.","category":"page"},{"location":"Harmonie-mSMS/#Before-you-start-...-1","page":"Running at ECMWF","title":"Before you start ...","text":"","category":"section"},{"location":"Harmonie-mSMS/#hirald-group-1","page":"Running at ECMWF","title":"hirald group","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"New Harmonie users will require membership of the hirald user group at ECMWF. Please contact the HIRLAM System Manager, Daniel Santos, to make this request on your behalf.","category":"page"},{"location":"Harmonie-mSMS/#SHELL-settings-1","page":"Running at ECMWF","title":"SHELL settings","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"The C shell, is no longer supported by ECMWF.  Check your shell on ecgate with:","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"echo $SHELL","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"To change your shell use the changesh command:","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"changesh","category":"page"},{"location":"Harmonie-mSMS/#Configure-your-experiment-1","page":"Running at ECMWF","title":"Configure your experiment","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Create an experiment directory under HOME/hm_home and use the master script Harmonie to set up a minimum environment for your experiment.","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"   mkdir -p $HOME/hm_home/my_exp\r\n   cd $HOME/hm_home/my_exp\r\n   ~hlam/harmonie_release/git/tags/release-43h2.1/config-sh/Harmonie setup -r ~hlam/harmonie_release/git/tags/release-43h2.1 -h ecgb-cca","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"where","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"-r tells which version to use. There are several old versions kept on ecgb. Check the directories under ~hlam/harmonie_release to see the available versions. \n-h tells which configuration files to use. At ECMWF config.ecgb-cca is the default one.\nThis would give you the default setup which currently is AROME physics with CANARI+OI_MAIN surface assimilation and 3DVAR upper air assimilations with 3h cycling on a domain covering Denmark using 2.5km horizontal resolution and 65 levels in the vertical.\nNow you can edit the basic configuration file ecf/config_exp.h to configure your experiment scenarios. Modify specifications for domain, data locations, settings for dynamics, physics, coupling host model etc. Read more about the options in here. You can also use some of the predefined configurations by calling Harmonie with the -c option:","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"   ~hlam/Harmonie setup -r PATH_TO_HARMONIE -h YOURHOST -c CONFIG -d DOMAIN","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"where CONFIG is one of the setups defined in Harmonie_configurations.pm. If you give -c with out an argument or a non existing configuration a list of configurations will be printed.","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"In some cases you might have to edit the general system configuration file, Env_system. See here for further information: HarmonieSystemDocumentation/PlatformConfiguration\nThe rules for how to submit jobs on ecgb/cca are defined in  Env_submit. See here for further information: HarmonieSystemDocumentation/PlatformConfiguration\nIf you experiment in data assimilation you might also want to change settings in scr/include.ass.","category":"page"},{"location":"Harmonie-mSMS/#Start-your-experiment-1","page":"Running at ECMWF","title":"Start your experiment","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Launch the experiment by giving start time, DTG, end time, DTGEND","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"      ~hlam/Harmonie start DTG=YYYYMMDDHH DTGEND=YYYYMMDDHH\r\n                                    # e.g., ~hlam/Harmonie start DTG=2012122400 DTGEND=2012122406","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"If successful, Harmonie will identify your experiment name and start building your binaries and run your forecast. If not, you need to examine the ECFLOW log file $HM_DATA/ECF.log. $HM_DATA is defined in your Env_system file. At ECMWF $HM_DATA=$SCRATCH/hm_home/$EXP where $EXP is your experiment name. Read more about where things happen further down.","category":"page"},{"location":"Harmonie-mSMS/#Continue-your-experiment-1","page":"Running at ECMWF","title":"Continue your experiment","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"If your experiment have successfully completed and you would like to continue for another period you should write","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"      ~hlam/Harmonie prod DTGEND=YYYYMMDDHH","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"By using prod you tell the system that you are continuing the experiment and using the first guess from the previous cycle. The start date is take from a file progress.log created in your $HOME/hm_home/my_exp directory. If you would have used start the initial data would have been interpolated from the boundaries, a cold start in other words.","category":"page"},{"location":"Harmonie-mSMS/#!Start/Restart-of-ecflow_ui-1","page":"Running at ECMWF","title":"!Start/Restart of ecflow_ui","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"To start the graphical window for ECFLOW on ecgb type","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"      ~hlam/Harmonie mon","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"The graphical window runs independently of the experiment and can be closed and restarted again with the same command. With the graphical interface you can control and view logfiles of each task. ","category":"page"},{"location":"Harmonie-mSMS/#Making-local-changes-1","page":"Running at ECMWF","title":"Making local changes","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Very soon you will find that you need to do changes in a script or in the source code. Once you have identified which file to edit you put it into the current $HOME/hm_home/my_exp directory, with exactly the same subdirectory structure as in the reference. e.g, if you want to modify a namelist setting ","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"   ~hlam/Harmonie co nam/harmonie_namelists.pm         # retrieve default namelist harmonie_namelists.pm\r\n   vi nam/harmonie_namelists.pm                        # modify the namelist","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Next time you run your experiment the changed file will be used. You can also make changes in a running experiment. Make the change you wish and rerun the InitRun task from the viewer. The !InitRun task copies all files from your local experiment directory to your working directory $HM_DATA. Once your InitRun task is complete your can rerun the task you are interested in. If you wish to recompile something you will also have to rerun the Build tasks.","category":"page"},{"location":"Harmonie-mSMS/#Directory-structure-1","page":"Running at ECMWF","title":"Directory structure","text":"","category":"section"},{"location":"Harmonie-mSMS/#ecgb-1","page":"Running at ECMWF","title":"ecgb","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"On ecgb, you can follow the progress of the runs on $SCRATCH/hm_home/my_exp","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Working directory for the current cycle under YYYYMMDD_HH\nArchived files under are in $SCRATCH/hm_home/my_exp/archive\nA YYYY/MM/DD/HH structure for per cycle data is used\nAll logfiles under archive/log   \nOn ecgb log files per task are found under /cca/perm/ms/$COUNTRY/$USER/HARMONIE/my_exp. All logfiles are also gathered in html files named like e.g. HM_Date_YYYYMMDDHH.html which are archived in $SCRATCH/hm_home/my_exp/archive/log on ecgb.\nVerification data available on the permanent disk /hpc/perm/$GROUP/$USER/HARMONIE/archive/$EXP/archive/extract     ","category":"page"},{"location":"Harmonie-mSMS/#cca-1","page":"Running at ECMWF","title":"cca","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"More complete results and the main data are available on cca:$SCRATCH/hm_home/my_exp. Under these directories you will find:","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"All binaries under bin\nIFS libraries, object files and source code under lib/src if you build with makeup\nScripts, config files, ecf and suite definitions under lib/\nUtilities such as makeup, gl_grib_api or oulan under lib/util\nClimate files under climate\nWorking directory for the current cycle under YYYYMMDD_HH\nIf an experiment fails it is useful to check the IFS log file, NODE.001_01, in the working directory of the current cycle ( $HM_DATA/YYYYMMDD_HH ). The failed job will be in a directory called something like Failedthisjob.\nArchived files under archive\nA YYYY/MM/DD/HH structure for per cycle data\nICMSHHARM+NNNN and ICMSHHARM+NNNN.sfx are atmospheric and surfex forecast output files\nVerification input data under extract. This is also stored on the permanent disk /perm/$GROUP/$USER/HARMONIE/archive/$EXP/archive/extract","category":"page"},{"location":"Harmonie-mSMS/#ECFS-1","page":"Running at ECMWF","title":"ECFS","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Since the disks on cca/ecgb are cleaned regularly we need to store data permanently on ECFS, the EC file system, as well. There are two options for ECFS, ectmp and ec. The latter is a permanent storage and first one is cleaned after 90 days. Which one you use is defined by the ECFSLOC variable. To view your data type e.g.","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":" els ectmp:/$USER/harmonie/my_exp","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"The level of archiving depends on ARSTRATEGY in ecf/config_exp.h . The default setting will give you one YYYY/MM/DD/HH structure per cycle data containing:\nSurface analysis, ICMSHANAL+0000[.sfx]\nAtmospheric analysis result MXMIN1999+0000\nBlending between surface/atmospheric analysis and cloud variable from the first guess LSMIXBCout\nICMSHHARM+NNNN and ICMSHHARM+NNNN.sfx are atmospheric and surfex forecast model state files\nPFHARM* files produced by the inline postprocessing\nICMSHSELE+NNNN.sfx are surfex files with selected output\nGRIB files for fullpos and surfex select files\nLogfiles in a tar file logfiles.tar\nObservation database and feedback information in odb_stuff.tar.\nExtracted files for obsmon in sqlite.tar\nClimate files are stored in the climate directory\nOne directory each for  vfld and vobs data respectively for verification data","category":"page"},{"location":"Harmonie-mSMS/#Cleanup-of-old-experiments-1","page":"Running at ECMWF","title":"Cleanup of old experiments","text":"","category":"section"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Once you have complete your experiment you may wish to remove code, scripts and data from the disks. Harmonie provides some simple tools to do this. First check the content of the different disks by","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":" Harmonie CleanUp -ALL","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"Once you have convinced yourself that this is OK you can proceed with the removal.","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":" Harmonie CleanUp -ALL -go ","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"If you would like to exclude the data stored on e.g ECFS ( at ECMWF ) or in more general terms stored under HM_EXP ( as defined in Env_system ) you run ","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":" Harmonie CleanUp -d","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"to list the directories intended for cleaning. Again, convince yourself that this is OK and proceed with the cleaning by","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":" Harmonie CleanUp -d -go","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"NOTE that these commands may not work properly in all versions. Do not run the removal before you're sure it's OK","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"You can always remove the data from ECFS directly by running e.g.","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":" erm -R ec:/YOUR_USER/harmonie/EXPERIMENT_NAME \r\n or\r\n erm -R ectmp:/YOUR_USER/harmonie/EXPERIMENT_NAME ","category":"page"},{"location":"Harmonie-mSMS/#","page":"Running at ECMWF","title":"Running at ECMWF","text":"For more information about cleaning with Harmonie read here\nFor more information about the ECFS commands read here","category":"page"},{"location":"Harmonie-mSMS/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Running at ECMWF","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/ObservationPreprocessing/Oulan?action=edit\"","category":"page"},{"location":"ObservationPreprocessing/Oulan/#OBSOUL-creation:-Oulan-1","page":"Oulan","title":"OBSOUL creation: Oulan","text":"","category":"section"},{"location":"ObservationPreprocessing/Oulan/#General-Description-1","page":"Oulan","title":"General Description","text":"","category":"section"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"The pre-processing step creates ODB (Observational Data Base) from various observation data files possibly in different formats.","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"Software: The programs used for pre-processing (Shufflebufr, oulan and BATOR) are not part of the IFS code. oulan is software developed at Météo France to extract observations from their local database (BDM). The output of oulan (OBSOUL) is one of the inputs of BATOR. BATOR is also software developed at Météo France to generate the ODB (Observational !DataBase) database for the ARPEGE/ALADIN/HARMONIE analysis system. ODB is a tailor made database software developed at ECMWF to manage very large observational data volumes assimilated in the IFS 4DVAR system, and to enable flexible post-processing of this data (Sami Saarinen, 2006). We use oulan to generate an OBSOUL file from different BUFR files (note you can easily change the oulan program to handle data in different format than BUFR. For example in OPLACE data processing some files are in netCDF format). OBSOUL file is an ASCII formatted file, the content of which is similar to that of the CMA (Central Memory Array, packing format actually in use in the HIRLAM data assimilation system). Our version of ouland is placed under “util” directory in the repository. HARMONIE BATOR originates from the MF export-pack. The figure bellow describes the mechanism of the observation pre-processing in HARMONIE DA. To sum it up, !ShuffleBufr splits different observations into BUFR files, then oulan creates the OBSOUL file, and BATOR creates the ODB file using satellite BUFR/GRIB/BIN files and the OBSOUL one.\nCompilation: oulan, Shufflebufr are compiled using gmakpack or makeup.\nScripts: Oulan\nInput/output\noulan  input: BUFR files; output: the OBSOUL file in ASCII format","category":"page"},{"location":"ObservationPreprocessing/Oulan/#!ShuffleBufr-1","page":"Oulan","title":"!ShuffleBufr","text":"","category":"section"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"!ShuffleBufr splits different observations into separate BUFR files according the IFS observation type/sub-type definition. Some of them (essentially those of conventional observations) are then fed to OULAN; the others go directly into BATOR.","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"    PROGRAM SHUFFLEBUFR\r\n    Split and shuffle BUFR file into  specific BUFR files for OULAN\r\n  \r\n    Usage: SHUFFLEBUFR -i <bufr_file> [-s1|-s2|-s3]  [-a] [-r]\r\n  \r\n           -s1 : Synop ship will be extracted in <synop>\r\n           -s2 : Synop ship will be extracted in <buoy>\r\n           -s3 : Synop ship will be extracted in <ship>\r\n  \r\n           Nota Bene: If -s1,-s2 or -s3 are not specified\r\n                      synop_ship will not be extracted\r\n  \r\n           -a  : Extracts ATOVS in files amsua and amsub\r\n  \r\n           -r  : Extracts also record messages (synop)","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"The splitting is done with the following command (BUFRFILE is a file containing all observations) in the Oulan script:","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"      $BINDIR/ShuffleBufr -i ${BUFRFILE} -s3 -a ","category":"page"},{"location":"ObservationPreprocessing/Oulan/#oulan-1","page":"Oulan","title":"oulan","text":"","category":"section"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"oulan reads (primarily conventional observation) BUFR data and converts them into ASCII format OBSOUL files. Note, we can make observation selection in oulan. More details about how to do data selection can be found here (Randriamampianina, ALADIN/HIRLAM Workshop 2005)","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"namelist description: ","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"NADIRS \nALANZA=90., If LZONEA is true then only extract observations south of 90N\nALASZA=0., If LZONEA is true then only extract observations north of 0\nALOEZA=-180., If LZONEA is true then only extract observations west of 180W\nALOOZA=180., If LZONEA is true then only extract observations west of 180E\nLNEWSYNOPBUFR=.FALSE., Process new format BUFR SYNOP experimental\nLNEWSHIPBUFR=.FALSE., Process new format BUFR SHIP experimental\nLNEWBUOYBUFR=.FALSE., Process new format BUFR BUOY experimental\nLNEWTEMPBUFR=.FALSE., Process new format BUFR TEMP experimental\nLACAR=.TRUE., Process ACARS BUFR data\nLAIREP=.TRUE., Process AIREP BUFR data\nLAMDAR=.TRUE., Process AMDAR BUFR data\nLBUOY=.TRUE., Process BUOY BUFR data\nLEUROPROFIL=.FALSE., Process European Profiler BUFR data\nLPILOT=.TRUE., Process PILOT BUFR data\nLRH2Q=.FALSE., Extract 2m RH from SYNOP, BUOY and TEMP BUFR data\nLSHIP=.TRUE., Process SHIP BUFR data\nLSYNOP=.TRUE., Process SYNOP BUFR data\nLTEMP=.TRUE., Process TEMP BUFR data\nLTEMPDROP=.TRUE., Process DROPTEMP BUFR data\nLTEMPSHIP=.TRUE., Process TEMPSHIP BUFR data\nLTOVSAMSUA=.FALSE., Process AMSUA data\nLTOVSAMSUB=.FALSE., Process AMSUB data\nLTOVSHIRS=.FALSE., Process HIRS data\nLZONEA=.TRUE., Switch to extract data in defined lat-lon domain (N,S,E,W)\nNDATE=DDATE, OBSOUL Date\nNDIFFM1=30, Define analysis window (T-NDIFFM1)\nNDIFFM2=300, Define analysis window (T-NDIFFM2)\nNDIFFP1=30, Define analysis window (T+NDIFFP1)\nNDIFFP2=259, Define analysis window (T+NDIFFP2)\nNINIT=0, flag used by oulan to prevent writing if problem is found\nNRESO=HHOUR, OBSOUL Hour\nNANBOB Namelist to define number of observations to be extracted\nNBACAR=750000, Number of ACAR obs\nNBAIREP=750000, Number of AIREP obs\nNBAMDAR=750000, Number of AMDAR obs\nNBBUOY=  4000, Number of BUOY obs\nNBEUROPROFIL= 15000, Number of European profiler obs\nNBPILOT=  2000, Number of PILOT obs\nNBSHIP= 30000, Number of SHIP obs\nNBSYNOP= 60000, Number of SYNOP obs\nNBTEMP=  2000, Number of Land TEMP obs (since r14078)\nNBTEMPDROP=  1000, Number of DROPTEMP obs (since r14078)\nNBTEMPSHIP=  1000, Number of Ship TEMP obs (since r14078)\nNBTOVSAMSUA= 80000, Number of AMSUA obs\nNBTOVSAMSUB= 80000, Number of AMSUB obs\nNBTOVSHIRS=  8000, Number of HIRS obs","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"make a namelist","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"  NAMELIST=$WRK/$WDIR/namelist_oulan\r\n  Get_namelist oulan $NAMELIST\r\n  sed -e \"s/DDATE/$SDATE/\" \\\r\n      -e \"s/HHOUR/$SHOUR/\"\r\n      -e \"s/SALOOZA/$OULWEST/\"  \\\r\n      -e \"s/SALANZA/$OULNORTH/\"  \\\r\n      -e \"s/SALOEZA/$OULEAST/\"  \\\r\n      -e \"s/SALASZA/$OULSOUTH/\" \\\r\n      -e \"s/SLNEWSYNOPBUFR/$SLNEWSYNOPBUFR/\" \\\r\n      -e \"s/SLNEWSHIPBUFR/$SLNEWSHIPBUFR/\" \\\r\n      -e \"s/SLNEWBUOYBUFR/$SLNEWBUOYBUFR/\" \\\r\n      -e \"s/SLNEWTEMPBUFR/$SLNEWTEMPBUFR/\" \\\r\n      ${NAMELIST} >NAMELIST","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"run oulan","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"    $BINDIR/oulan ","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"process GNSS data. If GNSS_OBS is set to 1 then GNSS observations are added to the OBSOUL file and whitelisting is carried out using PREGPSSOL","category":"page"},{"location":"ObservationPreprocessing/Oulan/#New-BUFR-templates-1","page":"Oulan","title":"New BUFR templates","text":"","category":"section"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"Valid for HARMONIE 40h1 and later","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"The use of new format (GTS WMO) BUFR is controlled in scr/include.ass by LNEWSYNOPBUFR, LNEWSHIPBUFR, LNEWBUOYBUFR, LNEWTEMPBUFR (set to 0 or 1). These environment variables control namelist settings in the Oulan script. GTS and ECMWF BUFR were used to guide the code changes so Oulan assumes either \"flavour\" of BUFR. Local changes may be required if your locally produced BUFR, in particular section 1 data sub-type settings, do not follow WMO and/or ECMWF practices.","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"The ECMWF wiki contains updates regarding the quality of the new BUFR HR observations. See the following ECMWF wiki pages for furher information:","category":"page"},{"location":"ObservationPreprocessing/Oulan/#","page":"Oulan","title":"Oulan","text":"https://software.ecmwf.int/wiki/display/TCBUF/TAC+To+BUFR+Migration\nhttps://software.ecmwf.int/wiki/display/TCBUF/Statistics+of+High+resolution+BUFR+TEMP","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/Phasing?action=edit\"","category":"page"},{"location":"Phasing/#Phasing-information-1","page":"Phasing information","title":"Phasing information","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Version (trunk,40h1.1)","category":"page"},{"location":"Phasing/#Introduction-1","page":"Phasing information","title":"Introduction","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"In the following we describe the procedure to interface the HIRLAM subversion repository to the git repository at Météo France. Further on, the tasks of the phasers and procedure to create a new branch are described. A course was held at Météo France in 2010 on the subject of Maintenance Training. Some of the presentations made at this Maintenance Training course may still be of use. They are available from this !GmapDoc web page: http://www.cnrm.meteo.fr/gmapdoc/spip.php?article208&lang=en","category":"page"},{"location":"Phasing/#Access-to-external-Meteo-France-git-repository-1","page":"Phasing information","title":"Access to external Meteo France git repository","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Meteo France have a mirror of their git repository located outside of all firewalls. To be able to access the firewall you have to by granted access by providing a public SSH key to Meteo France. Once this is done you can clone the repository by:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"git clone ssh://reader054@git.cnrm-game-meteo.fr/git/arpifs.git","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Note that this is only for read access. To arrange access to the repository please contact the HIRLAM system manager.","category":"page"},{"location":"Phasing/#git-subversion-merging-1","page":"Phasing information","title":"git -> subversion merging","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"This section of the phasing documentation provides instructions on how to retrieve . In here we assume you have the access rights and the knowledge to connect to the right computers (Météo France git repositories can be accessed from 'merou'). Details on how to access Météo France servers are available here: wiki:HarmonieSystemDocumentation/MFaccess.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Set up git for the first time: Météo France provide documentation on how to set up and use their git repository here: http://www.cnrm.meteo.fr/gmapdoc/spip.php?article218&var_lang=en. A git user account must be requested from gco at Météo France. ","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Add the following lines to your HOME/.bashrc file (replacing yourusername with your user name):","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"export GIT_INSTALL=\"/home/marp001/git-install\"\r\nexport GIT_ROOTPACK=\"git://mirage\"\r\nexport GIT_HOMEPACK=\"/home/mrpe/yourusername/git-dev\"\r\nexport GIT_WORKDIR=\"/home/mrpe/yourusername/.git-workdir\"\r\n\r\nexport PATH=/home/marp001/git-install/default/bin:/home/marp001/git-install/default/libexec/git-core:/home/marp001/git-install/client/default/\r\nbin:$PATH","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"I issued the git_start command (in /home/marp001/git-install/client/default/bin) to initialize a git repository in my own account on merou:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"git_start    ### this will require your git userid and password","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"To get the latest tagged version of the source code:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cd $HOME/git-dev/arpifs/\r\ngit tag  ### this command will list available tags in the git repository\r\ngit archive --format=tar -o /home/mrpe/whelane/CY40_t1.04.tar --prefix=CY40_t1.04/ CY40_t1.04\r\ncd $HOME\r\ngzip /home/mrpe/whelane/CY40_t1.04.tar","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"ftp this zipped tar-ball to wherever you plan to carry out your merging activities.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Continue with the Merge into vendor branch instructions.","category":"page"},{"location":"Phasing/#Merge-into-vendor-branch-1","page":"Phasing information","title":"Merge into vendor branch","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"To import source code from an external vendor we use the script autosvnload_dirs.pl in contrib/util.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Unpack your tar file in a directory with a proper name, e.g. CY40_t1.04, and rename the standard projects and remove some projects not used by Harmonie. (Further details on the !ClearCase/GIT/PERFORCE project naming are available here: http://www.cnrm.meteo.fr/gmapdoc/IMG/pdf/ykarchi40.pdf).","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"gunzip CY40_t1.04.tar.gz \r\ntar -xvf CY40_t1.04.tar \r\nls CY40_t1.04\r\ncd CY40_t1.04\r\nmv aeolus/ aeo\r\nmv aladin/ ald\r\nmv arpifs/ arp\r\nmv biper/ bip\r\nmv blacklist/ bla\r\nmv satrad/ sat\r\nmv surf sur\r\nmv etrans/ tal\r\nmv trans/ tfl\r\nmv utilities/ uti\r\nmv algor/ xla\r\nmv ifsaux/ xrd\r\nrm -rf cope/ obstat/ scripts/ scat/","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Check out vendor/aladin/current as current-wc in a parallel directory:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"svn co https://svn.hirlam.org/vendor/aladin/current current-wc","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Now we are ready to start the merge:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"auto_svn_load_dirs.pl -v -wc current-wc https://svn.hirlam.org/vendor/aladin current CY40_t1.04","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"This will present you with a list of all the files that seem to have been moved. You then get a chance to have the script \"Guess\" what the corrective action should be. You can accept or reject that choice for every file separately.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"When all files have been processed, choose \"Finish\" to have the script complete the update to vendor/aladin/current and commit the changes.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Subsequently, tag the new vendor/aladin/current:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"svn copy -m \"Tag vendor/aladin/current as vendor/aladin/cy40t1.04.\" https://svn.hirlam.org/vendor/aladin/current https://svn.hirlam.org/vendor/aladin/cy40t1.04","category":"page"},{"location":"Phasing/#Merge-new-vendor-copy-into-phasing-branch-1","page":"Phasing information","title":"Merge new vendor copy into phasing branch","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Create a fresh working copy of the phasing branch (cy40):","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"svn co https://svn.hirlam.org/branches/phasing/cy40 working-copy","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Perform the merge of the new source code. Note that <previous-tag> below should be the version used last time there was a merge from the vendor branch to the trunk.  If you pick the wrong version you could miss changes. Postpone every conflict by choosing 'p':","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"svn merge https://svn.hirlam.org/vendor/aladin/<previous-tag> https://svn.hirlam.org/vendor/aladin/current working-copy/src","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Resolve the conflicts by using the script svn_resolve.pl (available in contrib/util):","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cd working-copy\r\nsvn_resolve.pl","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"The script gives you the option to view various differences, edit the working copy and indicate to svn that the conflict has been resolved.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"In the end, the correct source has to end up in the file with the name of the original source. That name, with the extension '.working' means what's in the working-copy directory, with '.merge-left' means what's in the old vendor branch and with '.merge-right' what's in the new vendor branch.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"After all conflicts have been resolved (sometimes it might be expedient to simply take the the updated file from the vendor branch and have researchers resolve conflicts afterwards), the final commit is in order (also from directory 'working-copy').","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"svn commit","category":"page"},{"location":"Phasing/#Alternatively,-merge-new-vendor-copy-into-trunk-1","page":"Phasing information","title":"Alternatively, merge new vendor copy into trunk","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Create a fresh working copy of the trunk:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"svn co https://svn.hirlam.org/trunk/harmonie working-copy","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Perform the merge of the new source code. Note that <previous-tag> below should be the version used last time there was a merge from the vendor branch to the trunk.  If you pick the wrong version you could miss changes. Postpone every conflict by choosing 'p':","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"svn merge https://svn.hirlam.org/vendor/aladin/<previous-tag> https://svn.hirlam.org/vendor/aladin/current working-copy/src","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Resolve the conflicts by using the script svn_resolve.pl (available in contrib/util):","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cd working-copy\r\nsvn_resolve.pl","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"In the end, the correct source has to end up in the file with the name of the original source. That name, with the extension '.working' means what's in the working-copy directory, with '.merge-left' means what's in the old vendor branch and with '.merge-right' what's in the new vendor branch.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"After all conflicts have been resolved (sometimes it might be expedient to simply take the the updated file from the vendor branch and have researchers resolve conflicts afterwards), the final commit is in order (also from directory 'working-copy').","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"svn commit","category":"page"},{"location":"Phasing/#Reverting-tree-conflicts-1","page":"Phasing information","title":"Reverting tree conflicts","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Just a short note to save time ...If you come accross a conflict such as the one below ...","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"!     C surfex/SURFEX/.isba_fluxes.F90.swp\r\n      >   local delete, incoming delete upon merge","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"one can try the following procedure:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"touch src/surfex/SURFEX/.isba_fluxes.F90.swp\r\nsvn revert  src/surfex/SURFEX/.isba_fluxes.F90.swp","category":"page"},{"location":"Phasing/#Subversion-MF-git:-Create-a-\"contributions-from-hirlam\"-branch-1","page":"Phasing information","title":"Subversion -> MF git: Create a \"contributions-from-hirlam\" branch","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Every development cycle there is the opportunity to add contributions or bug fixes from the HIRLAM consortium to IFS. This is done by creating a git branch off the latest version of that cycle. These HIRLAM contribution branches are then \"posted\" to the MF git SCR and GCO staff.","category":"page"},{"location":"Phasing/#Create-a-send-branch-and-add-HIRLAM-contributions-1","page":"Phasing information","title":"Create a send branch and add HIRLAM contributions","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Create a \"send\" branch based on the latest tagged vendor version. In the example below the vendor tag of cy40t1.04 is copied to the second contribution branch in the Harmonie phasing branch.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"svn cp https://svn.hirlam.org/vendor/aladin/cy40t1.04 https://svn.hirlam.org/branches/phasing/cy40_send2","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Commit agreed contributions from the Harmonie phasing branch to the send branch, cy40_send2 for example.","category":"page"},{"location":"Phasing/#Create-MF-git-branch(es)-containing-HIRLAM-contributions-1","page":"Phasing information","title":"Create MF git branch(es) containing HIRLAM contributions","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Log in to merou.meteo.fr and prepare the HIRLAM send branch code for a final comparison with the MF ","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cd $HOME\r\nmkdir hirlam_sends\r\ncd hirlam_sends\r\nsvn export https://svn.hirlam.org/branches/phasing/cy40_send2 cy40_send2_export\r\ncp -r cy40_send2_export cy40_send2_gitexport\r\ncd cy40_send2_gitexport\r\nmv aeo aeolus\r\nmv ald aladin\r\nmv arp arpifs\r\nmv bip biper\r\nmv bla blacklist\r\nmv obt obstat\r\nmv sat satrad\r\nmv sur surf\r\nmv tal etrans\r\nmv tfl trans\r\nmv uti utilities\r\nmv xrd ifsaux\r\nmv xla algor\r\ncd ~/git-dev/arpifs/\r\ngit pull\r\ngit branch CY40_bf.01_hirlam tags/CY40_bf.01\r\ngit checkout CY40_bf.01_hirlam\r\ncd ~/hirlam_sends/\r\ndiff -r cy40_send2_gitexport/ ~/git-dev/arpifs/ > diffs.txt","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Have a quick look in diffs.txt to ensure the send branch code contains the intended differences.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Ensure your account is readable so that when you \"post\" your branch GCO can read it:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cd $HOME/../\r\nchmod 755 username","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Now everything is in place to create some HIRLAM contribution git branches. In the following examples I will create two separate branches with two contributions from HIRLAM developers.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cd ~/git-dev/arpifs/\r\ngit pull\r\ngit_branch -r 40 -b t1 -v 04 -u suparar_bugfix      # answer \"y\" to create this branch\r\ngit branch                                          # this lists git branches and \"*\" indicates the branch you are working in (should be gitUserName_CY40_suparar_bugfix)\r\ncp ~/hirlam_sends/cy40_send2_gitexport/arpifs/phys_dmn/suparar.F90 arpifs/phys_dmn/suparar.F90\r\ngit status                                          # check on status\r\ngit add arpifs/phys_dmn/suparar.F90                 # add this change to your local git branch\r\ngit commit arpifs/phys_dmn/suparar.F90              # enter a useful commit message\r\ngit_post                                            # this command \"posts\" your git branch (this may be the same as/similar to git push)","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"You should receive an e-mail from gco@meteo.fr acknowledging your branch posting. ","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Now \"move\" back out of this new branch:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"git checkout gco_CY40_t1\r\ngit fetch\r\ngit branch","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Now an example involving the movement of files:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"git_branch -r 40 -b t1 -v 04 -u lfi_sub_move\r\ngit branch\r\ngit mv ifsaux/programs/fadate.F90 ifsaux/misc/\r\ngit mv ifsaux/programs/fadiff.F90 ifsaux/misc/\r\ngit mv ifsaux/programs/lfi_alt_copy.F90 ifsaux/misc/\r\ngit mv ifsaux/programs/lfi_alt_indx.F90 ifsaux/misc/\r\ngit mv ifsaux/programs/lfi_alt_pack.F90 ifsaux/misc/\r\ngit mv ifsaux/programs/lfifactm.F90 ifsaux/misc/\r\ngit status\r\ngit add ifsaux/misc/fadate.F90  ifsaux/misc/fadiff.F90 ifsaux/misc/lfi_alt_copy.F90 ifsaux/misc/lfi_alt_indx.F90 ifsaux/misc/lfi_alt_pack.F90 ifsaux/misc/lfifactm.F90\r\ngit commit\r\ngit_post","category":"page"},{"location":"Phasing/#Send-GCO-an-e-mail-relating-to-HIRLAM-contributions-1","page":"Phasing information","title":"Send GCO an e-mail relating to HIRLAM contributions","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"MF request that each contribution branch is accompanied with an e-mail (To:gco@meteo.fr cc: claude.fischer@meteo.fr, Ulf.Andrae@smhi.se) containing the following information:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Title/header of email should read like:  \"dev\"  nameoftargetcycle  shorttitle\nnameoftarget_cycle  should be CY40 or CY40T1 etc ...\nshort_title  can be either to announce that this is a bugfix or a specific contribution for R&D: \"Correction of a bug in Full-Pos\"   or  \"Additional code for handling Aeolus in ODB\"   or  \"Hirlam contribution to CY40\"   etc ...","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Date and name of Contributor:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"dd/mm/yyyy Name (MF Service, Aladin or Hirlam partner)","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Model or configuration affected by the modset:\narpege, aladin-france, aladin-réunion, arome, aearp, pearp,...\nfor partners: alaro, arome, harmonie (but you may be more specific about harmonie-alaro or harmonie-arome)","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Context and cycle:\ncontext: oper, double, dev   => refers to MF environment. dev => for partners\ncycle example: 40op1 (MF only), 40bf.01 (bugfix), 40_t1 (pre-cycle during phasing)","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Type of file/resource to be modified:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Namelist, Binary, climatology file, file of constant fields (sigma_b, ...), blacklist, ...   => mostly \"Binary\" (i.e. code changes) and \"namelist\" seem relevant for partners","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Description of the set of modifications:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"... a more or less detailed text about the code changes: purpose, how it was done, what is the impact on results or performances, options still under work ...","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Details about the provided files:\nif source code changes: name of GIT branch & list of modified/added/deleted routines/files\nif \"files of constants\":  (...)  (only MF, irrelevant for partners)\nif namelist change: name of namelist block, delta of namelist and/or location of namelist file  (probably only relevant to MF)","category":"page"},{"location":"Phasing/#Getting-namelists-used-at-Meteo-France-1","page":"Phasing information","title":"Getting namelists used at Meteo-France","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Log in to yuki (or tori). Then run the command genv (you may have to add /mf/dp/marp/marp001/public/bin to your PATH if you don't have it already):","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"mrpe726@yuki:~> genv\r\nusage (1) : genv suite-model:YYYY/MM/DD[-RXX]\r\n\r\n            suite = oper dble test\r\n            model = arpege aladin tropique mocage restart peace reunion alacep arome varpack tsr aria algerie qatar libye testmp1 testmp2\r\n\r\nusage (2) : genv suite-model\r\n\r\n            suite = oper dble test\r\n            model = arpege aladin tropique mocage restart peace reunion alacep arome varpack tsr aria algerie qatar libye testmp1 testmp2\r\n\r\n\t    NB: same as (1) - today's date is automatically added\r\n\r\nusage (3) : genv cycle-id\r\n       ex : genv cy33t0_op1.23","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Note that there are no namelists for ALARO. Anyway, to get e.g. the current AROME namelists:","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"mrpe726@yuki:~> genv oper-arome | grep NAMELIST\r\nNAMELIST_ALADIN=\"al35t2_arome-op1.16.nam\"\r\nNAMELIST_AROME=\"al35t2_arome-op1.16.nam\"\r\nNAMELIST_UTILITIES=\"ut35t2_arome-op1.04.nam\"","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"To actually get the namelists, run the command gget","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"mrpe726@yuki:~> gget al35t2_arome-op1.16.nam","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"You get a lot of namelists in a directory named NAMELIST_AROME","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"mrpe726@yuki:~> cd al35t2_arome-op1.16.nam/\r\nmrpe726@yuki:~/al35t2_arome-op1.16.nam> ls\r\ndiff.al35t2_arome-op1.15.nam  namel_ee927_surf.franxl    namel_lamflag_odb.midpyr  namel_sude_off_fp0\r\nlist.al35t2_arome-op1.16.nam  namel_ee927_surf.midpyr    namel_lamflag_odb.nore    namel_surfex_output\r\nnamel_bret_off_fp             namel_ee927_surf.nore      namel_lamflag_odb.pari    README\r\nnamel_bret_off_fp0            namel_ee927_surf.pari      namel_lamflag_odb.sude    select_bret_off_fp\r\nnamel_cplsurf_def             namel_ee927_surf.sude      namel_midpyr_off_fp       select_bret_off_fp0\r\nnamel_ee927_bret_cpl          namel_fpos_bret_addsurf    namel_midpyr_off_fp0      select_fran_off_fp\r\nnamel_ee927_bret_cpl0         namel_fpos_fran_addsurf    namel_minim               select_fran_off_fp0\r\nnamel_ee927_fran_cpl          namel_fpos_franxl_addsurf  namel_nore_off_fp         select_franxl_fp\r\nnamel_ee927_fran_cpl0         namel_fpos_midpyr_addsurf  namel_nore_off_fp0        select_franxl_fp0\r\nnamel_ee927_franxl_cpl        namel_fpos_nore_addsurf    namel_pari_off_fp         select_franxl_off_fp\r\nnamel_ee927_franxl_cpl0       namel_fpos_pari_addsurf    namel_pari_off_fp0        select_franxl_off_fp0\r\nnamel_ee927_midpyr_cpl        namel_fpos_sude_addsurf    namel_previ_dyn_off       select_midpyr_off_fp\r\nnamel_ee927_midpyr_cpl0       namel_fran_off_fp          namel_previ_off           select_midpyr_off_fp0\r\nnamel_ee927_nore_cpl          namel_fran_off_fp0         namel_previ_surfex        select_nore_off_fp\r\nnamel_ee927_nore_cpl0         namel_franxl_off_fp        namel_progrele            select_nore_off_fp0\r\nnamel_ee927_pari_cpl          namel_franxl_off_fp0       namel_pseudotraj          select_pari_off_fp\r\nnamel_ee927_pari_cpl0         namel_franxl_previ         namel_rgb                 select_pari_off_fp0\r\nnamel_ee927_sude_cpl          namel_franxl_previ_dyn     namel_rgb_met8            select_sude_off_fp\r\nnamel_ee927_sude_cpl0         namel_lamflag_odb.bret     namel_rgb_met9            select_sude_off_fp0\r\nnamel_ee927_surf.bret         namel_lamflag_odb.fran     namel_screen\r\nnamel_ee927_surf.fran         namel_lamflag_odb.franxl   namel_sude_off_fp","category":"page"},{"location":"Phasing/#Preparations-before-phasing-1","page":"Phasing information","title":"Preparations before phasing","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"Read the Meteo France webpage about phasing [http://www.cnrm.meteo.fr/aladin/spip.php?article63].","category":"page"},{"location":"Phasing/#HARMONIE-phasing-efforts-1","page":"Phasing information","title":"HARMONIE phasing efforts","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cy38t1","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cy39t1","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cy40t1","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cy41t1","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cy42t1","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"LUNBCincy43t1","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cy45t1","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"cy46t1","category":"page"},{"location":"Phasing/#Testbed-experiments-1","page":"Phasing information","title":"Testbed experiments","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"The Harmonie testbed is a tool to help you verify the technical functionality of the system. It runs through all meaningful configurations in an efficient manner.  Read more here.","category":"page"},{"location":"Phasing/#Update-documentation-1","page":"Phasing information","title":"Update documentation","text":"","category":"section"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"The final task at the end of the phasing is to tag the documentation with the current version number. The documentation has of course been updated continuously but might need a final review before tagging. Some scripts to make tagging easier is attached to this page. After tagging the new pages may be loaded to the wiki using the trac-admin tool on hirlam.org.","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"trac-admin /data/www/trac_hirlam_env/ wiki load MYDIR","category":"page"},{"location":"Phasing/#","page":"Phasing information","title":"Phasing information","text":"where MYDIR is a directory containing the revised wiki pages. You must have TRAC_ADMIN permissions to be able to use the trac-admin tool.","category":"page"},{"location":"Phasing/#[Back-to-the-main-page-of-the-HARMONIE-System-Documentation](../HarmonieSystemDocumentation.md)-1","page":"Phasing information","title":"Back to the main page of the HARMONIE System Documentation","text":"","category":"section"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"EditURL=\"https://hirlam.org/trac//wiki//HarmonieSystemDocumentation/StandaloneOdb?action=edit\"","category":"page"},{"location":"StandaloneOdb/#ODB-software-1","page":"Stand Alone ODB","title":"ODB software","text":"","category":"section"},{"location":"StandaloneOdb/#Get-the-software-1","page":"Stand Alone ODB","title":"Get the software","text":"","category":"section"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"To make best use of ODB information produced by your Harmonie experiment one should use ODB and ODB-API software developed by ECMWF. Below are instruction on how to obtain the software from ECMWF.","category":"page"},{"location":"StandaloneOdb/#ODB-API-1","page":"Stand Alone ODB","title":"ODB-API","text":"","category":"section"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"ODB-API software is open source and released under an Apache licence: https://software.ecmwf.int/wiki/display/ODBAPI ","category":"page"},{"location":"StandaloneOdb/#ODB-1","page":"Stand Alone ODB","title":"ODB","text":"","category":"section"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"ODB stands for Observational !DataBase. It is database software to store and retrieve large amounts of meteorological numerical data in an efficient manner while used from within IFS. ODB software mimics relational database queries through its ODB/SQL -compiler and accesses data currently via a Fortran90 library interface. The original documentation is available here: http://www.ecmwf.int/research/ifsdocs/CY28r1/pdf_files/odb.pdf","category":"page"},{"location":"StandaloneOdb/#Building-your-ODB-software-1","page":"Stand Alone ODB","title":"Building your ODB software","text":"","category":"section"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"The ODB-API Software bundle uses cmake http://www.cmake.org to configure the make files used to compile the software. The instructions below worked with Redhat 7/GCC 4.8.5 and CentOS 7/GCC 4.8.5. On newer systems python functionality may have to be switched off with -DENABLE_PYTHON=OFF.","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"VERSION=0.18.1\r\nwget https://software.ecmwf.int/wiki/download/attachments/61117379/odb_api_bundle-${VERSION}-Source.tar.gz\r\ngunzip odb_api_bundle-${VERSION}-Source.tar.gz\r\ntar -xvf odb_api_bundle-${VERSION}-Source.tar\r\ncd odb_api_bundle-${VERSION}-Source\r\nmkdir build\r\ncd build\r\ncmake.. -DCMAKE_INSTALL_PREFIX=/opt/metapp/odb_api/${VERSION}/gnu \\\r\n-DENABLE_ODB_API_SERVER_SIDE=ON -DENABLE_FORTRAN=ON \\\r\n-DENABLE_GRIB=OFF -DENABLE_ODB_SERVER_TIME_FORMAT_FOUR_DIGITS=ON \\\r\n-DENABLE_PYTHON=ON -DENABLE_ODB=ON -DODB_SCHEMAS=\"ECMA;CCMA\"\r\nmake -j 2\r\nctest\r\nmake install","category":"page"},{"location":"StandaloneOdb/#ACTION:-FOR-EOIN:-everything-below-here-needs-to-be-updated-1","page":"Stand Alone ODB","title":"ACTION: FOR EOIN: everything below here needs to be updated","text":"","category":"section"},{"location":"StandaloneOdb/#ODB-data-1","page":"Stand Alone ODB","title":"ODB data","text":"","category":"section"},{"location":"StandaloneOdb/#Convert-ODB-1-to-ODB-2-1","page":"Stand Alone ODB","title":"Convert ODB-1 to ODB-2","text":"","category":"section"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"Details on how to convert your ODB-1 (Harmonie experiment) databases to ODB-2 using odb_migrator are described here. I have used version 0.9.31 of ODB-API (I have had some problems with 0.9.32). I will use a Harmonie CCMA conventional ODB-1 database as an example:","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"tar -xvf odb_ccma.tar\r\ncd odb_ccma/CCMA/\r\ndcagen\r\ncd ../../\r\nls -l ../conv.38h1.sql\r\nwhich odb_migrator\r\n/opt/metlib/odb_api/0.9.31/gnu/bin/odb_migrator -addcolumns \"expver='    38h1',class=2,stream=1025,type=264\" odb_ccma/CCMA ../conv.38h1.sql var${DTG}.odb\r\nls -l var${DTG}.odb","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"Here is the SQL file used: conv.38h1.sql. To construct my conv.38h1.sql file did carried out the following commands:","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"cd odb_ccma/CCMA/\r\nodbsql -q \"select * from desc,timeslot_index,hdr,body\" | head -1 ","category":"page"},{"location":"StandaloneOdb/#Instructions-for-use-on-ecgb-1","page":"Stand Alone ODB","title":"Instructions for use on ecgb","text":"","category":"section"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"On ecgb I have installed odb_migrator in my own account. ODB developers have promise to provide a \"system\" installation of odbmigrator soon. The next version of ODB-API on ecgb should include *odbmigrator*. My installation is here:","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"/home/ms/ie/dui/odbapi/0.9.31","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"To produce your own ODB-2 file from a Harmonie CCMA tar ball on ecgb:","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"module load odb\r\nexport PATH=/home/ms/ie/dui/odbapi/0.9.31/bin:$PATH\r\nexport LD_LIBRARY_PATH=/home/ms/ie/dui/odbapi/0.9.31/lib:$LD_LIBRARY_PATH\r\ncd $SCRATCH\r\nmkdir ODB2odb\r\ncd ODB2odb\r\n## copy your odb_stuff.tar/odb_ccma.tar file from ECFS/your home system to this directory\r\n## eg -- ecp ec:/dui/harmonie/refSonde38h1p1/2013/12/27/00/odb_stuff.tar .\r\ntar -xvf odb_stuff.tar\r\ntar -xvf odb_ccma.tar\r\ncd odb_ccma/CCMA/\r\ndcagen\r\ncd ../../\r\nodb_migrator odb_ccma/CCMA -addcolumns \"expver='refSonde',class=2,stream=1025,type=264\" /home/ms/ie/dui/odbapi/conv.38h1.sql conv2013122700.odb\r\nodb header conv2013122700.odb\r\nodb sql 'select distinct varno' -i conv2013122700.odb\r\nodb sql 'select count(*) where varno=2' -i conv2013122700.odb\r\n#\r\nrm -f bdstrategy odb*.tar ## tidy up the directory if you wish\r\nrm -rf odb_ccma","category":"page"},{"location":"StandaloneOdb/#ODB-visualisation-1","page":"Stand Alone ODB","title":"ODB visualisation","text":"","category":"section"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"ODB-2 data can be visualized (directly) using Metview. On local platforms Metview must be built with ODB support (that uses ODB-API software) to visualize ODB-2 data. Here is an example, odbmap.mv4, of using Metview on ecagte to visualize ODB-2 data using a Metview Macro. This example requires an ODB-2 data file as input. Optionally this macro can also plot domain grid-points from a Harmonie GRIB file (called dom.grib) to indicate the extent of your Harmonie model domain.","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"Usage:","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":" odbmap:: Usage: metview -b odbmap.mv4 inputfile odbvar odbrequest odblegend outputtype\r\n odbmap::   where: inputfile  -- ODB-2 file\r\n odbmap::   where: odbvar     -- ODB variable to be plotted\r\n odbmap::                     -- (enclosed with inverted commas)\r\n odbmap::   where: odbrequest -- ODB SQL request \r\n odbmap::                     -- (enclosed with inverted commas)\r\n odbmap::   where: odblegend  -- legon/legoff\r\n odbmap::   where: outputtype -- ps/png","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"An example to plot 2m temperature observation values on 25th December 2013 at 12z:","category":"page"},{"location":"StandaloneOdb/#","page":"Stand Alone ODB","title":"Stand Alone ODB","text":"cd  $SCRATCH\r\ncp -r /home/ms/ie/dui/odbMacroTest .\r\ncd odbMacroTest\r\nmetview4 -b odbmap.mv4 conv201312.odb \"obsvalue\" \"andate=20131225 and antime=120000 and varno=39\" legon png\r\nxv odbmap.1.png","category":"page"}]
}
